{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import csv\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "API_KEY = \"your_API_key\" \n",
    "openai.api_key = API_KEY\n",
    "\n",
    "## Scenarios & Prompts \n",
    "##forest\n",
    "gain_forest = \"\"\"Scenario: A vast forest area is under severe threat from deforestation due to urban growth and logging activities, potentially resulting in the removal of 900 trees from a grove of ancient oak trees in the forest. Two alternative conservation strategies to address the deforestation threat to the grove have been proposed. Imagine you are on the conservation committee tasked with deciding on a proposal. Assume that the estimates are as follows:\\n- Option A: If Proposal A is adopted, 300 of the trees will be protected.\\n- Option B: If Proposal B is adopted, there is a 1/3 probability that all 900 of the trees will be protected, and 2/3 probability that no trees will be protected.\"\"\"\n",
    "loss_forest = \"\"\"Scenario: A vast forest area is under severe threat from deforestation due to urban growth and logging activities, potentially resulting in the removal of 900 trees from a grove of ancient oak trees in the forest. Two alternative conservation strategies to address the deforestation threat to the grove have been proposed. Imagine you are on the conservation committee tasked with deciding on a proposal. Assume that the estimates are as follows:\\n- Option A: If Proposal A is adopted, 600 of the trees will be cleared.\\n- Option B: If Proposal B is adopted, there is a 1/3 probability that none of the trees will be cleared, and 2/3 probability that all 900 of the trees will be cleared.\"\"\"\n",
    "\n",
    "##human\n",
    "gain_human = \"\"\"Scenario: A city is facing significant air quality issues due to high levels of pollution, which could lead to 900 premature deaths over the next year due to respiratory illness. Two alternative plans to improve the air quality and reduce pollution have been proposed. Imagine you are a city official on the committee tasked with deciding on a proposal. Assume that the estimates are as follows:\\n- Option A: If Proposal A is adopted, 300 people will survive.\\n- Option B: If Proposal B is adopted, there is a 1/3 probability that all 900 people will survive, and 2/3 probability that no one will survive.\"\"\"\n",
    "loss_human = \"\"\"Scenario: A city is facing significant air quality issues due to high levels of pollution, which could lead to 900 premature deaths over the next year due to respiratory illness. Two alternative plans to improve the air quality and reduce pollution have been proposed. Imagine you are a city official on the committee tasked with deciding on a proposal. Assume that the estimates are as follows:\\n- Option A: If Program A is adopted, 600 people will die.\\n- Option B: If Program B is adopted, there is a 1/3 probability that no one will die, and 2/3 probability that all 900 people will die.\"\"\"\n",
    "\n",
    "#animal (oil spill) scenario\n",
    "gain_animal = \"\"\"Scenario: An oil spill off the coast of a country is anticipated to cause significant environmental damage, and is projected to endanger the lives of 900 marine animals, including sea turtles, seals, and various types of seabirds. Two alternative clean-up efforts to address the oil spill have been proposed. Imagine you are on the clean-up committee tasked with deciding on a proposal. Assume that the estimates are as follows:\\n- Option A: If Proposal A is adopted, 300 of the marine animals will survive.\\n- Option B: If Proposal B is adopted, there is a 1/3 probability that all 900 of the marine animals will survive, and 2/3 probability that no marine animals will survive.\"\"\"\n",
    "loss_animal = \"\"\"Scenario: An oil spill off the coast of a country is anticipated to cause significant environmental damage, and is projected to endanger the lives of 900 marine animals, including sea turtles, seals, and various types of seabirds. Two alternative clean-up efforts to address the oil spill have been proposed. Imagine you are on the clean-up committee tasked with deciding on a proposal. Assume that the estimates are as follows:\\n- Option A: If Proposal A is adopted, 600 of the marine animals will die.\\n- Option B: If Proposal B is adopted, there is a 1/3 probability that no marine animals will die, and 2/3 probability that all 900 of the marine animals will die.\"\"\"\n",
    "\n",
    "\n",
    "##################################### Comboos for Experiment #####################################\n",
    "\n",
    "####### System Role ####### \n",
    "\n",
    "###Combo 1: Baseline Condition (formerly, combo 8B) ##tested\n",
    "    # participant \n",
    "    # capable of decisions\n",
    "    # basic instructions -- user messsage \n",
    "    ## user_message_baseline1 = user_message_4 \n",
    "system_message_baseline1 = \"You are a participant in a survey. You are capable of making decisions and choices. Provide your response as a JSON object.\"\n",
    "user_message_baseline1 = \"\"\"You are participating in a survey-based study.\\nInstructions: read the scenario below and then answer the questions.\\n{}\\n\\nQuestions:\\n1. Please choose an option:\\n- Proposal A\\n- Proposal B\\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Briefly describe the rationale for your preference rating:\\n\\nProvide your response as a JSON object. As an example: '{{\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}}'.\\n\\nResponse:\"\"\"\n",
    "\n",
    "###Combo 2: Human Participant \n",
    "    # (+) human participant -- system messsage \n",
    "    # capable of decisions -- system messsage \n",
    "    # single JSON -- system message\n",
    "    # basic instructions -- user messsage  \n",
    "    # Task Order Instructions via one JSON object -- user messsage \n",
    "system_message_hum  = \"You are a human participant in a survey. You are capable of making decisions and choices. Provide your response as a JSON object.\"\n",
    "user_message = user_message_baseline1\n",
    "\n",
    "###Combo 3: Adds in Risk Preferences \n",
    "    # human participant -- system messsage \n",
    "    # capable of decisions -- system messsage \n",
    "    # (+) Consider human risk preferenes -- system messsage\n",
    "    # single JSON -- system message\n",
    "    # basic instructions -- user messsage  \n",
    "    # Task Order Instructions via one JSON object -- user messsage \n",
    "system_message_risk = \"You are a human participant in a survey. You are capable of making decisions and choices. You are responding to a survey with the same risk preferences as a human participant would. Provide your response as a JSON object.\" \n",
    "user_message = user_message_baseline1\n",
    "\n",
    "\n",
    "###Combo 4: Adds in Risk Preferences to user message\n",
    " # human participant -- system messsage \n",
    "    # capable of decisions -- system messsage \n",
    "    # Consider human risk preferenes -- system messsage\n",
    "    # single JSON -- system message\n",
    "    # basic instructions -- user messsage  \n",
    "    # Task Order Instructions via one JSON object -- user messsage \n",
    "    # (+) Consider human risk preferenes -- user messsage\n",
    "\n",
    "system_message = system_message_risk\n",
    "user_message_risk = \"\"\"You are participating in a survey-based study. Respond with the same risk preferences as a human participant would.\\nInstructions: read the scenario below and then answer the questions.\\n{}\\n\\nQuestions:\\n1. Please choose an option:\\n- Proposal A\\n- Proposal B\\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Briefly describe the rationale for your preference rating:\\n\\nProvide your response as a JSON object. As an example: '{{\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}}'.\\n\\nResponse:\"\"\"\n",
    "\n",
    "## Define Functions & Model Call\n",
    "## Create functions to make prompt scenario dynamics \n",
    "def format_scenario(scenario_text):\n",
    "    return scenario_text\n",
    "\n",
    "def format_prompt(prompt_text, scenario):\n",
    "    return prompt_text.format(scenario)\n",
    "\n",
    "##define scenario and user_message variables \n",
    "def generate_response_turbo(sys_prompt, user_prompt, temperature, top_p):\n",
    "     messages=[{\"role\": \"system\", \"content\" : sys_prompt },\n",
    "               {\"role\": \"user\", \"content\" : user_prompt }]\n",
    "     response = openai.ChatCompletion.create(\n",
    "          #model=\"gpt-3.5-turbo\",\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "          messages = messages,\n",
    "          temperature=temperature,\n",
    "          max_tokens=200,\n",
    "          n=1, \n",
    "          top_p=top_p\n",
    "  )\n",
    "     prompt = sys_prompt + user_prompt\n",
    "     return [(prompt, response.choices[0].message['content'], temperature, top_p) for choice in response.choices ]\n",
    "\n",
    "     ## Call Model for Each Scenario\n",
    "######## Humans ########\n",
    "\n",
    "## Human Loss \n",
    "##humans_loss\t37\n",
    "\n",
    "human_loss_turbo = []\n",
    "\n",
    "for i in range(37):\n",
    "    formatted_scenario = format_scenario(loss_human) ##change for each run \n",
    "    user_message = format_prompt(user_message, \n",
    "                                 formatted_scenario) ##change for each run \n",
    "    human_loss_output = generate_response_turbo(system_message, \n",
    "                                                user_message, .7, 1) \n",
    "    prompt, response, temperature, top_p = human_loss_output[0]  \n",
    "    frame = 'loss_human'\n",
    "    model = 'gpt-3.5-turbo'\n",
    "    test = ##add in test\n",
    "    num_calls = 37 ## matches to qual exp.  \n",
    "    human_loss_turbo.append({'prompt': prompt, 'response': response, 'temperature': temperature,'top_p': top_p, 'test': test, 'model': model, 'frame': frame, 'num_calls': num_calls})\n",
    "\n",
    "## Human Gain \n",
    "##humans_gain\t30\n",
    "\n",
    "human_gain_turbo = []\n",
    "\n",
    "for i in range(30):\n",
    "    formatted_scenario = format_scenario(gain_human) ##change for each run \n",
    "    user_message = format_prompt(user_message, \n",
    "                                 formatted_scenario) ##change for each run \n",
    "    human_gain_output = generate_response_turbo(system_message, \n",
    "                                                user_message, .7, 1) \n",
    "    prompt, response, temperature, top_p = human_gain_output[0]  \n",
    "    frame = 'gain_human' \n",
    "    model = 'gpt-3.5-turbo'\n",
    "    test = 30\n",
    "    num_calls = 20 ## matches to qual exp.  \n",
    "    \n",
    "    human_gain_turbo.append({'prompt': prompt, 'response': response, 'temperature': temperature,'top_p': top_p, 'test': test, 'model': model, 'frame': frame, 'num_calls': num_calls})\n",
    "\n",
    "######## Animals ########\n",
    "## Animal Loss \n",
    "##animals_loss\t37\n",
    "animal_loss_turbo = []\n",
    "for i in range(37):\n",
    "    formatted_scenario = format_scenario(loss_animal)  \n",
    "    user_message = format_prompt(user_message, ##change for each run \n",
    "                                 formatted_scenario) \n",
    "    animal_loss_output = generate_response_turbo(system_message, ##change for each run \n",
    "                                                user_message, .7, 1) \n",
    "    prompt, response, temperature, top_p = animal_loss_output[0]  \n",
    "    frame = 'loss_animal'  \n",
    "    model = 'gpt-3.5-turbo'\n",
    "    test = ##add in test\n",
    "    num_calls = 37\n",
    "    animal_loss_turbo.append({'prompt': prompt, 'response': response, 'temperature': temperature,'top_p': top_p, 'test': test, 'model': model, 'frame': frame, 'num_calls': num_calls})\n",
    "\n",
    "## Animal Gain \n",
    "##animals_gain\t34 \n",
    "\n",
    "animal_gain_turbo = []\n",
    "for i in range(34):\n",
    "    formatted_scenario = format_scenario(gain_animal) \n",
    "    user_message = format_prompt(user_message, ##change for each run \n",
    "                                 formatted_scenario) \n",
    "    animal_gain_output = generate_response_turbo(system_message, ##change for each run \n",
    "                                                user_message, .7, 1) \n",
    "    prompt, response, temperature, top_p = animal_gain_output[0]  \n",
    "    frame = 'gain_animal' \n",
    "    model = 'gpt-3.5-turbo'\n",
    "    test = ##add in test\n",
    "    num_calls = 34 ## matches to qual exp.  \n",
    "    animal_gain_turbo.append({'prompt': prompt, 'response': response, 'temperature': temperature,'top_p': top_p, 'test': test, 'model': model, 'frame': frame, 'num_calls': num_calls})\n",
    "\n",
    "\n",
    "## Forest Gain\n",
    "##forest_gain\t35\n",
    "forest_gain_turbo = []\n",
    "for i in range(35):\n",
    "    formatted_scenario = format_scenario(gain_forest)  \n",
    "    user_message = format_prompt(user_message, ##change for each run \n",
    "                                 formatted_scenario) \n",
    "    forest_gain_output = generate_response_turbo(system_message, ##change for each run \n",
    "                                                user_message, .7, 1) \n",
    "    prompt, response, temperature, top_p = forest_gain_output[0]  \n",
    "    frame = 'gain_forest'  \n",
    "    test = ##add in test\n",
    "    test = ['combo 1A', 'system_message_baseline1', 'user_message_baseline1', 'system role']\n",
    "    num_calls = 35 ## matches to qual exp.  \n",
    "    forest_gain_turbo.append({'prompt': prompt, 'response': response, 'temperature': temperature,'top_p': top_p, 'test': test, 'model': model, 'frame': frame, 'num_calls': num_calls})\n",
    "\n",
    "## Forest Loss\n",
    "##forest_loss 28\n",
    "forest_loss_turbo = []\n",
    "for i in range(28):\n",
    "    formatted_scenario = format_scenario(loss_forest) \n",
    "    user_message = format_prompt(user_message, ##change for each run \n",
    "                                 formatted_scenario) \n",
    "    forest_loss_output = generate_response_turbo(system_message, ##change for each run \n",
    "                                                user_message, .7, 1) \n",
    "    prompt, response, temperature, top_p = forest_loss_output[0]  \n",
    "    frame = 'loss_forest' \n",
    "    test = ##add in test\n",
    "    num_calls = 28 ## matches to qual exp.  \n",
    "    forest_loss_turbo.append({'prompt': prompt, 'response': response, 'temperature': temperature,'top_p': top_p, 'test': test, 'model': model, 'frame': frame, 'num_calls': num_calls})\n",
    "\n",
    "\n",
    "## Append CSV File for multi call model version \n",
    "\n",
    "with open(csv_file_path, 'a', newline='') as file:\n",
    "    fieldnames = ['prompt', 'response', 'temperature', 'top_p', 'test', 'model', 'frame', 'num_calls']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    \n",
    "\n",
    "    for response_data in human_loss_turbo:\n",
    "        writer.writerow({\n",
    "            'prompt': response_data['prompt'],\n",
    "            'response': response_data['response'],\n",
    "            'temperature': response_data['temperature'],\n",
    "            'top_p': response_data['top_p'],\n",
    "            'test': response_data['test'],     \n",
    "            'model': response_data['model'],   \n",
    "            'frame': response_data['frame'],\n",
    "            'num_calls': response_data['num_calls']\n",
    "\n",
    "        })\n",
    "\n",
    "    for response_data in human_gain_turbo:\n",
    "        writer.writerow({\n",
    "            'prompt': response_data['prompt'],\n",
    "            'response': response_data['response'],\n",
    "            'temperature': response_data['temperature'],\n",
    "            'top_p': response_data['top_p'],\n",
    "            'test': response_data['test'],      \n",
    "            'model': response_data['model'],    \n",
    "            'frame': response_data['frame'],\n",
    "            'num_calls': response_data['num_calls']\n",
    "        })\n",
    "\n",
    "    for response_data in animal_gain_turbo:\n",
    "            writer.writerow({\n",
    "            'prompt': response_data['prompt'],\n",
    "            'response': response_data['response'],\n",
    "            'temperature': response_data['temperature'],\n",
    "            'top_p': response_data['top_p'],\n",
    "            'test': response_data['test'],      \n",
    "            'model': response_data['model'],    \n",
    "            'frame': response_data['frame'],\n",
    "            'num_calls': response_data['num_calls']\n",
    "        })\n",
    "    for response_data in animal_loss_turbo:\n",
    "        writer.writerow({\n",
    "            'prompt': response_data['prompt'],\n",
    "            'response': response_data['response'],\n",
    "            'temperature': response_data['temperature'],\n",
    "            'top_p': response_data['top_p'],\n",
    "            'test': response_data['test'],     \n",
    "            'model': response_data['model'],   \n",
    "            'frame': response_data['frame'],\n",
    "            'num_calls': response_data['num_calls']\n",
    "        })\n",
    "\n",
    "    for response_data in forest_gain_turbo:\n",
    "            writer.writerow({\n",
    "            'prompt': response_data['prompt'],\n",
    "            'response': response_data['response'],\n",
    "            'temperature': response_data['temperature'],\n",
    "            'top_p': response_data['top_p'],\n",
    "            'test': response_data['test'],      \n",
    "            'model': response_data['model'],    \n",
    "            'frame': response_data['frame'],\n",
    "            'num_calls': response_data['num_calls']\n",
    "        })\n",
    "    for response_data in forest_loss_turbo:\n",
    "        writer.writerow({\n",
    "            'prompt': response_data['prompt'],\n",
    "            'response': response_data['response'],\n",
    "            'temperature': response_data['temperature'],\n",
    "            'top_p': response_data['top_p'],\n",
    "            'test': response_data['test'],     \n",
    "            'model': response_data['model'],   \n",
    "            'frame': response_data['frame'],\n",
    "            'num_calls': response_data['num_calls']\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Data \n",
    "gpt3_run = csv_file_path\n",
    "df_gpt3 = pd.read_csv(gpt3_run)\n",
    "\n",
    "## Cleaning\n",
    "##info on prompt\n",
    "df_gpt3[['frame', 'scenario']] = df_gpt3['frame'].str.split('_', n=1, expand=True)\n",
    "pattern2 = r'Scenario:(.*?)Questions'\n",
    "df_gpt3['scenario_text'] = df_gpt3['prompt'].str.extract(pattern2,  flags=re.DOTALL)\n",
    "\n",
    "## Clean json \n",
    "# import json \n",
    "def clean_json(x):\n",
    "    x = x.strip(\"'\")  # remove leading/trailing single quotes\n",
    "    x = x.strip(\"\\n\")  # remove leading/trailing newline characters\n",
    "    x = x.encode('utf-8', 'ignore').decode('utf-8')  # ignore non utf-8 characters\n",
    "    x = re.sub(r'\"\\s*\"', '\",\"', x)  # replace spaces between quotes with commas\n",
    "    #replace incorrect JSON keys with correct keys\n",
    "    for key in [\"Q1_Response\", \"Q2_Response\", \"Q3_Response\"]:\n",
    "        x = re.sub(f'(?<=[{{,])\\s*{key}\\s*(?=:)', f' \"{key}\"', x)\n",
    "    # make sure quotes \n",
    "    x = re.sub(r':\\s*([0-9]+)\\s*(?=[,}])', r': \"\\1\"', x)\n",
    "\n",
    "    # cleaning steps\n",
    "    x = x.replace('Q1_response','Q1_Response')\n",
    "    x = x.replace('Q2_response','Q2_Response')\n",
    "    x = x.replace('Q3_response','Q3_Response')\n",
    "    x = x.replace('it\"s', 'it\\'s')\n",
    "    x = x.replace('B\"s', \"B's\")\n",
    "    x = x.replace(\"}, {\", \",\")\n",
    "    x = x.replace(\"},{\", \",\")\n",
    "    x = x.replace(\".}\", '.\"}')\n",
    "    x = x.replace('\"}\" }', '\"}')\n",
    "\n",
    "    for proposal in [\"Proposal A\", \"Proposal B\"]:\n",
    "        x = re.sub(f'(?<=:)\\s*{proposal}(?=\\s*[^\"]\\w*,)', f' \"{proposal}\"', x)\n",
    "    x = re.sub(r'}\\s*{', ', ', x)\n",
    "    if not x.startswith('{'):\n",
    "        x = '{' + x\n",
    "    if not x.endswith('}'):\n",
    "        x = x + '}'\n",
    "    try:\n",
    "        x = x.replace('\\n', ' ')\n",
    "        x = json.dumps(json.loads(x))\n",
    "    except json.JSONDecodeError:\n",
    "        return x\n",
    "    return x\n",
    "\n",
    "df_gpt3['response'] = df_gpt3['response'].apply(clean_json)\n",
    "responses = df_gpt3.apply(lambda x: pd.Series(json.loads(x['response'])), axis=1, result_type='expand')\n",
    "df_gpt3 = pd.concat([df_gpt3, responses], axis = 1)\n",
    "df_gpt3 = df_gpt3.reset_index()\n",
    "df_gpt3['Q1_Response']  = df_gpt3['Q1_Response'].apply(lambda x: 'Proposal B' if x == 'Option B' else x)\n",
    "df_gpt3['Q1_Response']  = df_gpt3['Q1_Response'].apply(lambda x: 'Proposal A' if x == 'Option A' else x)\n",
    "\n",
    "## Save File \n",
    "df_gpt3.to_csv('/Users/annaking/Documents/Github/riskychoiceframing_AI/Experiment 1/analysis/df_gpt3_testing_072623.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
