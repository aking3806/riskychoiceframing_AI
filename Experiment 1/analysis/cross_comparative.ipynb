{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "le = preprocessing.LabelEncoder()\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt3 = \"/Users/annaking/Documents/Github/riskychoiceframing_AI/Experiment 1/analysis/df_gpt3.csv\"\n",
    "df_gpt3 = pd.read_csv(gpt3)\n",
    "df_gpt3['source'] = 'AI'\n",
    "humans = \"/Users/annaking/Documents/Github/riskychoiceframing_AI/Experiment 1/analysis/experimentone_results.csv\"\n",
    "df_hum = pd.read_csv(humans)\n",
    "df_hum['source'] = 'human'\n",
    "df_hum = df_hum.rename(columns={'scenario_clean':'scenario'})\n",
    "df_hum['frame_cat'] = le.fit_transform(df_hum['frame']) ##0 = gain, 1 = loss\n",
    "df_hum['frame_rev'] = 1 - df_hum['frame_cat'] ##1 = gain, 0 = loss\n",
    "df_hum['option_selected_cat'] = le.fit_transform(df_hum['option_selected']) ##0 = Prop A, 1 = Prop B\n",
    "df_hum['option_selected_rev'] = 1 - df_hum['option_selected_cat'] ##1 = Prop A, 0 = Prop B\n",
    "df_combined = pd.concat([df_hum, df_gpt3],axis = 0 ,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.scenario = df_combined.scenario.str.replace('humans', 'human')\n",
    "df_combined.scenario = df_combined.scenario.str.replace('humanss', 'human')\n",
    "df_combined.scenario = df_combined.scenario.str.replace('humans', 'human')\n",
    "df_combined.scenario = df_combined.scenario.str.replace('animals', 'animal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">rating_num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AI</th>\n",
       "      <td>3.821429</td>\n",
       "      <td>2.109995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>human</th>\n",
       "      <td>3.321782</td>\n",
       "      <td>1.639203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rating_num          \n",
       "             mean       std\n",
       "source                     \n",
       "AI       3.821429  2.109995\n",
       "human    3.321782  1.639203"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.groupby('source').agg({'rating_num':['mean', 'std']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -3.2222477325933605\n",
      "p-value: 0.001298415641651965\n"
     ]
    }
   ],
   "source": [
    "##chi-square for option selected \n",
    "contingency_table = pd.crosstab(df_combined['source'], df_combined['option_selected'])\n",
    "chi, pval, _, _ = stats.chi2_contingency(contingency_table)\n",
    "chi, pval\n",
    "\n",
    "##fix this \n",
    "human_ratings = df_combined[df_combined['source'] == 'human']['rating_num']\n",
    "ai_ratings = df_combined[df_combined['source'] == 'AI']['rating_num']\n",
    "t_stat, p_val = ttest_ind(human_ratings, ai_ratings)\n",
    "print(\"t-statistic:\", t_stat)\n",
    "print(\"p-value:\", p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for signficance \n",
    "def sig_effect(pvalue):\n",
    "    if pvalue <= .01:\n",
    "        return f\"\"\"significant at 1% level\"\"\"\n",
    "    elif pvalue <= .05:\n",
    "        return f\"\"\"significant at 5% level\"\"\"\n",
    "    elif pvalue <= .1:\n",
    "        return f\"\"\"significant at 10% level\"\"\"\n",
    "    else:\n",
    "        return \"not significant\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['frame_gain'] = (df_combined['frame'] == 'gain').astype(int) # gain asreference \n",
    "df_combined['source_AI'] = pd.get_dummies(df_combined['source'], drop_first=True) #AI as reference\n",
    "\n",
    "##assumption of equal variance \n",
    "##could affect power \n",
    "##issues with confounding \n",
    "\n",
    "##caveat --> why this was better strategy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.647341\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>option_selected_rev</td> <th>  No. Observations:  </th>  <td>  1546</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>Logit</td>        <th>  Df Residuals:      </th>  <td>  1543</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                  <td>MLE</td>         <th>  Df Model:          </th>  <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 11 Aug 2023</td>   <th>  Pseudo R-squ.:     </th>  <td>0.02589</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:25:07</td>       <th>  Log-Likelihood:    </th> <td> -1000.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>              <td>True</td>         <th>  LL-Null:           </th> <td> -1027.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>      <th>  LLR p-value:       </th> <td>2.819e-12</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>             <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>         <td>    0.7876</td> <td>    0.080</td> <td>    9.902</td> <td> 0.000</td> <td>    0.632</td> <td>    0.944</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>source_AI[T.True]</th> <td>    0.4871</td> <td>    0.167</td> <td>    2.920</td> <td> 0.003</td> <td>    0.160</td> <td>    0.814</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>frame_gain</th>        <td>   -0.7117</td> <td>    0.107</td> <td>   -6.661</td> <td> 0.000</td> <td>   -0.921</td> <td>   -0.502</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}     & option\\_selected\\_rev & \\textbf{  No. Observations:  } &     1546    \\\\\n",
       "\\textbf{Model:}             &         Logit         & \\textbf{  Df Residuals:      } &     1543    \\\\\n",
       "\\textbf{Method:}            &          MLE          & \\textbf{  Df Model:          } &        2    \\\\\n",
       "\\textbf{Date:}              &    Fri, 11 Aug 2023   & \\textbf{  Pseudo R-squ.:     } &  0.02589    \\\\\n",
       "\\textbf{Time:}              &        11:25:07       & \\textbf{  Log-Likelihood:    } &   -1000.8   \\\\\n",
       "\\textbf{converged:}         &          True         & \\textbf{  LL-Null:           } &   -1027.4   \\\\\n",
       "\\textbf{Covariance Type:}   &       nonrobust       & \\textbf{  LLR p-value:       } & 2.819e-12   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                            & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}          &       0.7876  &        0.080     &     9.902  &         0.000        &        0.632    &        0.944     \\\\\n",
       "\\textbf{source\\_AI[T.True]} &       0.4871  &        0.167     &     2.920  &         0.003        &        0.160    &        0.814     \\\\\n",
       "\\textbf{frame\\_gain}        &      -0.7117  &        0.107     &    -6.661  &         0.000        &       -0.921    &       -0.502     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            Logit Regression Results                           \n",
       "===============================================================================\n",
       "Dep. Variable:     option_selected_rev   No. Observations:                 1546\n",
       "Model:                           Logit   Df Residuals:                     1543\n",
       "Method:                            MLE   Df Model:                            2\n",
       "Date:                 Fri, 11 Aug 2023   Pseudo R-squ.:                 0.02589\n",
       "Time:                         11:25:07   Log-Likelihood:                -1000.8\n",
       "converged:                        True   LL-Null:                       -1027.4\n",
       "Covariance Type:             nonrobust   LLR p-value:                 2.819e-12\n",
       "=====================================================================================\n",
       "                        coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "Intercept             0.7876      0.080      9.902      0.000       0.632       0.944\n",
       "source_AI[T.True]     0.4871      0.167      2.920      0.003       0.160       0.814\n",
       "frame_gain           -0.7117      0.107     -6.661      0.000      -0.921      -0.502\n",
       "=====================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Simple Model\n",
    "logit_model = smf.logit('option_selected_rev ~ frame_gain + source_AI', df_combined).fit()\n",
    "logit_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.620867\n",
      "         Iterations 5\n",
      "frame p-vale: 2.483177736339205e-09\n",
      "\n",
      "signficicant effect? -->  significant at 1% level\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>option_selected_rev</td> <th>  No. Observations:  </th>  <td>  1546</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>Logit</td>        <th>  Df Residuals:      </th>  <td>  1541</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                  <td>MLE</td>         <th>  Df Model:          </th>  <td>     4</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 11 Aug 2023</td>   <th>  Pseudo R-squ.:     </th>  <td>0.06572</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:25:17</td>       <th>  Log-Likelihood:    </th> <td> -959.86</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>              <td>True</td>         <th>  LL-Null:           </th> <td> -1027.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>      <th>  LLR p-value:       </th> <td>3.241e-28</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>          <td>   -0.7623</td> <td>    0.127</td> <td>   -5.986</td> <td> 0.000</td> <td>   -1.012</td> <td>   -0.513</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>frame[T.loss]</th>      <td>    0.6553</td> <td>    0.110</td> <td>    5.963</td> <td> 0.000</td> <td>    0.440</td> <td>    0.871</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>source[T.human]</th>    <td>    0.5842</td> <td>    0.201</td> <td>    2.904</td> <td> 0.004</td> <td>    0.190</td> <td>    0.978</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scenario[T.forest]</th> <td>    1.4744</td> <td>    0.386</td> <td>    3.815</td> <td> 0.000</td> <td>    0.717</td> <td>    2.232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scenario[T.human]</th>  <td>    1.1148</td> <td>    0.131</td> <td>    8.488</td> <td> 0.000</td> <td>    0.857</td> <td>    1.372</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}     & option\\_selected\\_rev & \\textbf{  No. Observations:  } &     1546    \\\\\n",
       "\\textbf{Model:}             &         Logit         & \\textbf{  Df Residuals:      } &     1541    \\\\\n",
       "\\textbf{Method:}            &          MLE          & \\textbf{  Df Model:          } &        4    \\\\\n",
       "\\textbf{Date:}              &    Fri, 11 Aug 2023   & \\textbf{  Pseudo R-squ.:     } &  0.06572    \\\\\n",
       "\\textbf{Time:}              &        11:25:17       & \\textbf{  Log-Likelihood:    } &   -959.86   \\\\\n",
       "\\textbf{converged:}         &          True         & \\textbf{  LL-Null:           } &   -1027.4   \\\\\n",
       "\\textbf{Covariance Type:}   &       nonrobust       & \\textbf{  LLR p-value:       } & 3.241e-28   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                            & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}          &      -0.7623  &        0.127     &    -5.986  &         0.000        &       -1.012    &       -0.513     \\\\\n",
       "\\textbf{frame[T.loss]}      &       0.6553  &        0.110     &     5.963  &         0.000        &        0.440    &        0.871     \\\\\n",
       "\\textbf{source[T.human]}    &       0.5842  &        0.201     &     2.904  &         0.004        &        0.190    &        0.978     \\\\\n",
       "\\textbf{scenario[T.forest]} &       1.4744  &        0.386     &     3.815  &         0.000        &        0.717    &        2.232     \\\\\n",
       "\\textbf{scenario[T.human]}  &       1.1148  &        0.131     &     8.488  &         0.000        &        0.857    &        1.372     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            Logit Regression Results                           \n",
       "===============================================================================\n",
       "Dep. Variable:     option_selected_rev   No. Observations:                 1546\n",
       "Model:                           Logit   Df Residuals:                     1541\n",
       "Method:                            MLE   Df Model:                            4\n",
       "Date:                 Fri, 11 Aug 2023   Pseudo R-squ.:                 0.06572\n",
       "Time:                         11:25:17   Log-Likelihood:                -959.86\n",
       "converged:                        True   LL-Null:                       -1027.4\n",
       "Covariance Type:             nonrobust   LLR p-value:                 3.241e-28\n",
       "======================================================================================\n",
       "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "Intercept             -0.7623      0.127     -5.986      0.000      -1.012      -0.513\n",
       "frame[T.loss]          0.6553      0.110      5.963      0.000       0.440       0.871\n",
       "source[T.human]        0.5842      0.201      2.904      0.004       0.190       0.978\n",
       "scenario[T.forest]     1.4744      0.386      3.815      0.000       0.717       2.232\n",
       "scenario[T.human]      1.1148      0.131      8.488      0.000       0.857       1.372\n",
       "======================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_reg = smf.logit('option_selected_rev ~ frame + source + scenario', df_combined).fit()\n",
    "print(\"frame p-vale:\", logit_reg.pvalues[1])\n",
    "print(\"\\nsignficicant effect? --> \", sig_effect(logit_reg.pvalues[1]))\n",
    "logit_reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.612555\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>option_selected_rev</td> <th>  No. Observations:  </th>  <td>  1546</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>Logit</td>        <th>  Df Residuals:      </th>  <td>  1538</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                  <td>MLE</td>         <th>  Df Model:          </th>  <td>     7</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 10 Aug 2023</td>   <th>  Pseudo R-squ.:     </th>  <td>0.07823</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>05:40:43</td>       <th>  Log-Likelihood:    </th> <td> -947.01</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>              <td>True</td>         <th>  LL-Null:           </th> <td> -1027.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>      <th>  LLR p-value:       </th> <td>2.233e-31</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                   <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                     <td>   -0.9500</td> <td>    0.137</td> <td>   -6.943</td> <td> 0.000</td> <td>   -1.218</td> <td>   -0.682</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>frame[T.loss]</th>                 <td>    0.8105</td> <td>    0.118</td> <td>    6.855</td> <td> 0.000</td> <td>    0.579</td> <td>    1.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>source[T.human]</th>               <td>    1.6374</td> <td> 7.84e+06</td> <td> 2.09e-07</td> <td> 1.000</td> <td>-1.54e+07</td> <td> 1.54e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scenario[T.animals]</th>           <td>    0.2242</td> <td> 7.84e+06</td> <td> 2.86e-08</td> <td> 1.000</td> <td>-1.54e+07</td> <td> 1.54e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scenario[T.forest]</th>            <td>    1.1384</td> <td> 7.84e+06</td> <td> 1.45e-07</td> <td> 1.000</td> <td>-1.54e+07</td> <td> 1.54e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scenario[T.human]</th>             <td>    1.2610</td> <td>    0.143</td> <td>    8.839</td> <td> 0.000</td> <td>    0.981</td> <td>    1.541</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scenario[T.humans]</th>            <td>    0.2748</td> <td> 7.84e+06</td> <td> 3.51e-08</td> <td> 1.000</td> <td>-1.54e+07</td> <td> 1.54e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>frame[T.loss]:source[T.human]</th> <td>   -1.3675</td> <td>    0.340</td> <td>   -4.025</td> <td> 0.000</td> <td>   -2.033</td> <td>   -0.702</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                & option\\_selected\\_rev & \\textbf{  No. Observations:  } &     1546    \\\\\n",
       "\\textbf{Model:}                        &         Logit         & \\textbf{  Df Residuals:      } &     1538    \\\\\n",
       "\\textbf{Method:}                       &          MLE          & \\textbf{  Df Model:          } &        7    \\\\\n",
       "\\textbf{Date:}                         &    Thu, 10 Aug 2023   & \\textbf{  Pseudo R-squ.:     } &  0.07823    \\\\\n",
       "\\textbf{Time:}                         &        05:40:43       & \\textbf{  Log-Likelihood:    } &   -947.01   \\\\\n",
       "\\textbf{converged:}                    &          True         & \\textbf{  LL-Null:           } &   -1027.4   \\\\\n",
       "\\textbf{Covariance Type:}              &       nonrobust       & \\textbf{  LLR p-value:       } & 2.233e-31   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                       & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                     &      -0.9500  &        0.137     &    -6.943  &         0.000        &       -1.218    &       -0.682     \\\\\n",
       "\\textbf{frame[T.loss]}                 &       0.8105  &        0.118     &     6.855  &         0.000        &        0.579    &        1.042     \\\\\n",
       "\\textbf{source[T.human]}               &       1.6374  &     7.84e+06     &  2.09e-07  &         1.000        &    -1.54e+07    &     1.54e+07     \\\\\n",
       "\\textbf{scenario[T.animals]}           &       0.2242  &     7.84e+06     &  2.86e-08  &         1.000        &    -1.54e+07    &     1.54e+07     \\\\\n",
       "\\textbf{scenario[T.forest]}            &       1.1384  &     7.84e+06     &  1.45e-07  &         1.000        &    -1.54e+07    &     1.54e+07     \\\\\n",
       "\\textbf{scenario[T.human]}             &       1.2610  &        0.143     &     8.839  &         0.000        &        0.981    &        1.541     \\\\\n",
       "\\textbf{scenario[T.humans]}            &       0.2748  &     7.84e+06     &  3.51e-08  &         1.000        &    -1.54e+07    &     1.54e+07     \\\\\n",
       "\\textbf{frame[T.loss]:source[T.human]} &      -1.3675  &        0.340     &    -4.025  &         0.000        &       -2.033    &       -0.702     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            Logit Regression Results                           \n",
       "===============================================================================\n",
       "Dep. Variable:     option_selected_rev   No. Observations:                 1546\n",
       "Model:                           Logit   Df Residuals:                     1538\n",
       "Method:                            MLE   Df Model:                            7\n",
       "Date:                 Thu, 10 Aug 2023   Pseudo R-squ.:                 0.07823\n",
       "Time:                         05:40:43   Log-Likelihood:                -947.01\n",
       "converged:                        True   LL-Null:                       -1027.4\n",
       "Covariance Type:             nonrobust   LLR p-value:                 2.233e-31\n",
       "=================================================================================================\n",
       "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------\n",
       "Intercept                        -0.9500      0.137     -6.943      0.000      -1.218      -0.682\n",
       "frame[T.loss]                     0.8105      0.118      6.855      0.000       0.579       1.042\n",
       "source[T.human]                   1.6374   7.84e+06   2.09e-07      1.000   -1.54e+07    1.54e+07\n",
       "scenario[T.animals]               0.2242   7.84e+06   2.86e-08      1.000   -1.54e+07    1.54e+07\n",
       "scenario[T.forest]                1.1384   7.84e+06   1.45e-07      1.000   -1.54e+07    1.54e+07\n",
       "scenario[T.human]                 1.2610      0.143      8.839      0.000       0.981       1.541\n",
       "scenario[T.humans]                0.2748   7.84e+06   3.51e-08      1.000   -1.54e+07    1.54e+07\n",
       "frame[T.loss]:source[T.human]    -1.3675      0.340     -4.025      0.000      -2.033      -0.702\n",
       "=================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_reg = smf.logit('option_selected_rev ~ frame * source, df_combined).fit()\n",
    "logit_reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Pandas data cast to numpy dtype of object. Check input data with np.asarray(data).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 12\u001b[0m\n\u001b[1;32m      7\u001b[0m X \u001b[39m=\u001b[39m sm\u001b[39m.\u001b[39madd_constant(X)  \u001b[39m# Adds a constant (intercept) to your predictor variables\u001b[39;00m\n\u001b[1;32m     10\u001b[0m y_option \u001b[39m=\u001b[39m df_combined[\u001b[39m'\u001b[39m\u001b[39moption_selected\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> 12\u001b[0m model_option \u001b[39m=\u001b[39m sm\u001b[39m.\u001b[39;49mLogit(y_option, X)\u001b[39m.\u001b[39mfit()\n\u001b[1;32m     13\u001b[0m \u001b[39mprint\u001b[39m(model_option\u001b[39m.\u001b[39msummary())\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/discrete/discrete_model.py:475\u001b[0m, in \u001b[0;36mBinaryModel.__init__\u001b[0;34m(self, endog, exog, offset, check_rank, **kwargs)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, endog, exog, offset\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_rank\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    473\u001b[0m     \u001b[39m# unconditional check, requires no extra kwargs added by subclasses\u001b[39;00m\n\u001b[1;32m    474\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_kwargs(kwargs)\n\u001b[0;32m--> 475\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(endog, exog, offset\u001b[39m=\u001b[39;49moffset, check_rank\u001b[39m=\u001b[39;49mcheck_rank,\n\u001b[1;32m    476\u001b[0m                      \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    477\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m, MultinomialModel):\n\u001b[1;32m    478\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39mall((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendog \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m) \u001b[39m&\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendog \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/discrete/discrete_model.py:185\u001b[0m, in \u001b[0;36mDiscreteModel.__init__\u001b[0;34m(self, endog, exog, check_rank, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, endog, exog, check_rank\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    184\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_rank \u001b[39m=\u001b[39m check_rank\n\u001b[0;32m--> 185\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(endog, exog, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    186\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraise_on_perfect_prediction \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# keep for backwards compat\u001b[39;00m\n\u001b[1;32m    187\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_extra \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/base/model.py:270\u001b[0m, in \u001b[0;36mLikelihoodModel.__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, endog, exog\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 270\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(endog, exog, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    271\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialize()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/base/model.py:95\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m missing \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mmissing\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     94\u001b[0m hasconst \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mhasconst\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m---> 95\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_data(endog, exog, missing, hasconst,\n\u001b[1;32m     96\u001b[0m                               \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_constant \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mk_constant\n\u001b[1;32m     98\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexog \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mexog\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/base/model.py:135\u001b[0m, in \u001b[0;36mModel._handle_data\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_handle_data\u001b[39m(\u001b[39mself\u001b[39m, endog, exog, missing, hasconst, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 135\u001b[0m     data \u001b[39m=\u001b[39m handle_data(endog, exog, missing, hasconst, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    136\u001b[0m     \u001b[39m# kwargs arrays could have changed, easier to just attach here\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m kwargs:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/base/data.py:675\u001b[0m, in \u001b[0;36mhandle_data\u001b[0;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    672\u001b[0m     exog \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(exog)\n\u001b[1;32m    674\u001b[0m klass \u001b[39m=\u001b[39m handle_data_class_factory(endog, exog)\n\u001b[0;32m--> 675\u001b[0m \u001b[39mreturn\u001b[39;00m klass(endog, exog\u001b[39m=\u001b[39;49mexog, missing\u001b[39m=\u001b[39;49mmissing, hasconst\u001b[39m=\u001b[39;49mhasconst,\n\u001b[1;32m    676\u001b[0m              \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/base/data.py:84\u001b[0m, in \u001b[0;36mModelData.__init__\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39morig_endog \u001b[39m=\u001b[39m endog\n\u001b[1;32m     83\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39morig_exog \u001b[39m=\u001b[39m exog\n\u001b[0;32m---> 84\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendog, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexog \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_endog_exog(endog, exog)\n\u001b[1;32m     86\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconst_idx \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_constant \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/base/data.py:509\u001b[0m, in \u001b[0;36mPandasData._convert_endog_exog\u001b[0;34m(self, endog, exog)\u001b[0m\n\u001b[1;32m    507\u001b[0m exog \u001b[39m=\u001b[39m exog \u001b[39mif\u001b[39;00m exog \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m np\u001b[39m.\u001b[39masarray(exog)\n\u001b[1;32m    508\u001b[0m \u001b[39mif\u001b[39;00m endog\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m \u001b[39mor\u001b[39;00m exog \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m exog\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m:\n\u001b[0;32m--> 509\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPandas data cast to numpy dtype of object. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    510\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mCheck input data with np.asarray(data).\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    511\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m(PandasData, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m_convert_endog_exog(endog, exog)\n",
      "\u001b[0;31mValueError\u001b[0m: Pandas data cast to numpy dtype of object. Check input data with np.asarray(data)."
     ]
    }
   ],
   "source": [
    "# Convert categorical variables into dummy/indicator variables. We'll use 'AI' as our reference group.\n",
    "df_combined['frame'] = pd.get_dummies(df_combined['frame'], drop_first=True) # Assuming 'Loss' as reference\n",
    "#####df_combined['scenario'] = pd.get_dummies(df_combined['scenario'], drop_first=True) # Assume one scenario, e.g., 'Animals', as reference\n",
    "df_combined['source'] = pd.get_dummies(df_combined['source'], drop_first=True) # 'AI' as reference\n",
    "\n",
    "X = df_combined[['frame', 'source']]\n",
    "X = sm.add_constant(X)  # Adds a constant (intercept) to your predictor variables\n",
    "\n",
    "\n",
    "y_option = df_combined['option_selected']\n",
    "\n",
    "model_option = sm.Logit(y_option, X).fit()\n",
    "print(model_option.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m y_option \u001b[39m=\u001b[39m df_combined[\u001b[39m'\u001b[39m\u001b[39moption_selected\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m model_option \u001b[39m=\u001b[39m sm\u001b[39m.\u001b[39mLogit(y_option, X)\u001b[39m.\u001b[39mfit()\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(model_option\u001b[39m.\u001b[39msummary())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "y_option = df_combined['option_selected']\n",
    "X = 'frame'\n",
    "model_option = sm.Logit(y_option, X).fit()\n",
    "print(model_option.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
