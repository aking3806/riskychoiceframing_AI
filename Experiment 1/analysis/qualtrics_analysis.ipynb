{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pycountry-convert --quiet\n",
    "#pip install seaborn  --quiet\n",
    "#pip install scipy --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(141, 97)\n"
     ]
    }
   ],
   "source": [
    "csv_file = \"/Users/annaking/Documents/Github/riskychoiceframing_AI/Experiment 1/data/Dissertation - Risky Choice Framing_July 18, 2023_08.57.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['StartDate', 'EndDate', 'Status', 'Progress', 'Duration (in seconds)',\n",
       "       'Finished', 'RecordedDate', 'ResponseId', 'DistributionChannel',\n",
       "       'UserLanguage', 'Q_RecaptchaScore', 'Q1. Metadata_Browser',\n",
       "       'Q1. Metadata_Version', 'Q1. Metadata_Operating System',\n",
       "       'Q1. Metadata_Resolution', 'Q2. Time_First Click',\n",
       "       'Q2. Time_Last Click', 'Q2. Time_Page Submit', 'Q2. Time_Click Count',\n",
       "       'Q3. Consent', 'Q10. GS1, Time_First Click',\n",
       "       'Q10. GS1, Time_Last Click', 'Q10. GS1, Time_Page Submit',\n",
       "       'Q10. GS1, Time_Click Count', 'Q12. GS1, Option', 'Q13. GS1, Rating',\n",
       "       'Q13. GS1, Rationale', 'Q10. GS2, Time_First Click',\n",
       "       'Q10. GS2, Time_Last Click', 'Q10. GS2, Time_Page Submit',\n",
       "       'Q10. GS2, Time_Click Count', 'Q12. GS2, Option', 'Q13. GS2, Rating',\n",
       "       'Q14. GS2, Rationale', 'Q10. GS3, Time_First Click',\n",
       "       'Q10. GS3, Time_Last Click', 'Q10. GS3, Time_Page Submit',\n",
       "       'Q10. GS3, Time_Click Count', 'Q12. GS3, Option.', 'Q13. GS3, Rating',\n",
       "       'Q14. GS3, Rationle', 'Q10. LS1, Time_First Click',\n",
       "       'Q10. LS1, Time_Last Click', 'Q10. LS1, Time_Page Submit',\n",
       "       'Q10. LS1, Time_Click Count', 'Q12. LS1, Option', 'Q13. LS1, Rating',\n",
       "       'Q14. LS1, Rationale', 'Q10. LS2, Time_First Click',\n",
       "       'Q10. LS2, Time_Last Click', 'Q10. LS2, Time_Page Submit',\n",
       "       'Q10. LS2, Time_Click Count', 'Q12. LS2, Option', 'Q13. LS2, Rating',\n",
       "       'Q14. LS2, Rationale', 'Q10. LS3, Time_First Click',\n",
       "       'Q10. LS3, Time_Last Click', 'Q10. LS3, Time_Page Submit',\n",
       "       'Q10. LS3, Time_Click Count', 'Q12. LS3, Option', 'Q13. LS3, Rating',\n",
       "       'Q14. LS3, Rationale', 'Q34_First Click', 'Q34_Last Click',\n",
       "       'Q34_Page Submit', 'Q34_Click Count', 'Q. NEP_1', 'Q. NEP_2',\n",
       "       'Q. NEP_3', 'Q. NEP_4', 'Q. NEP_5', 'Q. NEP_6', 'Q. NEP_7', 'Q. NEP_8',\n",
       "       'Q4. Dem, Time1_First Click', 'Q4. Dem, Time1_Last Click',\n",
       "       'Q4. Dem, Time1_Page Submit', 'Q4. Dem, Time1_Click Count', 'Q5. Age',\n",
       "       'Q6. Gender', 'Q6. Gender_4_TEXT', 'Q8. Ethnicity',\n",
       "       'Q8. Ethnicity_6_TEXT', 'Q7. Dem, Time2_First Click',\n",
       "       'Q7. Dem, Time2_Last Click', 'Q7. Dem, Time2_Page Submit',\n",
       "       'Q7. Dem, Time2_Click Count', 'Q9. Education', 'Q10. Country',\n",
       "       'Q10. Student', 'Q91', 'Q62', 'Q62_2_TEXT', 'Q63', 'Q63_2_TEXT', 'Q61',\n",
       "       'Condition'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 141 entries, 0 to 140\n",
      "Data columns (total 97 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   StartDate                      141 non-null    object \n",
      " 1   EndDate                        141 non-null    object \n",
      " 2   Status                         141 non-null    object \n",
      " 3   Progress                       141 non-null    int64  \n",
      " 4   Duration (in seconds)          141 non-null    int64  \n",
      " 5   Finished                       141 non-null    bool   \n",
      " 6   RecordedDate                   141 non-null    object \n",
      " 7   ResponseId                     141 non-null    object \n",
      " 8   DistributionChannel            141 non-null    object \n",
      " 9   UserLanguage                   141 non-null    object \n",
      " 10  Q_RecaptchaScore               133 non-null    float64\n",
      " 11  Q1. Metadata_Browser           141 non-null    object \n",
      " 12  Q1. Metadata_Version           141 non-null    object \n",
      " 13  Q1. Metadata_Operating System  141 non-null    object \n",
      " 14  Q1. Metadata_Resolution        141 non-null    object \n",
      " 15  Q2. Time_First Click           141 non-null    float64\n",
      " 16  Q2. Time_Last Click            141 non-null    float64\n",
      " 17  Q2. Time_Page Submit           141 non-null    float64\n",
      " 18  Q2. Time_Click Count           141 non-null    int64  \n",
      " 19  Q3. Consent                    141 non-null    object \n",
      " 20  Q10. GS1, Time_First Click     23 non-null     float64\n",
      " 21  Q10. GS1, Time_Last Click      23 non-null     float64\n",
      " 22  Q10. GS1, Time_Page Submit     23 non-null     float64\n",
      " 23  Q10. GS1, Time_Click Count     23 non-null     float64\n",
      " 24  Q12. GS1, Option               23 non-null     object \n",
      " 25  Q13. GS1, Rating               23 non-null     object \n",
      " 26  Q13. GS1, Rationale            14 non-null     object \n",
      " 27  Q10. GS2, Time_First Click     23 non-null     float64\n",
      " 28  Q10. GS2, Time_Last Click      23 non-null     float64\n",
      " 29  Q10. GS2, Time_Page Submit     23 non-null     float64\n",
      " 30  Q10. GS2, Time_Click Count     23 non-null     float64\n",
      " 31  Q12. GS2, Option               23 non-null     object \n",
      " 32  Q13. GS2, Rating               23 non-null     object \n",
      " 33  Q14. GS2, Rationale            23 non-null     object \n",
      " 34  Q10. GS3, Time_First Click     16 non-null     float64\n",
      " 35  Q10. GS3, Time_Last Click      16 non-null     float64\n",
      " 36  Q10. GS3, Time_Page Submit     16 non-null     float64\n",
      " 37  Q10. GS3, Time_Click Count     16 non-null     float64\n",
      " 38  Q12. GS3, Option.              16 non-null     object \n",
      " 39  Q13. GS3, Rating               16 non-null     object \n",
      " 40  Q14. GS3, Rationle             13 non-null     object \n",
      " 41  Q10. LS1, Time_First Click     23 non-null     float64\n",
      " 42  Q10. LS1, Time_Last Click      23 non-null     float64\n",
      " 43  Q10. LS1, Time_Page Submit     23 non-null     float64\n",
      " 44  Q10. LS1, Time_Click Count     23 non-null     float64\n",
      " 45  Q12. LS1, Option               23 non-null     object \n",
      " 46  Q13. LS1, Rating               23 non-null     object \n",
      " 47  Q14. LS1, Rationale            21 non-null     object \n",
      " 48  Q10. LS2, Time_First Click     21 non-null     float64\n",
      " 49  Q10. LS2, Time_Last Click      21 non-null     float64\n",
      " 50  Q10. LS2, Time_Page Submit     21 non-null     float64\n",
      " 51  Q10. LS2, Time_Click Count     21 non-null     float64\n",
      " 52  Q12. LS2, Option               21 non-null     object \n",
      " 53  Q13. LS2, Rating               21 non-null     object \n",
      " 54  Q14. LS2, Rationale            17 non-null     object \n",
      " 55  Q10. LS3, Time_First Click     23 non-null     float64\n",
      " 56  Q10. LS3, Time_Last Click      23 non-null     float64\n",
      " 57  Q10. LS3, Time_Page Submit     23 non-null     float64\n",
      " 58  Q10. LS3, Time_Click Count     23 non-null     float64\n",
      " 59  Q12. LS3, Option               23 non-null     object \n",
      " 60  Q13. LS3, Rating               23 non-null     object \n",
      " 61  Q14. LS3, Rationale            17 non-null     object \n",
      " 62  Q34_First Click                129 non-null    float64\n",
      " 63  Q34_Last Click                 129 non-null    float64\n",
      " 64  Q34_Page Submit                129 non-null    float64\n",
      " 65  Q34_Click Count                129 non-null    float64\n",
      " 66  Q. NEP_1                       128 non-null    object \n",
      " 67  Q. NEP_2                       128 non-null    object \n",
      " 68  Q. NEP_3                       128 non-null    object \n",
      " 69  Q. NEP_4                       128 non-null    object \n",
      " 70  Q. NEP_5                       128 non-null    object \n",
      " 71  Q. NEP_6                       128 non-null    object \n",
      " 72  Q. NEP_7                       128 non-null    object \n",
      " 73  Q. NEP_8                       128 non-null    object \n",
      " 74  Q4. Dem, Time1_First Click     129 non-null    float64\n",
      " 75  Q4. Dem, Time1_Last Click      129 non-null    float64\n",
      " 76  Q4. Dem, Time1_Page Submit     129 non-null    float64\n",
      " 77  Q4. Dem, Time1_Click Count     129 non-null    float64\n",
      " 78  Q5. Age                        129 non-null    object \n",
      " 79  Q6. Gender                     127 non-null    object \n",
      " 80  Q6. Gender_4_TEXT              1 non-null      object \n",
      " 81  Q8. Ethnicity                  127 non-null    object \n",
      " 82  Q8. Ethnicity_6_TEXT           0 non-null      float64\n",
      " 83  Q7. Dem, Time2_First Click     129 non-null    float64\n",
      " 84  Q7. Dem, Time2_Last Click      129 non-null    float64\n",
      " 85  Q7. Dem, Time2_Page Submit     129 non-null    float64\n",
      " 86  Q7. Dem, Time2_Click Count     129 non-null    float64\n",
      " 87  Q9. Education                  127 non-null    object \n",
      " 88  Q10. Country                   124 non-null    object \n",
      " 89  Q10. Student                   127 non-null    object \n",
      " 90  Q91                            124 non-null    object \n",
      " 91  Q62                            122 non-null    object \n",
      " 92  Q62_2_TEXT                     0 non-null      float64\n",
      " 93  Q63                            122 non-null    object \n",
      " 94  Q63_2_TEXT                     2 non-null      object \n",
      " 95  Q61                            64 non-null     object \n",
      " 96  Condition                      129 non-null    float64\n",
      "dtypes: bool(1), float64(43), int64(3), object(50)\n",
      "memory usage: 106.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126, 98)\n"
     ]
    }
   ],
   "source": [
    "##### Data cleaning to change column types\n",
    "\n",
    "#drop anyone now sorted into condition \n",
    "df_clean = df.drop(df[df['Condition'].isna()].index)\n",
    "\n",
    "#change data type to int \n",
    "df_clean['Condition'] =  df_clean['Condition'].astype('int64')\n",
    "\n",
    "# create frame column gain or loss condition based on condition value \n",
    "df_clean['frame'] = df_clean['Condition'].apply(lambda x: 'gain' if x < 3 else 'loss')\n",
    "\n",
    "#filter only where progress = 100 \n",
    "df_clean = df_clean[df_clean['Progress']==100]\n",
    "print(df_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116, 98)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## survey timing & outlier removal \n",
    "\n",
    "## visual completion times \n",
    "#sns.histplot( y='Duration (in seconds)', data =df_clean)\n",
    "#plt.show()\n",
    "\n",
    "#look at completion times \n",
    "df_clean['Duration (in seconds)'].describe()\n",
    "\n",
    "def remove_outliers(df, column_name):\n",
    "    # Calculate Z-scores for the column\n",
    "    z_scores = stats.zscore(df[column_name])\n",
    "    threshold = 3 #3 standard deviations \n",
    "    # Filter the dataframe to keep only the data within the threshold\n",
    "    df_clean = df[abs(z_scores) < threshold]\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "#apply function to remove outliers \n",
    "column_name = 'Duration (in seconds)'\n",
    "df_clean = remove_outliers(df_clean, column_name) \n",
    "\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### check for NAs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mapping Columns & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "##### Option Column Cleaning\n",
    "# select option columns \n",
    "df_clean['option_selected'] = df_clean[['Q12. GS1, Option','Q12. GS2, Option', 'Q12. GS3, Option.', 'Q12. LS1, Option', 'Q12. LS2, Option', 'Q12. LS3, Option']].fillna(method='ffill', axis=1).iloc[:, -1]\n",
    "option_columns = ['Q12. GS1, Option','Q12. GS2, Option', 'Q12. GS3, Option.', 'Q12. LS1, Option', 'Q12. LS2, Option', 'Q12. LS3, Option']\n",
    "\n",
    "#rating column clean & creation \n",
    "rating_columns = ['Q13. GS1, Rating','Q13. GS2, Rating', 'Q13. GS3, Rating', 'Q13. LS1, Rating', 'Q13. LS2, Rating', 'Q13. LS3, Rating']\n",
    "df_clean['rating'] = df_clean[rating_columns].fillna(method='ffill', axis=1).iloc[:, -1]\n",
    "df_clean['rating_num'] = df_clean['rating'].apply(lambda x: x.split(\":\")[0])\n",
    "\n",
    "#rationale column cleaning\n",
    "rationale_columns = ['Q13. GS1, Rationale','Q14. GS2, Rationale', 'Q14. GS3, Rationle', 'Q14. LS1, Rationale', 'Q14. LS2, Rationale', 'Q14. LS3, Rationale']\n",
    "df_clean['rationale'] = df_clean[rationale_columns].fillna(method='ffill', axis=1).iloc[:, -1]\n",
    "\n",
    "##### drop standalone choice, rationale, and rating columns\n",
    "colu = rationale_columns + option_columns + rating_columns\n",
    "df_clean = df_clean.drop(colu, axis= 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Creating columns and grouping for various scenarios:\n",
    "# dictionary mapping\n",
    "scenario_dict = {\"GS1\":\"animals_gain\", \"GS2\":\"forest_gain\", \"GS3\":\"humans_gain\", \"LS1\":\"animals_loss\", \"LS2\":\"forest_loss\", \"LS3\":\"humans_loss\"  }\n",
    "\n",
    "#set columns based on scenario \n",
    "def scenario(row):\n",
    "    for col in selected_columns:\n",
    "        if pd.notnull(row[col]):\n",
    "            match = re.search(r'(GS\\d+|LS\\d+)', col)\n",
    "            if match:\n",
    "                return match.group()\n",
    "    return None\n",
    "# get scenario from dictionary \n",
    "def get_scenario(row):\n",
    "    value = row['scenario']\n",
    "    if value in scenario_dict:\n",
    "        return scenario_dict[value]\n",
    "    return None\n",
    "# match scenario to dict\n",
    "df_clean['scenario'] = df_clean[['Q12. GS1, Option','Q12. GS2, Option', 'Q12. GS3, Option.', 'Q12. LS1, Option', 'Q12. LS2, Option', 'Q12. LS3, Option']].apply(lambda row: scenario(row), axis=1)\n",
    "df_clean['scenario_mapped'] = df_clean.apply(lambda row: get_scenario(row), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116, 76)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Cleaning and dropping time columns ###\n",
    "columns = list(df_clean.columns)\n",
    "\n",
    "###  First click columns\n",
    "time_click1 = [col for col in columns if 'first click' in col.lower()]\n",
    "#time first click for the scenario \n",
    "time_click1_scn = [string for string in time_click1 if string.startswith('Q10')]\n",
    "#make as 1 column \n",
    "df_clean['scn_t_first_click'] = df_clean[time_click1_scn].fillna(method='ffill', axis=1).iloc[:, -1]\n",
    "\n",
    "### Last click columns\n",
    "time_click2 = [col for col in columns if 'last click' in col.lower()]\n",
    "time_click2_scn = [string for string in time_click2 if string.startswith('Q10')]\n",
    "df_clean['scn_t_last_click'] = df_clean[time_click2_scn].fillna(method='ffill', axis=1).iloc[:, -1]\n",
    "\n",
    "### Time Submit Scenario columns\n",
    "time_submit = [col for col in columns if 'submit' in col.lower()]\n",
    "time_submit_scn = [string for string in time_submit if string.startswith('Q10')]\n",
    "df_clean['scn_t_submit'] = df_clean[time_submit_scn].fillna(method='ffill', axis=1).iloc[:, -1]\n",
    "\n",
    "#click_count1_scn = [string for string in click_count1 if 'dem' in string.lower()]\n",
    "\n",
    "## drop Q10 time columns \n",
    "columns_drop = time_click2_scn + time_click1_scn + time_submit_scn\n",
    "df_clean = df_clean.drop(columns_drop, axis = 'columns')\n",
    "\n",
    "##Click count cleaning \n",
    "columns = list(df_clean.columns)\n",
    "## Click Count for Scenario \n",
    "click_count1 = [col for col in columns if 'click count' in col.lower()]\n",
    "#filer only scenario click coun t\n",
    "click_count_scn = [string for string in click_count1 if string.startswith('Q10')]\n",
    "#make as 1 column for all scenarios \n",
    "df_clean['scn_click_count'] = df_clean[click_count_scn].fillna(method='ffill', axis=1).iloc[:, -1]\n",
    "\n",
    "## Click Count for Scenario \n",
    "click_count = [col for col in columns if 'click count' in col.lower()]\n",
    "click_count1_dem = [string for string in click_count if 'dem' in string.lower()]\n",
    "df_clean['dem_click_count'] = df_clean[click_count1_dem].fillna(method='ffill', axis=1).iloc[:, -1]\n",
    "\n",
    "# drop scenario and dem click count columns \n",
    "columns_drop = click_count_scn + click_count1_dem\n",
    "df_clean = df_clean.drop(columns_drop, axis = 'columns')\n",
    "\n",
    "### drop metadata or misc columns from analysis \n",
    "metadata_or_misc = ['Q1. Metadata_Browser','Q1. Metadata_Version', 'Q1. Metadata_Operating System','Q1. Metadata_Resolution', 'UserLanguage', 'DistributionChannel', 'Status']\n",
    "df_clean = df_clean.drop(metadata_or_misc, axis = 'columns')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns \n",
    "df_clean = df_clean.rename(columns={\n",
    "    'Q5. Age': 'age',\n",
    "    'Q6. Gender': 'gender',\n",
    "    'Q6. Gender_4_TEXT': 'gender_text',\n",
    "    'Q8. Ethnicity': 'ethnicity',\n",
    "    'Q8. Ethnicity_6_TEXT': 'ethnicity_text',\n",
    "    'Q9. Education': 'education',\n",
    "    'Q10. Country': 'country',\n",
    "    'Q10. Student': 'student',\n",
    "    'Q91': 'ADP_familiar'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "###coutry name clean \n",
    "import pycountry_convert as pc\n",
    "\n",
    "#function to rename messy countries\n",
    "def rename_countries(country):\n",
    "    if pd.isnull(country):  # Check if the value is nan\n",
    "        return country\n",
    "    if country in ['United States of America', 'USA', 'US', 'us', 'usa', 'America', 'America   ', 'the United States', 'The United States',  'United States ', 'Amrican', 'United States', 'Florida', 'New York', 'MA', 'NZ', 'North Carolina', 'Newyork', 'denver']:\n",
    "        return 'USA'\n",
    "    elif country in ['United Kingdom', 'United Kingdom ', 'UK', 'England', 'England ', 'Cambridge', 'London', 'uuk', 'the Netherlands']:\n",
    "        return 'UK'\n",
    "    elif country in ['China', '中国', 'Chinese ', '美国','加州']:\n",
    "        return 'China'\n",
    "    elif country in [ 'New Zealand']:\n",
    "        return 'New Zealand'\n",
    "    elif country in ['Paris, France', 'France']:\n",
    "        return 'France'\n",
    "    elif country in ['Australia', 'Australia ']:\n",
    "        return 'Australia'\n",
    "    elif country in ['pakistan']:\n",
    "        return 'Pakistan'\n",
    "    else:\n",
    "        return country  # return the original name if no match is found\n",
    "\n",
    "#update country column \n",
    "df_clean['country'] = df_clean['country'].apply(rename_countries)\n",
    "#strip any remaining whitespaces\n",
    "df_clean['country'] = df_clean['country'].apply(lambda x: x.strip() if isinstance(x, str) else x) #checks if string, then removes spaces \n",
    "\n",
    "# Map each country to the continent\n",
    "def country_to_continent(country_name):\n",
    "    try:\n",
    "        if country_name == 'USA':\n",
    "            country_alpha2 = \"US\"\n",
    "        elif country_name == 'UK':\n",
    "            country_alpha2 = \"GB\"\n",
    "        else:\n",
    "            country_alpha2 = pc.country_name_to_country_alpha2(country_name)\n",
    "        country_continent_code = pc.country_alpha2_to_continent_code(country_alpha2)\n",
    "        country_continent_name = pc.convert_continent_code_to_continent_name(country_continent_code)\n",
    "        return country_continent_name\n",
    "    except:\n",
    "        return \"Unknown\"\n",
    "\n",
    "df_clean['continent'] = df_clean['country'].apply(country_to_continent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Cat Code Variables #########\n",
    "\n",
    "# ####Gender: clean gender column into numbers\n",
    "#0 if female, 1 if male, 2 if non-binary \n",
    "df_clean['gender_num'] = df_clean.gender.apply(lambda x: 0 if x == 'Female' else (1 if x == 'Male' else 2))\n",
    "df_clean.groupby(['gender','gender_num'])['ResponseId'].count()\n",
    "\n",
    "####Student: clean student column into numbers\n",
    "#0 if not a student, 1 if a student\n",
    "df_clean['student_num']= df_clean.student.astype('category').cat.codes\n",
    "df_clean.groupby(['student','student_num'])['ResponseId'].count()\n",
    "\n",
    "####Education: clean education column into numbers\n",
    "#education_num: 0 = Associates, 1 = Bachecholars, 2 = Completed High School, 3 = Grad School, 4 = Prefer Not to Say, 5 = Some high school \n",
    "df_clean['education_num']= df_clean.education.astype('category').cat.codes\n",
    "df_clean.groupby(['education','education_num'])['ResponseId'].count()\n",
    "\n",
    "#### Ethnicity: clean ethnicity column into numbers\n",
    "#ethnicity: 0 = African American, 1 = Black/African/Caribbean, 2 = Prefer not to say, 3 = White or Caucasian\n",
    "df_clean['ethnicity_num']= df_clean.ethnicity.astype('category').cat.codes\n",
    "df_clean.groupby(['ethnicity','ethnicity_num'])['ResponseId'].count()\n",
    "\n",
    "#### Continent: clean contintent column into numbers\n",
    "#continent: 0 = Asia, 1 = Europe, 2 = North America, 3 = Oceania, 4 = South America, 5 = Unknown \n",
    "df_clean['contintent_num']= df_clean.continent.astype('category').cat.codes\n",
    "df_clean.groupby(['continent','contintent_num'])['ResponseId'].count()\n",
    "\n",
    "#### ADP: lean ADP column into numbers\n",
    "#ADP: 0 = I'm not sure, 1 = No, 2 = Yes \n",
    "df_clean['ADP_num']= df_clean.ADP_familiar.astype('category').cat.codes\n",
    "df_clean.groupby(['ADP_familiar','ADP_num'])['ResponseId'].count()\n",
    "\n",
    "#### Age: clean age column into numbers\n",
    "#age: {'18 - 24 years old': 0, '25 - 34 years old': 1, '35 - 44 years old': 2, '45 - 54 years old': 3, '55 - 64 years old': 4}\n",
    "age_order = ['18 - 24 years old', '25 - 34 years old', '35 - 44 years old', '45 - 54 years old', '55 - 64 years old']\n",
    "age_mapping = {age: i for i, age in enumerate(age_order)}\n",
    "df_clean['age_num'] = df_clean['age'].map(age_mapping) #maps dict \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "school NA: 1\n",
      "gender NA: 1\n",
      "education NA: 1\n",
      "ADP NA: 4\n"
     ]
    }
   ],
   "source": [
    "## Check for NA values \n",
    "#print(df_clean[['age_num','age']].isna().value_counts())\n",
    "#print(df_clean['education'].isna().value_counts())\n",
    "#print('\\n\\n',df_clean['ADP_num'].isna().value_counts())\n",
    "#df_clean['ADP_familiar'].isna().count()\n",
    "\n",
    "print(f\"\"\"school NA: {df_clean['student'].isna().sum()}\"\"\")\n",
    "print(f\"\"\"gender NA: {df_clean['gender'].isna().sum()}\"\"\")\n",
    "print(f\"\"\"education NA: {df_clean['education'].isna().sum()}\"\"\")\n",
    "print(f\"\"\"ADP NA: {df_clean['ADP_familiar'].isna().sum()}\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demographic Insights "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defintions\n",
    "- gender_num: 0 = female, 1 = male, 2 = other\n",
    "- student_num: 0 = not a studnet, 1 = a student, -1 = NA\n",
    "- education_num: 0 = Associates, 1 = Bachecholars, 2 = Completed High School, 3 = Grad School, 4 = Prefer Not to Say, 5 = Some high school \n",
    "- ethnicity: 0 = African American, 1 = Black/African/Caribbean, 2 = Prefer not to say, 3 = White or Caucasian\n",
    "- continent: 0 = Asia, 1 = Europe, 2 = North America, 3 = Oceania, 4 = South America, 5 = Unknown \n",
    "- ADP: 0 = I'm not sure, 1 = No, 2 = Yes \n",
    "- age: {'18 - 24 years old': 0, '25 - 34 years old': 1, '35 - 44 years old': 2, '45 - 54 years old': 3, '55 - 64 years old': 4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Participant Demographic Insights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ethnicity\n",
       "White or Caucasian         0.709677\n",
       "Asian                      0.153226\n",
       "Black/African/Caribbean    0.129032\n",
       "Prefer not to say          0.008065\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Participant Demographic Insights \n",
    "demographics =   [ 'ResponseId','gender_num', 'gender', 'student_num', 'student','education_num', 'education','ethnicity_num','ethnicity', 'contintent_num', 'continent','age_num', 'age', 'ADP_num', 'ADP_familiar'] \n",
    "df_demographics = df_clean[demographics]\n",
    "\n",
    "#ethnicity\n",
    "print(df_demographics.ethnicity.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education\n",
       "Bachelor's degree                                                   0.379032\n",
       "Graduate or professional degree (MA, MS, MBA, PHd, JD, MD, etc.)    0.241935\n",
       "Associates or technical degree                                      0.209677\n",
       "Completed high school / secondary school                            0.120968\n",
       "Some high school / secondary school or less                         0.040323\n",
       "Prefer not to say                                                   0.008065\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Demographic Insights \n",
    "#df_clean.education.value_counts(normalize = True)\n",
    "#df_clean.groupby(['education_num','frame']).ResponseId.agg(['count', 'sum', 'mean','median'])\n",
    "#ed = df_clean.groupby(['education_num','frame']).ResponseId.count().reset_index()\n",
    "#pivoted = ed.pivot(index='education_num', columns='frame', values='ResponseId')\n",
    "#df_clean[['education_num','frame']].value_counts(normalize =True)\n",
    "\n",
    "#df_clean.groupby('continent').ResponseId.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>frame</th>\n",
       "      <th>gain</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>28</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non-binary / third gender</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prefer not to say</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prefer to self-describe</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "frame                      gain  loss\n",
       "gender                               \n",
       "Female                       28    25\n",
       "Male                         28    38\n",
       "Non-binary / third gender     2     1\n",
       "Prefer not to say             1     0\n",
       "Prefer to self-describe       1     0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_cross_tab = pd.crosstab(df_clean['gender'], df_clean['frame'])\n",
    "cross_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.groupby(['age', 'age_num'])['ResponseId'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frame  scenario  scenario_mapped  option_selected\n",
       "gain   GS1       animals_gain     Proposal A         16\n",
       "                                  Proposal B          7\n",
       "       GS2       forest_gain      Proposal A         20\n",
       "                                  Proposal B          3\n",
       "       GS3       humans_gain      Proposal A         12\n",
       "                                  Proposal B          4\n",
       "loss   LS1       animals_loss     Proposal A         13\n",
       "                                  Proposal B         10\n",
       "       LS2       forest_loss      Proposal A         16\n",
       "                                  Proposal B          5\n",
       "       LS3       humans_loss      Proposal A         14\n",
       "                                  Proposal B          9\n",
       "Name: ResponseId, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summary insights \n",
    "df_clean.groupby(['frame','scenario','scenario_mapped','option_selected']).ResponseId.count()\n",
    "\n",
    "#% in each condition (gain or loss)\n",
    "df_clean['frame'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADP question \n",
    "df_clean['Q91'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
