{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File Set-Up & Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import csv\n",
    "import pandas as pd\n",
    "API_KEY = \"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\" \n",
    "openai.api_key = API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Instructions & Basic Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from this experiment: https://osf.io/r2gyc?view_only=45fff3953884443d81b628cdd5d50f7a\n",
    "####instructions = \"Your task is to answer a survey question. Given the survey question, return the [blank] replaced with your answer. The [blank] should be replaced with only a single capitalized alphabet letter, and nothing more. For example, if you choose choice A, you should replace '[blank]' with 'A' and end the line immediately afterwards. Do your task step by step and only then return the completed survey question.\\n\\n\\n\\nSURVEY QUESTION:\\n\\nPlease read the following information carefully. Then, answer the question below.\\n\\nImagine that you are in a large lecture with a few hundred students and you are sitting in the middle section, a little more than half-way back in the room. The professor asks a question about the readings, but no one raises his or her hand to answer. You have done the reading and feel confident that the professor would like your answer, but prefer not to volunteer answers in large classes. The class sits in silence for two minutes before the professor explains that if no one volunteers, he will choose someone.\\n\\nHow likely do you believe it is that the professor will call on you?\\nA: Not at all Likely 1\\nB: 2\\nC: 3\\nD: 4\\nE: 5\\nF: 6\\nG: 7\\nH: 8\\nI: 9\\nJ: Extremely Likely 10\\n\\nQuestion 1 (Multiple choice):\\n[blank]\\n\\n\\n\\nCHECKLIST FOR SURVEY ANSWER:\\n\\nDid you replace [blank] with your response?\\nIs your response exactly one capitalized letter long (A, B, C, D, E, F, G, H, I, or J) with no further explanations or symbols?\\n\\n\\n\\nSURVEY ANSWER:\\n\\nQuestion 1 (Multiple choice):\\n\"\n",
    "##come back to \n",
    "\n",
    "\n",
    "#Variation wording \n",
    "#You are a participant in a consumer survey. You will be partaking in a short survey on the effect of advertising messages on consumers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Survey Consent\n",
    "\"\"\"This study seeks to better understand risk preferences and general, related attitudes. In this study, you will be presented with a hypothetical scenario, requiring a choice between two options. You will then be asked a few general questions regarding risk and general attitudes and preferences. There are no right or wrong answers.\"\"\"\n",
    "\n",
    "## Qualtrics: \n",
    "\"\"\"Part 1: Scenario\\nInstructions: read the scenario below and then answer the questions.\"\"\"\n",
    "\n",
    "##Question 3 wording: \"Briefly describe the rationale for your preference rating\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####  Instruction Prompts \n",
    "## no format request in beginning\n",
    "human_agent_risk = \"\"\"You are a human participant in a survey, capable of making decisions and choices. You are responding to a survey with the same risk preferences as a human participant would.\\nReview the hypothetical scenario. Then, answer the questions.\\n\"\"\"\n",
    "human_participant_risk=\"\"\"You are a human participant in a survey. You are responding to a survey with the same risk preferences as a human participant would.\\nReview the hypothetical scenario. Then, answer the questions.\\n\"\"\"\n",
    "human_participant_knowledge=\"\"\"You are a human participant in a survey. You are responding to a survey with the same risk preferences as a human participant would. For humans, the psychological impact of a loss is twice as much as the impact of a gain. \\nReview the hypothetical scenario. Then, answer the questions.\\n\"\"\"\n",
    "human_participant_knowledge_2=\"\"\"You are a human participant in a survey. You are responding to a survey with the same risk preferences as a human participant would. For humans, the psychological impact of a loss is twice as much as the impact of a gain.\\nReview the hypothetical scenario. Then, answer the questions.\\n\"\"\"\n",
    "\n",
    "\n",
    "human_participant_survey=\"\"\"You are a human participant in a survey. You are participating in a survey on risk attitudes.\\nReview the hypothetical scenario below. Then, answer the questions.\\n\"\"\"\n",
    "##human_agent = \"\"\"You are a human agent capable of making decisions. You are responding to a survey with the same risk preferences as a human pariticpant would with the characteristics described below.\"\"\"\n",
    "\n",
    "\n",
    "#print(human_agent_risk)\n",
    "#print(f\"\"\"\\n{human_participant_risk}\"\"\")\n",
    "#print(f\"\"\"\\n{human_participant_knowledge}\"\"\")\n",
    "#print(f\"\"\"\\n{human_participant_survey}\"\"\")\n",
    "\n",
    "\n",
    "##Look at \n",
    "##'indication of what survey is on'\n",
    "\n",
    "##### System Messages & Instruction Prompts -- with demographics endowed \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Questions (Archive) ####\n",
    "## Tested but likley will not use \n",
    "\n",
    "#only two questions; Which proposal do you prefer? \n",
    "rating_and_rationle =  \"\"\"\\n---\\nQuestions:\\n- Question 1: On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), which Proposal do you prefer?\\n1: Strong Preference for Proposal A\\n2: Preference for Proposal A\\n3: Slight Preference for Proposal A\\n4: No Preference for Proposal A or B\\n5: Slight Preference for Proposal B\\n6: Preference for Proposal B\\n7: Strong Preference for Proposal B\\n- Question 2: Describe your rationale.\\n---\\n\\nProvide your response in a JSON format with the following keys: Q1_Answer, Q2_Answer.\\nAnswer:\"\"\"\n",
    "\n",
    "#three questions, written out \n",
    "three_questions_ = \"\"\"\\n---\\nQuestions:\\nQuestion 1: Please choose an option: \\n- Proposal A \\n- Proposal B \\nQuestion 2: On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), which option do you prefer?\\n1: Strong Preference for Proposal A\\n2: Preference for Proposal A\\n3: Slight Preference for Proposal A\\n4: No Preference for Proposal A or B\\n5: Slight Preference for Proposal B\\n6: Preference for Proposal B\\n7: Strong Preference for Proposal B\\nQuestion 3: Describe your rationale.\\n---\\n\\nProvide your response in a JSON format with the following keys: Q1_Answer, Q2_Answer, Q3_Answer.\\nAnswer:\"\"\"\n",
    "\n",
    "#with 1. instead of Question 1: ; 2. rate your preference \n",
    "three_questions_number = \"\"\"\\n---\\nQuestions:\\n1. Please choose an option:\\n- Proposal A \\n- Proposal B \\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected: \\n1: Strong Preference for Proposal A\\n2: Preference for Proposal A\\n3: Slight Preference for Proposal A\\n4: No Preference for Proposal A or B\\n5: Slight Preference for Proposal B\\n6: Preference for Proposal B\\n7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n---\\n\\nProvide your response in a JSON format with the following keys: Q1_Answer, Q2_Answer, Q3_Answer.\\nResponse:\"\"\"\n",
    "\n",
    "#with Q1_Response ; 2. rate your preference \n",
    "three_questions_number_response =  \"\"\"\\n---\\nQuestions:\\n1. Please choose an option: \\n- Proposal A \\n- Proposal B \\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected: \\n1: Strong Preference for Proposal A\\n2: Preference for Proposal A\\n3: Slight Preference for Proposal A\\n4: No Preference for Proposal A or B\\n5: Slight Preference for Proposal B\\n6: Preference for Proposal B\\n7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n---\\n\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response.\\nResponse:\"\"\"\n",
    "\n",
    "\n",
    "print(f\"\"\"rating_and_rationle: {rating_and_rationle}\"\"\")\n",
    "print(f\"\"\"three_questions_: {three_questions_}\"\"\")\n",
    "print(f\"\"\"three_questions_number: {three_questions_number}\"\"\")\n",
    "print(f\"\"\"three_questions_number_response: {three_questions_number_response}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Questions ####\n",
    "\n",
    "#with JSON format example ; 2. rate your preference \n",
    "three_questions_number_json = \"\"\"\\n---\\nQuestions:\\n1. Please choose an option: \\n- Proposal A \\n- Proposal B \\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n1: Strong Preference for Proposal A\\n2: Preference for Proposal A\\n3: Slight Preference for Proposal A\\n4: No Preference for Proposal A or B\\n5: Slight Preference for Proposal B\\n6: Preference for Proposal B\\n7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n---\\n\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and format: '{\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}'. \\nResponse:\"\"\"\n",
    "\n",
    "#with bullet points for ratings  ; 2. rate your preference \n",
    "three_questions_number_bullets_vA = \"\"\"\\n---\\nQuestions:\\n1. Please choose an option: \\n- Proposal A \\n- Proposal B \\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n---\\n\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and format: '{\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}'. \\nResponses:\"\"\"\n",
    "three_questions_number_bullets_vA_2 = \"\"\"\\n\\nQuestions:\\n1. Please choose an option: \\n- Proposal A \\n- Proposal B \\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and format: '{\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}'. \\nResponses:\"\"\"\n",
    "##spacing changee \n",
    "three_questions_number_bullets_vA_3= \"\"\"\\n---\\nQuestions:\\n1. Please choose an option:\\n- Proposal A\\n- Proposal B\\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n---\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and format: '{\\\"Q1_Response\\\": \\\"Your Proposal Choice\\\", \\\"Q2_Response\\\": \\\"Your Rating\\\", \\\"Q3_Response\\\": \\\"Your Rationale.\\\"}'. \\n\\nResponses:\"\"\"\n",
    "three_questions_number_bullets_vA_4= \"\"\"\\n---\\nQuestions:\\n1. Please choose an option:\\n- Proposal A\\n- Proposal B\\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n---\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and format: '{\\\"Q1_Response\\\": \\\"Your Proposal Choice\\\", \\\"Q2_Response\\\": \\\"Your Rating\\\", \\\"Q3_Response\\\": \\\"Your Rationale.\\\"}'.\\n\\nResponses:\"\"\"\n",
    "\n",
    "\n",
    "three_questions_number_bullets_vB = \"\"\"\\n\\nQuestions:\\n1. Please choose an option: \\n- Proposal A \\n- Proposal B \\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and format: '{\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}'. \\nResponse:\"\"\"\n",
    "three_questions_number_bullets_vC = \"\"\"\\n---\\nQuestions:\\n1. Please choose an option: \\n- Proposal A \\n- Proposal B \\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n---\\n\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and format: '{\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}'. \\nResponse:\"\"\"\n",
    "\n",
    "three_questions_number_bullets_vD = \"\"\"\\n###\\nQuestions:\\n1. Please choose an option: \\n- Proposal A \\n- Proposal B \\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n###\\n\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and format: '{\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}'. \\nResponse:\"\"\"\n",
    "three_questions_number_bullets_vD_2 = \"\"\"\\n###\\nQuestions:\\n1. Please choose an option: \\n- Proposal A \\n- Proposal B \\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n###\\n\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and JSON format: '{\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}'. \\nResponse:\"\"\"\n",
    "three_questions_number_bullets_vD_3 = \"\"\"\\n###\\nQuestions:\\n1. Please choose an option: \\n- Proposal A \\n- Proposal B \\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n###\\n\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and JSON format: {\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}. \\nResponse:\"\"\"\n",
    "\n",
    "#print(f\"\"\"three_questions_number_json: {three_questions_number_json}\"\"\")\n",
    "#print(f\"\"\"three_questions_number_bullets: {three_questions_number_bullets}\"\"\")\n",
    "#print(f\"\"\"three_questions_number_bullets_vB: {three_questions_number_bullets_vB}\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### System Messages #####\n",
    "\n",
    "##base system prompt, human focused \n",
    "sys_prompt = \"\"\"You are a human participant in a survey, capable of making decisions and choices. You are responding to a survey with the same risk preferences as a human participant would. Your response should be in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and JSON format: {\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}.\"\"\"\n",
    "\n",
    "\n",
    "##### System Messages & Instruction Prompts -- with comma separated fields: \n",
    "system_prompts = [\n",
    "  'You are a human participant in a survey, capable of making decisions and choices.',\n",
    "  'You are responding to a survey with the same risk preferences as a human participant would.',\n",
    "  #'For humans, the psychological impact of a loss is twice as much as the impact of a gain.'\n",
    "  'Your response should be in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and JSON format: {\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}.'\n",
    "]\n",
    "\n",
    "\n",
    "##### User Prompt \n",
    "\n",
    "\n",
    "#prompt_dict = {idx:prompt for idx, prompt in enumerate(prompts)}\n",
    "#prompts_df = pd.DataFrame.from_dict(data = prompt_dict, orient = 'index', columns = ['prompt'])\n",
    "#pd.set_option('display.max_colwidth', None)\n",
    "#prompts_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demographic User Prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [],
   "source": [
    "#access participant demographics from experiment 1\n",
    "\n",
    "participant_demographics = pd.read_csv('participant_demographics.csv')\n",
    "participant_demographics\n",
    "participant_demographics['education'] = participant_demographics['education'].apply(lambda x: 'High School or Secondary School degree' if x == 'Completed high school / secondary school' \\\n",
    "                                                                                    else ('partial High School or Secondary School degree' if x =='Some high school / secondary school or less' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Participant Prompts\n",
    "\n",
    "#basic prompt to mirror above \n",
    "participant_prompt = f\"\"\"You are a {ethnicity} {gender} between {age} from {continent}. Your education level is a {education}. You are participating in a survey on risk attitudes.\\nReview the hypothetical scenario below. Then, answer the questions. Provide your response in a JSON format with the following keys: Q1_Answer, Q2_Answer, Q3_Answer.\\n\"\"\"\n",
    "\n",
    "#urge to consider background\n",
    "participant_prompt_background = f\"\"\"You are {ethnicity} {gender}between {age} from {continent}. Your education level is a {education}. You are participating in a survey on risk attitudes.\\nReview the hypothetical scenario below. Then, taking into account your background, answer the questions. Provide your response in a JSON format with the following keys: Q1_Answer, Q2_Answer, Q3_Answer.\\n\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Script for all Scenarios (Text Davinci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Writing as 1 script (For multiple Prompting)  #######\n",
    "\n",
    "#read in participant data from exp 1 \n",
    "participant_demographics = pd.read_csv('participant_demographics.csv')\n",
    "\n",
    "#create dataframes for each scenario condition\n",
    "#df for each group of participants\n",
    "forest_gain_dems = participant_demographics[participant_demographics['scenario_mapped'] == 'forest_gain' ]\n",
    "forest_loss_dems = participant_demographics[participant_demographics['scenario_mapped'] == 'forest_loss' ]\n",
    "\n",
    "human_gain_dems = participant_demographics[participant_demographics['scenario_mapped'] == 'humans_gain' ]\n",
    "human_loss_dems  = participant_demographics[participant_demographics['scenario_mapped'] == 'humans_loss' ]\n",
    "\n",
    "animal_gain_dems = participant_demographics[participant_demographics['scenario_mapped'] == 'animals_gain' ]\n",
    "animal_loss_dems = participant_demographics[participant_demographics['scenario_mapped'] == 'animals_loss' ]\n",
    "\n",
    "\n",
    "####### --- Prompt Combinations  --- #######\n",
    "##combo 1  \n",
    "p_prompt_1 = \"\"\"You are a {ethnicity} {gender} between {age} from {continent}. Your education level is a {education}.\"\"\"\n",
    "user_message_1 =  \"\"\"Thank you for taking the time to participate in this study. This study seeks to better understand risk preferences and general, related attitudes. In this study, you will be presented with a hypothetical scenario, requiring a choice between two options. There are no right or wrong answers.\\nInstructions: read the scenario below and then answer the questions.\\n{}\\n\\nQuestions:\\n1. Please choose an option:\\n- Proposal A\\n- Proposal B\\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Briefly describe the rationale for your preference rating:\\n\\nProvide your response as a JSON object. As an example: '{{\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}}'.\\n\\nResponse:\"\"\"\n",
    "\n",
    "## dynamic function for the scenario \n",
    "def format_scenario(scenario_text):\n",
    "    return scenario_text\n",
    "\n",
    "## dynamic function for the prompt \n",
    "def format_prompt(prompt_text, scenario):\n",
    "    return prompt_text.format(scenario)\n",
    "\n",
    "##set variables for the prompt\n",
    "\n",
    "##function to generate responses \n",
    "def generate_response(prompt, temperature, top_p):\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=90,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=temperature,\n",
    "        top_p = top_p\n",
    "    )\n",
    "    return [(prompt, choice.text.strip(), temperature, top_p) for choice in response.choices]\n",
    "\n",
    "####################### Alter VARIABLES  ####################### \n",
    "\n",
    "########## Forest Scenario ########## \n",
    "## Forest Gain \n",
    "forest_gain_responses = []\n",
    "\n",
    "for _, participant in forest_gain_dems.iterrows(): ##change with each\n",
    "    age = participant['age']\n",
    "    gender = participant['gender']\n",
    "    education = participant['education']\n",
    "    ethnicity = participant['ethnicity']\n",
    "    continent = participant['continent']\n",
    "    \n",
    "    formatted_scenario = format_scenario(gain_forest) #### change for each run \n",
    "    user_message = format_prompt(user_message_1, formatted_scenario) #### change for each run \n",
    "    full_prompt = p_prompt_1.format(age=age,gender=gender,ethnicity=ethnicity,education = education, continent=continent) + user_message\n",
    "\n",
    "    forest_gain = generate_response(full_prompt, 0, 1) \n",
    "        \n",
    "    full_prompt, response, temperature, top_p = forest_gain[0]\n",
    "    frame = 'forest_gain' ##change with each run \n",
    "    model = 'text-davinci-003' \n",
    "    test = ['combo 1', 'p_prompt_1', 'user_message_1']\n",
    "\n",
    "    forest_gain_responses.append({\n",
    "        'full_prompt': full_prompt, \n",
    "        'response': response, \n",
    "        'temperature': temperature,\n",
    "        'top_p': top_p, \n",
    "        'test': test, \n",
    "        'model': model, \n",
    "        'frame': frame, \n",
    "        'age': age,\n",
    "        'gender': gender,\n",
    "        'education': education,\n",
    "        'ethnicity': ethnicity,\n",
    "        'continent': continent\n",
    "        })\n",
    "    \n",
    "## Forest Loss \n",
    "forest_loss_responses = []\n",
    "for _, participant in forest_loss_dems.iterrows(): ##change with each\n",
    "    age = participant['age']\n",
    "    gender = participant['gender']\n",
    "    education = participant['education']\n",
    "    ethnicity = participant['ethnicity']\n",
    "    continent = participant['continent']\n",
    "    \n",
    "    formatted_scenario = format_scenario(loss_forest) #### change for each run \n",
    "    user_message = format_prompt(user_message_1, formatted_scenario) #### change for each run \n",
    "    full_prompt = p_prompt_1.format(age=age,gender=gender,ethnicity=ethnicity,education = education, continent=continent) + user_message\n",
    "\n",
    "    forest_loss = generate_response(full_prompt, 0, 1) \n",
    "        \n",
    "    full_prompt, response, temperature, top_p = forest_loss[0]\n",
    "    frame = 'forest_loss' ##change with each run \n",
    "    model = 'text-davinci-003' \n",
    "    test = ['combo 1', 'p_prompt_1', 'user_message_1']\n",
    "\n",
    "    forest_loss_responses.append({\n",
    "        'full_prompt': full_prompt, \n",
    "        'response': response, \n",
    "        'temperature': temperature,\n",
    "        'top_p': top_p, \n",
    "        'test': test, \n",
    "        'model': model, \n",
    "        'frame': frame, \n",
    "        'age': age,\n",
    "        'gender': gender,\n",
    "        'education': education,\n",
    "        'ethnicity': ethnicity,\n",
    "        'continent': continent\n",
    "        })\n",
    "\n",
    "########## Animal Scenario ########## \n",
    "\n",
    "## Animal Gain \n",
    "animal_gain_responses = []\n",
    "for _, participant in animal_gain_dems.iterrows(): ##change with each\n",
    "    age = participant['age']\n",
    "    gender = participant['gender']\n",
    "    education = participant['education']\n",
    "    ethnicity = participant['ethnicity']\n",
    "    continent = participant['continent']\n",
    "    \n",
    "    gain_animal_scn = format_scenario(gain_animal) #### change for each run \n",
    "    user_message = format_prompt(user_message_1, gain_animal_scn) #### change for each run \n",
    "    full_prompt = p_prompt_1.format(age=age,gender=gender,ethnicity=ethnicity,education = education, continent=continent) + user_message\n",
    "\n",
    "    animal_gain = generate_response(full_prompt, 0, 1) \n",
    "        \n",
    "    full_prompt, response, temperature, top_p = animal_gain[0]\n",
    "    frame = 'animal_gain' ##change with each run \n",
    "    model = 'text-davinci-003' \n",
    "    test = ['combo 1', 'p_prompt_1', 'user_message_1']\n",
    "\n",
    "    animal_gain_responses.append({\n",
    "        'full_prompt': full_prompt, \n",
    "        'response': response, \n",
    "        'temperature': temperature,\n",
    "        'top_p': top_p, \n",
    "        'test': test, \n",
    "        'model': model, \n",
    "        'frame': frame, \n",
    "        'age': age,\n",
    "        'gender': gender,\n",
    "        'education': education,\n",
    "        'ethnicity': ethnicity,\n",
    "        'continent': continent\n",
    "        })\n",
    "    \n",
    "## Animal Loss \n",
    "animal_loss_responses = []\n",
    "    \n",
    "for _, participant in animal_loss_dems.iterrows(): ##change with each\n",
    "    age = participant['age']\n",
    "    gender = participant['gender']\n",
    "    education = participant['education']\n",
    "    ethnicity = participant['ethnicity']\n",
    "    continent = participant['continent']\n",
    "    \n",
    "    formatted_scenario = format_scenario(loss_animal) #### change for each run \n",
    "    user_message = format_prompt(user_message_1, formatted_scenario) #### change for each run \n",
    "    full_prompt = p_prompt_1.format(age=age,gender=gender,ethnicity=ethnicity,education = education, continent=continent) + user_message\n",
    "\n",
    "    animal_loss = generate_response(full_prompt, 0, 1) \n",
    "        \n",
    "    full_prompt, response, temperature, top_p = animal_loss[0]\n",
    "    frame = 'animal_loss' ##change with each run \n",
    "    model = 'text-davinci-003' \n",
    "    test = ['combo 1', 'p_prompt_1', 'user_message_1']\n",
    "\n",
    "    animal_loss_responses.append({\n",
    "        'full_prompt': full_prompt, \n",
    "        'response': response, \n",
    "        'temperature': temperature,\n",
    "        'top_p': top_p, \n",
    "        'test': test, \n",
    "        'model': model, \n",
    "        'frame': frame, \n",
    "        'age': age,\n",
    "        'gender': gender,\n",
    "        'education': education,\n",
    "        'ethnicity': ethnicity,\n",
    "        'continent': continent\n",
    "        })\n",
    "\n",
    "########## Human Scenario ########## \n",
    "## Human Gain \n",
    "\n",
    "human_gain_responses = []\n",
    "for _, participant in human_gain_dems.iterrows(): ##change with each\n",
    "    age = participant['age']\n",
    "    gender = participant['gender']\n",
    "    education = participant['education']\n",
    "    ethnicity = participant['ethnicity']\n",
    "    continent = participant['continent']\n",
    "    \n",
    "    formatted_scenario = format_scenario(gain_human) #### change for each run \n",
    "    user_message = format_prompt(user_message_1, formatted_scenario) #### change for each run \n",
    "    full_prompt = p_prompt_1.format(age=age,gender=gender,ethnicity=ethnicity,education = education, continent=continent) + user_message\n",
    "\n",
    "    human_gain = generate_response(full_prompt, 0, 1) \n",
    "        \n",
    "    full_prompt, response, temperature, top_p = human_gain[0]\n",
    "    frame = 'human_gain' ##change with each run \n",
    "    model = 'text-davinci-003' \n",
    "    test = ['combo 1', 'p_prompt_1', 'user_message_1']\n",
    "\n",
    "    human_gain_responses.append({\n",
    "        'full_prompt': full_prompt, \n",
    "        'response': response, \n",
    "        'temperature': temperature,\n",
    "        'top_p': top_p, \n",
    "        'test': test, \n",
    "        'model': model, \n",
    "        'frame': frame, \n",
    "        'age': age,\n",
    "        'gender': gender,\n",
    "        'education': education,\n",
    "        'ethnicity': ethnicity,\n",
    "        'continent': continent\n",
    "        })\n",
    "    \n",
    "## Human Loss \n",
    "human_loss_responses = []\n",
    "for _, participant in human_loss_dems.iterrows(): ##change with each\n",
    "    age = participant['age']\n",
    "    gender = participant['gender']\n",
    "    education = participant['education']\n",
    "    ethnicity = participant['ethnicity']\n",
    "    continent = participant['continent']\n",
    "    \n",
    "    formatted_scenario = format_scenario(loss_human) #### change for each run \n",
    "    user_message = format_prompt(user_message_1, formatted_scenario) #### change for each run \n",
    "    full_prompt = p_prompt_1.format(age=age,gender=gender,ethnicity=ethnicity,education = education, continent=continent) + user_message\n",
    "\n",
    "    human_loss = generate_response(full_prompt, 0, 1) \n",
    "        \n",
    "    full_prompt, response, temperature, top_p = human_loss[0]\n",
    "    frame = 'human_loss' ##change with each run \n",
    "    model = 'text-davinci-003' \n",
    "    test = ['combo 1', 'p_prompt_1', 'user_message_1']\n",
    "\n",
    "    human_loss_responses.append({\n",
    "        'full_prompt': full_prompt, \n",
    "        'response': response, \n",
    "        'temperature': temperature,\n",
    "        'top_p': top_p, \n",
    "        'test': test, \n",
    "        'model': model, \n",
    "        'frame': frame, \n",
    "        'age': age,\n",
    "        'gender': gender,\n",
    "        'education': education,\n",
    "        'ethnicity': ethnicity,\n",
    "        'continent': continent\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Append\n",
    "csv_file_path = \"/Users/annaking/Documents/Github/riskychoiceframing_AI/Experiment 2/tests/participant_testing_080123_1run_v2.csv\"\n",
    "\n",
    "with open(csv_file_path, 'a', newline='') as file: \n",
    "    fieldnames = ['full_prompt', 'response', 'temperature', 'top_p', 'test', 'model', 'frame', 'age', 'gender', 'education', 'ethnicity', 'continent']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    #for data in forest_gain_responses:\n",
    "        #writer.writerow({\n",
    "          #  'full_prompt': response_data['full_prompt'], \n",
    "          #  'response': response_data['response'], \n",
    "          #  'temperature': response_data['temperature'],\n",
    "          #  'top_p': response_data['top_p'], \n",
    "          #  'test': response_data['test'], \n",
    "          #  'model': response_data['model'], \n",
    "          #  'frame': response_data['frame'], \n",
    "          #  'age': response_data['age'],\n",
    "          #  'gender': response_data['gender'],\n",
    "          #  'education': response_data['education'],\n",
    "          #  'ethnicity': response_data['ethnicity'],\n",
    "          #  'continent': response_data['continent']\n",
    "        #})\n",
    "    for response_data in forest_loss_responses:\n",
    "        writer.writerow({\n",
    "            'full_prompt': response_data['full_prompt'], \n",
    "            'response': response_data['response'], \n",
    "            'temperature': response_data['temperature'],\n",
    "            'top_p': response_data['top_p'], \n",
    "            'test': response_data['test'], \n",
    "            'model': response_data['model'], \n",
    "            'frame': response_data['frame'], \n",
    "            'age': response_data['age'],\n",
    "            'gender': response_data['gender'],\n",
    "            'education': response_data['education'],\n",
    "            'ethnicity': response_data['ethnicity'],\n",
    "            'continent': response_data['continent']\n",
    "        })\n",
    "    for response_data in human_gain_responses:\n",
    "        writer.writerow({\n",
    "            'full_prompt': response_data['full_prompt'], \n",
    "            'response': response_data['response'], \n",
    "            'temperature': response_data['temperature'],\n",
    "            'top_p': response_data['top_p'], \n",
    "            'test': response_data['test'], \n",
    "            'model': response_data['model'], \n",
    "            'frame': response_data['frame'], \n",
    "            'age': response_data['age'],\n",
    "            'gender': response_data['gender'],\n",
    "            'education': response_data['education'],\n",
    "            'ethnicity': response_data['ethnicity'],\n",
    "            'continent': response_data['continent']\n",
    "        })\n",
    "    for response_data in human_loss_responses:\n",
    "        writer.writerow({\n",
    "            'full_prompt': response_data['full_prompt'], \n",
    "            'response': response_data['response'], \n",
    "            'temperature': response_data['temperature'],\n",
    "            'top_p': response_data['top_p'], \n",
    "            'test': response_data['test'], \n",
    "            'model': response_data['model'], \n",
    "            'frame': response_data['frame'], \n",
    "            'age': response_data['age'],\n",
    "            'gender': response_data['gender'],\n",
    "            'education': response_data['education'],\n",
    "            'ethnicity': response_data['ethnicity'],\n",
    "            'continent': response_data['continent']\n",
    "        })\n",
    "    for response_data in animal_gain_responses:\n",
    "        writer.writerow({\n",
    "            'full_prompt': response_data['full_prompt'], \n",
    "            'response': response_data['response'], \n",
    "            'temperature': response_data['temperature'],\n",
    "            'top_p': response_data['top_p'], \n",
    "            'test': response_data['test'], \n",
    "            'model': response_data['model'], \n",
    "            'frame': response_data['frame'], \n",
    "            'age': response_data['age'],\n",
    "            'gender': response_data['gender'],\n",
    "            'education': response_data['education'],\n",
    "            'ethnicity': response_data['ethnicity'],\n",
    "            'continent': response_data['continent']\n",
    "        })\n",
    "    for response_data in animal_loss_responses:\n",
    "        writer.writerow({\n",
    "            'full_prompt': response_data['full_prompt'], \n",
    "            'response': response_data['response'], \n",
    "            'temperature': response_data['temperature'],\n",
    "            'top_p': response_data['top_p'], \n",
    "            'test': response_data['test'], \n",
    "            'model': response_data['model'], \n",
    "            'frame': response_data['frame'], \n",
    "            'age': response_data['age'],\n",
    "            'gender': response_data['gender'],\n",
    "            'education': response_data['education'],\n",
    "            'ethnicity': response_data['ethnicity'],\n",
    "            'continent': response_data['continent']\n",
    "        })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CREATE A NEW CSV FILE \n",
    "\n",
    "## New CSV \n",
    "csv_file_path = \"/Users/annaking/Documents/Github/riskychoiceframing_AI/Experiment 2/tests/participant_testing_080123_1run_v2.csv\"\n",
    "with open(csv_file_path, 'w', newline='') as file: \n",
    "    fieldnames = ['full_prompt', 'response', 'temperature', 'top_p', 'test', 'model', 'frame', 'age', 'gender', 'education', 'ethnicity', 'continent']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for response_data in forest_gain_responses:\n",
    "        writer.writerow({\n",
    "            'full_prompt': response_data['full_prompt'], \n",
    "            'response': response_data['response'], \n",
    "            'temperature': response_data['temperature'],\n",
    "            'top_p': response_data['top_p'], \n",
    "            'test': response_data['test'], \n",
    "            'model': response_data['model'], \n",
    "            'frame': response_data['frame'], \n",
    "            'age': response_data['age'],\n",
    "            'gender': response_data['gender'],\n",
    "            'education': response_data['education'],\n",
    "            'ethnicity': response_data['ethnicity'],\n",
    "            'continent': response_data['continent']\n",
    "        })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205, 12)"
      ]
     },
     "execution_count": 1020,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1run = pd.read_csv(csv_file_path)\n",
    "df_1run.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_json(x):\n",
    "    if not x.endswith('}'):\n",
    "        if not x.endswith('\"'):\n",
    "            x += '\"'  \n",
    "        x += '}'  \n",
    "    return x\n",
    "df_participant['response'] = df_participant['response'].apply(fix_json)\n",
    "\n",
    "responses = df_participant.apply(lambda x: pd.Series(json.loads(x['response'])), axis=1, result_type='expand')\n",
    "df_participant = pd.concat([df_participant,responses ], axis = 1).reset_index()\n",
    "\n",
    "cross_tab = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Script 1 Run (Turbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {},
   "outputs": [
    {
     "ename": "Timeout",
     "evalue": "Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mtimeout\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    537\u001b[0m \u001b[39mexcept\u001b[39;00m (BaseSSLError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connection.py:454\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[39m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 454\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    456\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:1349\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1348\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1349\u001b[0m     response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1350\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:316\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    317\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:277\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 277\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    278\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    705\u001b[0m \u001b[39mexcept\u001b[39;00m timeout:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1242\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1100\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mtimeout\u001b[0m: The read operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connectionpool.py:844\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    842\u001b[0m     new_e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, new_e)\n\u001b[0;32m--> 844\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[1;32m    845\u001b[0m     method, url, error\u001b[39m=\u001b[39;49mnew_e, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[1;32m    846\u001b[0m )\n\u001b[1;32m    847\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/util/retry.py:470\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[39mif\u001b[39;00m read \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m method \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_method_retryable(method):\n\u001b[0;32m--> 470\u001b[0m     \u001b[39mraise\u001b[39;00m reraise(\u001b[39mtype\u001b[39;49m(error), error, _stacktrace)\n\u001b[1;32m    471\u001b[0m \u001b[39melif\u001b[39;00m read \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/util/util.py:39\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[39mraise\u001b[39;00m value\u001b[39m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m---> 39\u001b[0m     \u001b[39mraise\u001b[39;00m value\n\u001b[1;32m     40\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    791\u001b[0m     conn,\n\u001b[1;32m    792\u001b[0m     method,\n\u001b[1;32m    793\u001b[0m     url,\n\u001b[1;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    795\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    796\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    798\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[1;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    802\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    803\u001b[0m )\n\u001b[1;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connectionpool.py:538\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[39mexcept\u001b[39;00m (BaseSSLError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 538\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_timeout(err\u001b[39m=\u001b[39;49me, url\u001b[39m=\u001b[39;49murl, timeout_value\u001b[39m=\u001b[39;49mread_timeout)\n\u001b[1;32m    539\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connectionpool.py:370\u001b[0m, in \u001b[0;36mHTTPConnectionPool._raise_timeout\u001b[0;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(err, SocketTimeout):\n\u001b[0;32m--> 370\u001b[0m     \u001b[39mraise\u001b[39;00m ReadTimeoutError(\n\u001b[1;32m    371\u001b[0m         \u001b[39mself\u001b[39m, url, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRead timed out. (read timeout=\u001b[39m\u001b[39m{\u001b[39;00mtimeout_value\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[39m# See the above comment about EAGAIN in Python 3.\u001b[39;00m\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py:596\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m     result \u001b[39m=\u001b[39m _thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    597\u001b[0m         method,\n\u001b[1;32m    598\u001b[0m         abs_url,\n\u001b[1;32m    599\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    600\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    601\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    602\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    603\u001b[0m         timeout\u001b[39m=\u001b[39;49mrequest_timeout \u001b[39mif\u001b[39;49;00m request_timeout \u001b[39melse\u001b[39;49;00m TIMEOUT_SECS,\n\u001b[1;32m    604\u001b[0m         proxies\u001b[39m=\u001b[39;49m_thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mproxies,\n\u001b[1;32m    605\u001b[0m     )\n\u001b[1;32m    606\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/adapters.py:532\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[0;32m--> 532\u001b[0m     \u001b[39mraise\u001b[39;00m ReadTimeout(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m    533\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, _InvalidHeader):\n",
      "\u001b[0;31mReadTimeout\u001b[0m: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTimeout\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1045], line 175\u001b[0m\n\u001b[1;32m    172\u001b[0m user_message \u001b[39m=\u001b[39m format_prompt(user_message_1, formatted_scenario) \u001b[39m#### change for each run \u001b[39;00m\n\u001b[1;32m    173\u001b[0m system_message \u001b[39m=\u001b[39m system_message_1_dem\u001b[39m.\u001b[39mformat(age\u001b[39m=\u001b[39mage,gender\u001b[39m=\u001b[39mgender,ethnicity\u001b[39m=\u001b[39methnicity,education \u001b[39m=\u001b[39m education, continent\u001b[39m=\u001b[39mcontinent) \n\u001b[0;32m--> 175\u001b[0m animal_loss_turbo \u001b[39m=\u001b[39m generate_response_turbo(system_message, user_message, \u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m) \n\u001b[1;32m    177\u001b[0m full_prompt, response, temperature, top_p \u001b[39m=\u001b[39m animal_loss_turbo[\u001b[39m0\u001b[39m]\n\u001b[1;32m    178\u001b[0m frame \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39manimal_loss\u001b[39m\u001b[39m'\u001b[39m \u001b[39m##change with each run \u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1045], line 35\u001b[0m, in \u001b[0;36mgenerate_response_turbo\u001b[0;34m(sys_prompt, user_prompt, temperature, top_p)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_response_turbo\u001b[39m(sys_prompt, user_prompt, temperature, top_p):\n\u001b[1;32m     33\u001b[0m      messages\u001b[39m=\u001b[39m[{\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39msystem\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m : sys_prompt },\n\u001b[1;32m     34\u001b[0m                {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m : user_prompt }]\n\u001b[0;32m---> 35\u001b[0m      response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     36\u001b[0m           model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     37\u001b[0m           messages \u001b[39m=\u001b[39;49m messages,\n\u001b[1;32m     38\u001b[0m           temperature\u001b[39m=\u001b[39;49mtemperature,\n\u001b[1;32m     39\u001b[0m           max_tokens\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m,\n\u001b[1;32m     40\u001b[0m           n\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, \n\u001b[1;32m     41\u001b[0m           top_p\u001b[39m=\u001b[39;49mtop_p\n\u001b[1;32m     42\u001b[0m   )\n\u001b[1;32m     43\u001b[0m      prompt \u001b[39m=\u001b[39m sys_prompt \u001b[39m+\u001b[39m user_prompt\n\u001b[1;32m     44\u001b[0m      \u001b[39mreturn\u001b[39;00m [(prompt, response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage[\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m], temperature, top_p) \u001b[39mfor\u001b[39;00m choice \u001b[39min\u001b[39;00m response\u001b[39m.\u001b[39mchoices ]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py:288\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[39m.\u001b[39;49mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[1;32m    291\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    292\u001b[0m         supplied_headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    293\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    294\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    295\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[1;32m    298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py:607\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    596\u001b[0m     result \u001b[39m=\u001b[39m _thread_context\u001b[39m.\u001b[39msession\u001b[39m.\u001b[39mrequest(\n\u001b[1;32m    597\u001b[0m         method,\n\u001b[1;32m    598\u001b[0m         abs_url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    604\u001b[0m         proxies\u001b[39m=\u001b[39m_thread_context\u001b[39m.\u001b[39msession\u001b[39m.\u001b[39mproxies,\n\u001b[1;32m    605\u001b[0m     )\n\u001b[1;32m    606\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 607\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mTimeout(\u001b[39m\"\u001b[39m\u001b[39mRequest timed out: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    608\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mRequestException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    609\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mAPIConnectionError(\n\u001b[1;32m    610\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mError communicating with OpenAI: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e)\n\u001b[1;32m    611\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mTimeout\u001b[0m: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)"
     ]
    }
   ],
   "source": [
    "####### Writing as 1 script (For multiple Prompting)  #######\n",
    "\n",
    "#read in participant data from exp 1 \n",
    "participant_demographics = pd.read_csv('participant_demographics.csv')\n",
    "\n",
    "#create dataframes for each scenario condition\n",
    "#df for each group of participants\n",
    "forest_gain_dems = participant_demographics[participant_demographics['scenario_mapped'] == 'forest_gain' ]\n",
    "forest_loss_dems = participant_demographics[participant_demographics['scenario_mapped'] == 'forest_loss' ]\n",
    "\n",
    "human_gain_dems = participant_demographics[participant_demographics['scenario_mapped'] == 'humans_gain' ]\n",
    "human_loss_dems  = participant_demographics[participant_demographics['scenario_mapped'] == 'humans_loss' ]\n",
    "\n",
    "animal_gain_dems = participant_demographics[participant_demographics['scenario_mapped'] == 'animals_gain' ]\n",
    "animal_loss_dems = participant_demographics[participant_demographics['scenario_mapped'] == 'animals_loss' ]\n",
    "\n",
    "\n",
    "####### --- Prompt Combinations  --- #######\n",
    "##combo 1  \n",
    "system_message_1_dem = \"\"\"You are a {ethnicity} {gender} between {age} from {continent}. Your education level is a {education}. You are a participant in a survey. You are capable of making decisions and choices.\"\"\"\n",
    "user_message_1 =  \"\"\"Thank you for taking the time to participate in this study. This study seeks to better understand risk preferences and general, related attitudes. In this study, you will be presented with a hypothetical scenario, requiring a choice between two options. There are no right or wrong answers.\\nInstructions: read the scenario below and then answer the questions.\\n{}\\n\\nQuestions:\\n1. Please choose an option:\\n- Proposal A\\n- Proposal B\\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Briefly describe the rationale for your preference rating:\\n\\nProvide your response as a JSON object. As an example: '{{\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}}'.\\n\\nResponse:\"\"\"\n",
    "\n",
    "## dynamic function for the scenario \n",
    "def format_scenario(scenario_text):\n",
    "    return scenario_text\n",
    "\n",
    "## dynamic function for the prompt \n",
    "def format_prompt(prompt_text, scenario):\n",
    "    return prompt_text.format(scenario)\n",
    "\n",
    "### Define Function \n",
    "def generate_response_turbo(sys_prompt, user_prompt, temperature, top_p):\n",
    "     messages=[{\"role\": \"system\", \"content\" : sys_prompt },\n",
    "               {\"role\": \"user\", \"content\" : user_prompt }]\n",
    "     response = openai.ChatCompletion.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "          messages = messages,\n",
    "          temperature=temperature,\n",
    "          max_tokens=200,\n",
    "          n=1, \n",
    "          top_p=top_p\n",
    "  )\n",
    "     prompt = sys_prompt + user_prompt\n",
    "     return [(prompt, response.choices[0].message['content'], temperature, top_p) for choice in response.choices ]\n",
    "     \n",
    "\n",
    "###################### Alter VARIABLES  ####################### \n",
    "\n",
    "########## Forest Scenario ########## \n",
    "## Forest Gain \n",
    "forest_gain_responses_turbo = []\n",
    "\n",
    "for _, participant in forest_gain_dems.iterrows(): ##change with each\n",
    "    age = participant['age']\n",
    "    gender = participant['gender']\n",
    "    education = participant['education']\n",
    "    ethnicity = participant['ethnicity']\n",
    "    continent = participant['continent']\n",
    "    \n",
    "    formatted_scenario = format_scenario(gain_forest) #### change for each run \n",
    "    user_message = format_prompt(user_message_1, formatted_scenario) #### change for each run \n",
    "    system_message = system_message_1_dem.format(age=age,gender=gender,ethnicity=ethnicity,education = education, continent=continent) \n",
    "\n",
    "    forest_gain_turbo = generate_response_turbo(system_message, user_message, 0, 1) \n",
    "        \n",
    "    full_prompt, response, temperature, top_p = forest_gain_turbo[0]\n",
    "    frame = 'forest_gain' ##change with each run \n",
    "    model = 'gpt-3.5-turbo' \n",
    "    test = ['combo 1', 'system_message_1_dem', 'user_message_1']\n",
    "\n",
    "    forest_gain_responses_turbo.append({\n",
    "        'full_prompt': full_prompt, \n",
    "        'response': response, \n",
    "        'temperature': temperature,\n",
    "        'top_p': top_p, \n",
    "        'test': test, \n",
    "        'model': model, \n",
    "        'frame': frame, \n",
    "        'age': age,\n",
    "        'gender': gender,\n",
    "        'education': education,\n",
    "        'ethnicity': ethnicity,\n",
    "        'continent': continent\n",
    "        })\n",
    "\n",
    "## Forest Loss \n",
    "forest_loss_responses_turbo = []\n",
    "\n",
    "for _, participant in forest_loss_dems.iterrows(): ##change with each\n",
    "    age = participant['age']\n",
    "    gender = participant['gender']\n",
    "    education = participant['education']\n",
    "    ethnicity = participant['ethnicity']\n",
    "    continent = participant['continent']\n",
    "    \n",
    "    formatted_scenario = format_scenario(loss_forest) #### change for each run \n",
    "    user_message = format_prompt(user_message_1, formatted_scenario) #### change for each run \n",
    "    system_message = system_message_1_dem.format(age=age,gender=gender,ethnicity=ethnicity,education = education, continent=continent)\n",
    "\n",
    "    forest_loss_turbo = generate_response_turbo(system_message, user_message, 0, 1) \n",
    "        \n",
    "    full_prompt, response, temperature, top_p = forest_loss_turbo[0]\n",
    "    frame = 'forest_loss' ##change with each run \n",
    "    model = 'gpt-3.5-turbo' \n",
    "    test = ['combo 1', 'system_message_1_dem', 'user_message_1']\n",
    "\n",
    "    forest_loss_responses_turbo.append({\n",
    "        'full_prompt': full_prompt, \n",
    "        'response': response, \n",
    "        'temperature': temperature,\n",
    "        'top_p': top_p, \n",
    "        'test': test, \n",
    "        'model': model, \n",
    "        'frame': frame, \n",
    "        'age': age,\n",
    "        'gender': gender,\n",
    "        'education': education,\n",
    "        'ethnicity': ethnicity,\n",
    "        'continent': continent\n",
    "        })\n",
    "\n",
    "    \n",
    "######### Animal Scenario ########## \n",
    "## Animal Gain \n",
    "animal_gain_responses_turbo = []\n",
    "\n",
    "for _, participant in animal_gain_dems.iterrows(): ##change with each\n",
    "    age = participant['age']\n",
    "    gender = participant['gender']\n",
    "    education = participant['education']\n",
    "    ethnicity = participant['ethnicity']\n",
    "    continent = participant['continent']\n",
    "    \n",
    "    formatted_scenario = format_scenario(gain_animal) #### change for each run \n",
    "    user_message = format_prompt(user_message_1, formatted_scenario) #### change for each run \n",
    "    system_message = system_message_1_dem.format(age=age,gender=gender,ethnicity=ethnicity,education = education, continent=continent) \n",
    "\n",
    "    animal_gain_turbo = generate_response_turbo(system_message, user_message, 0, 1) \n",
    "        \n",
    "    full_prompt, response, temperature, top_p = animal_gain_turbo[0]\n",
    "    frame = 'animal_gain' ##change with each run \n",
    "    model = 'gpt-3.5-turbo' \n",
    "    test = ['combo 1', 'system_message_1_dem', 'user_message_1']\n",
    "\n",
    "    animal_gain_responses_turbo.append({\n",
    "        'full_prompt': full_prompt, \n",
    "        'response': response, \n",
    "        'temperature': temperature,\n",
    "        'top_p': top_p, \n",
    "        'test': test, \n",
    "        'model': model, \n",
    "        'frame': frame, \n",
    "        'age': age,\n",
    "        'gender': gender,\n",
    "        'education': education,\n",
    "        'ethnicity': ethnicity,\n",
    "        'continent': continent\n",
    "        })\n",
    "\n",
    "## Animal Loss \n",
    "\n",
    "animal_loss_responses_turbo = []\n",
    "\n",
    "for _, participant in animal_loss_dems.iterrows(): ##change with each\n",
    "    age = participant['age']\n",
    "    gender = participant['gender']\n",
    "    education = participant['education']\n",
    "    ethnicity = participant['ethnicity']\n",
    "    continent = participant['continent']\n",
    "    \n",
    "    formatted_scenario = format_scenario(loss_animal) #### change for each run \n",
    "    user_message = format_prompt(user_message_1, formatted_scenario) #### change for each run \n",
    "    system_message = system_message_1_dem.format(age=age,gender=gender,ethnicity=ethnicity,education = education, continent=continent) \n",
    "\n",
    "    animal_loss_turbo = generate_response_turbo(system_message, user_message, 0, 1) \n",
    "        \n",
    "    full_prompt, response, temperature, top_p = animal_loss_turbo[0]\n",
    "    frame = 'animal_loss' ##change with each run \n",
    "    model = 'gpt-3.5-turbo' \n",
    "    test = ['combo 1', 'system_message_1_dem', 'user_message_1']\n",
    "\n",
    "    animal_loss_responses_turbo.append({\n",
    "        'full_prompt': full_prompt, \n",
    "        'response': response, \n",
    "        'temperature': temperature,\n",
    "        'top_p': top_p, \n",
    "        'test': test, \n",
    "        'model': model, \n",
    "        'frame': frame, \n",
    "        'age': age,\n",
    "        'gender': gender,\n",
    "        'education': education,\n",
    "        'ethnicity': ethnicity,\n",
    "        'continent': continent\n",
    "        })\n",
    "    \n",
    "######### Human Scenario ########## \n",
    "## Human Gain \n",
    "\n",
    "human_gain_responses_turbo = []\n",
    "\n",
    "for _, participant in human_gain_dems.iterrows(): ##change with each\n",
    "    age = participant['age']\n",
    "    gender = participant['gender']\n",
    "    education = participant['education']\n",
    "    ethnicity = participant['ethnicity']\n",
    "    continent = participant['continent']\n",
    "    \n",
    "    formatted_scenario = format_scenario(gain_human) #### change for each run \n",
    "    user_message = format_prompt(user_message_1, formatted_scenario) #### change for each run \n",
    "    system_message = system_message_1_dem.format(age=age,gender=gender,ethnicity=ethnicity,education = education, continent=continent) \n",
    "\n",
    "    human_gain_turbo = generate_response_turbo(system_message, user_message, 0, 1) \n",
    "        \n",
    "    full_prompt, response, temperature, top_p = human_gain_turbo[0]\n",
    "    frame = 'human_gain' ##change with each run \n",
    "    model = 'gpt-3.5-turbo' \n",
    "    test = ['combo 1', 'system_message_1_dem', 'user_message_1']\n",
    "\n",
    "    human_gain_responses_turbo.append({\n",
    "        'full_prompt': full_prompt, \n",
    "        'response': response, \n",
    "        'temperature': temperature,\n",
    "        'top_p': top_p, \n",
    "        'test': test, \n",
    "        'model': model, \n",
    "        'frame': frame, \n",
    "        'age': age,\n",
    "        'gender': gender,\n",
    "        'education': education,\n",
    "        'ethnicity': ethnicity,\n",
    "        'continent': continent\n",
    "        })\n",
    "\n",
    "## Human Loss \n",
    "\n",
    "human_loss_responses_turbo = []\n",
    "\n",
    "for _, participant in human_loss_dems.iterrows(): ##change with each\n",
    "    age = participant['age']\n",
    "    gender = participant['gender']\n",
    "    education = participant['education']\n",
    "    ethnicity = participant['ethnicity']\n",
    "    continent = participant['continent']\n",
    "    \n",
    "    formatted_scenario = format_scenario(loss_human) #### change for each run \n",
    "    user_message = format_prompt(user_message_1, formatted_scenario) #### change for each run \n",
    "    system_message = system_message_1_dem.format(age=age,gender=gender,ethnicity=ethnicity,education = education, continent=continent) \n",
    "\n",
    "    human_loss_turbo = generate_response_turbo(system_message, user_message, 0, 1) \n",
    "        \n",
    "    full_prompt, response, temperature, top_p = human_loss_turbo[0]\n",
    "    frame = 'human_loss' ##change with each run \n",
    "    model = 'gpt-3.5-turbo' \n",
    "    test = ['combo 1', 'system_message_1_dem', 'user_message_1']\n",
    "\n",
    "    human_loss_responses_turbo.append({\n",
    "        'full_prompt': full_prompt, \n",
    "        'response': response, \n",
    "        'temperature': temperature,\n",
    "        'top_p': top_p, \n",
    "        'test': test, \n",
    "        'model': model, \n",
    "        'frame': frame, \n",
    "        'age': age,\n",
    "        'gender': gender,\n",
    "        'education': education,\n",
    "        'ethnicity': ethnicity,\n",
    "        'continent': continent\n",
    "        })\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix: \n",
    "###Bachelor\\'s degree.\n",
    "\n",
    "###Other --> n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Append\n",
    "csv_file_path = \"/Users/annaking/Documents/Github/riskychoiceframing_AI/Experiment 2/tests/participant_testing_080123_turbo2.csv\"\n",
    "with open(csv_file_path, 'a', newline='') as file: \n",
    "    fieldnames = ['full_prompt', 'response', 'temperature', 'top_p', 'test', 'model', 'frame', 'age', 'gender', 'education', 'ethnicity', 'continent']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    #for data in forest_gain_responses:\n",
    "        #writer.writerow({\n",
    "          #  'full_prompt': response_data['full_prompt'], \n",
    "          #  'response': response_data['response'], \n",
    "          #  'temperature': response_data['temperature'],\n",
    "          #  'top_p': response_data['top_p'], \n",
    "          #  'test': response_data['test'], \n",
    "          #  'model': response_data['model'], \n",
    "          #  'frame': response_data['frame'], \n",
    "          #  'age': response_data['age'],\n",
    "          #  'gender': response_data['gender'],\n",
    "          #  'education': response_data['education'],\n",
    "          #  'ethnicity': response_data['ethnicity'],\n",
    "          #  'continent': response_data['continent']\n",
    "        #})\n",
    "    for response_data in forest_loss_responses_turbo:\n",
    "        writer.writerow({\n",
    "            'full_prompt': response_data['full_prompt'], \n",
    "            'response': response_data['response'], \n",
    "            'temperature': response_data['temperature'],\n",
    "            'top_p': response_data['top_p'], \n",
    "            'test': response_data['test'], \n",
    "            'model': response_data['model'], \n",
    "            'frame': response_data['frame'], \n",
    "            'age': response_data['age'],\n",
    "            'gender': response_data['gender'],\n",
    "            'education': response_data['education'],\n",
    "            'ethnicity': response_data['ethnicity'],\n",
    "            'continent': response_data['continent']\n",
    "        })\n",
    "    for response_data in human_gain_responses_turbo:\n",
    "        writer.writerow({\n",
    "            'full_prompt': response_data['full_prompt'], \n",
    "            'response': response_data['response'], \n",
    "            'temperature': response_data['temperature'],\n",
    "            'top_p': response_data['top_p'], \n",
    "            'test': response_data['test'], \n",
    "            'model': response_data['model'], \n",
    "            'frame': response_data['frame'], \n",
    "            'age': response_data['age'],\n",
    "            'gender': response_data['gender'],\n",
    "            'education': response_data['education'],\n",
    "            'ethnicity': response_data['ethnicity'],\n",
    "            'continent': response_data['continent']\n",
    "        })\n",
    "    for response_data in human_loss_responses_turbo:\n",
    "        writer.writerow({\n",
    "            'full_prompt': response_data['full_prompt'], \n",
    "            'response': response_data['response'], \n",
    "            'temperature': response_data['temperature'],\n",
    "            'top_p': response_data['top_p'], \n",
    "            'test': response_data['test'], \n",
    "            'model': response_data['model'], \n",
    "            'frame': response_data['frame'], \n",
    "            'age': response_data['age'],\n",
    "            'gender': response_data['gender'],\n",
    "            'education': response_data['education'],\n",
    "            'ethnicity': response_data['ethnicity'],\n",
    "            'continent': response_data['continent']\n",
    "        })\n",
    "    for response_data in animal_gain_responses_turbo:\n",
    "        writer.writerow({\n",
    "            'full_prompt': response_data['full_prompt'], \n",
    "            'response': response_data['response'], \n",
    "            'temperature': response_data['temperature'],\n",
    "            'top_p': response_data['top_p'], \n",
    "            'test': response_data['test'], \n",
    "            'model': response_data['model'], \n",
    "            'frame': response_data['frame'], \n",
    "            'age': response_data['age'],\n",
    "            'gender': response_data['gender'],\n",
    "            'education': response_data['education'],\n",
    "            'ethnicity': response_data['ethnicity'],\n",
    "            'continent': response_data['continent']\n",
    "        })\n",
    "    for response_data in animal_loss_responses_turbo:\n",
    "        writer.writerow({\n",
    "            'full_prompt': response_data['full_prompt'], \n",
    "            'response': response_data['response'], \n",
    "            'temperature': response_data['temperature'],\n",
    "            'top_p': response_data['top_p'], \n",
    "            'test': response_data['test'], \n",
    "            'model': response_data['model'], \n",
    "            'frame': response_data['frame'], \n",
    "            'age': response_data['age'],\n",
    "            'gender': response_data['gender'],\n",
    "            'education': response_data['education'],\n",
    "            'ethnicity': response_data['ethnicity'],\n",
    "            'continent': response_data['continent']\n",
    "        })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CREATE A NEW CSV FILE \n",
    "\n",
    "## New CSV \n",
    "csv_file_path = \"/Users/annaking/Documents/Github/riskychoiceframing_AI/Experiment 2/tests/participant_testing_080123_turbo2.csv\"\n",
    "with open(csv_file_path, 'w', newline='') as file: \n",
    "    fieldnames = ['full_prompt', 'response', 'temperature', 'top_p', 'test', 'model', 'frame', 'age', 'gender', 'education', 'ethnicity', 'continent']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for response_data in forest_gain_responses_turbo:\n",
    "        writer.writerow({\n",
    "            'full_prompt': response_data['full_prompt'], \n",
    "            'response': response_data['response'], \n",
    "            'temperature': response_data['temperature'],\n",
    "            'top_p': response_data['top_p'], \n",
    "            'test': response_data['test'], \n",
    "            'model': response_data['model'], \n",
    "            'frame': response_data['frame'], \n",
    "            'age': response_data['age'],\n",
    "            'gender': response_data['gender'],\n",
    "            'education': response_data['education'],\n",
    "            'ethnicity': response_data['ethnicity'],\n",
    "            'continent': response_data['continent']\n",
    "        })\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1_Response</th>\n",
       "      <th>Proposal A</th>\n",
       "      <th>Proposal B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <th>frame</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">['combo 1', 'system_message_1_dem', 'user_message_1']</th>\n",
       "      <th>animal_gain</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>animal_loss</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_gain</th>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_loss</th>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>human_gain</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>human_loss</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Q1_Response                                                        Proposal A  Proposal B\n",
       "test                                                  frame                              \n",
       "['combo 1', 'system_message_1_dem', 'user_message_1'] animal_gain           0          34\n",
       "                                                      animal_loss          37           0\n",
       "                                                      forest_gain           2          34\n",
       "                                                      forest_loss          11          20\n",
       "                                                      human_gain           30           0\n",
       "                                                      human_loss           37           0"
      ]
     },
     "execution_count": 1099,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run1_T0 = \"/Users/annaking/Documents/Github/riskychoiceframing_AI/Experiment 2/tests/participant_testing_080123_turbo1.csv\"\n",
    "run2_T0 = \"/Users/annaking/Documents/Github/riskychoiceframing_AI/Experiment 2/tests/participant_testing_080123_turbo2.csv\"\n",
    "\n",
    "###set up dataframe for 1st Run \n",
    "df_turbo1 = pd.read_csv(run1_T0)\n",
    "\n",
    "###clean json data\n",
    "responses = df_turbo1.apply(lambda x: pd.Series(json.loads(x['response'])), axis=1, result_type='expand')\n",
    "df_turbo1 = pd.concat([df_turbo1,responses ], axis = 1)\n",
    "\n",
    "##clean rating data\n",
    "df_turbo1['Q2_Response'] = df_turbo1['Q2_Response'].str.extract(r'(\\d)')\n",
    "df_turbo1['Q2_Response'] = df_turbo1['Q2_Response'].astype('int')\n",
    "\n",
    "\n",
    "##look at response breakdown \n",
    "df_turbo1_cross = pd.crosstab([df_turbo1['test'], df_turbo1['frame']], df_turbo1['Q1_Response']) ##,normalize='index')\n",
    "df_turbo1_cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q2_Response</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>animal_gain</th>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>animal_loss</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_gain</th>\n",
       "      <td>5.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_loss</th>\n",
       "      <td>4.741935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>human_gain</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>human_loss</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Q2_Response\n",
       "frame                   \n",
       "animal_gain     6.000000\n",
       "animal_loss     2.000000\n",
       "forest_gain     5.777778\n",
       "forest_loss     4.741935\n",
       "human_gain      2.000000\n",
       "human_loss      2.000000"
      ]
     },
     "execution_count": 1082,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##look at rating breakdown #\n",
    "##f_turbo1_cross = pd.crosstab(df_turbo1['frame'],   values = df_turbo1['Q2_Response'])\n",
    "rating1 = df_turbo1.groupby('frame')['Q2_Response'].mean().to_frame()\n",
    "rating1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1059,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 2 is not meaningfully different from run 1\n"
     ]
    }
   ],
   "source": [
    "#### Set up dataframe for 2nd Run \n",
    "df_turbo2 = pd.read_csv(run2_T0)\n",
    "responses = df_turbo2.apply(lambda x: pd.Series(json.loads(x['response'])), axis=1, result_type='expand')\n",
    "df_turbo2 = pd.concat([df_turbo2,responses ], axis = 1)\n",
    "\n",
    "##clean rating data\n",
    "df_turbo2['Q2_Response'] = df_turbo2['Q2_Response'].str.extract(r'(\\d)')\n",
    "df_turbo2['Q2_Response'] = df_turbo2['Q2_Response'].astype('int')\n",
    "\n",
    "##look at response breakdown \n",
    "df_turbo2_cross = pd.crosstab(df_turbo2['frame'],df_turbo2['Q1_Response'],normalize='index')\n",
    "##df_turbo2_cross \n",
    "print(\"run 2 is not meaningfully different from run 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_turbo2['Q2_Response'] = df_turbo2['Q2_Response'].str.extract(r'(\\d)')\n",
    "df_turbo2['Q2_Response'] = df_turbo2['Q2_Response'].astype('int')\n",
    "\n",
    "rating2 = df_turbo2.groupby('frame')['Q2_Response'].mean().to_frame()\n",
    "rating2\n",
    "print(\"run 2 is not meaningfully different from run 1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataframes by Condition \n",
    "#forest gain \n",
    "fg_df = df_turbo1[df_turbo1['frame'] == 'forest_gain']\n",
    "#forest gain \n",
    "fl_df = df_turbo1[df_turbo1['frame'] == 'forest_loss']\n",
    "hl_df = df_turbo1[df_turbo1['frame'] == 'human_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "hl_rationales = {index: response for  index, response in enumerate(hl_df.Q3_Response.unique())}\n",
    "fl_rationales = {index: response for  index, response in enumerate(fl_df.Q3_Response.unique())}\n",
    "\n",
    "##fl_response = pd.DataFrame.from_dict(fl_rationales, orient = 'index')\n",
    "###hl_rationales = pd.DataFrame.from_dict(fl_rationales, orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1097,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q1_Response\n",
       "Proposal A    16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1097,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_columns = ['Q1_Response', 'Q3_Response']\n",
    "unique_combinations_fl_df = fl_df[relevant_columns].drop_duplicates()\n",
    "unique_combinations_hl_df = hl_df[relevant_columns].drop_duplicates()\n",
    "##unique_combinations_hl_df['Q3_Response']\n",
    "unique_combinations_fl_df['Q1_Response'].value_counts()\n",
    "unique_combinations_hl_df['Q1_Response'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes \n",
    "- run 2 for combo 1 with T0 is not meaninguflly different \n",
    "- forest gain and loss appear the most different in responses -- why? ; forest loss appears somewhat similar to human preferences \n",
    "- animal gain is completely reverse to human preferences "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Script 1 by 1 Scenario (Text Davinci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Writing as 1 script  #######\n",
    "\n",
    "#read in participant data from exp 1 \n",
    "participant_demographics = pd.read_csv('participant_demographics.csv')\n",
    "\n",
    "#create dataframes for each scenario condition\n",
    "#df for each group of participants\n",
    "forest_gain_dems = participant_demographics[participant_demographics['scenario_mapped'] == 'forest_gain' ]\n",
    "forest_loss_dems = participant_demographics[participant_demographics['scenario_mapped'] == 'forest_loss' ]\n",
    "\n",
    "human_gain_dems = participant_demographics[participant_demographics['scenario_mapped'] == 'humans_gain' ]\n",
    "human_loss_dems  = participant_demographics[participant_demographics['scenario_mapped'] == 'humans_loss' ]\n",
    "\n",
    "animal_gain_dems = participant_demographics[participant_demographics['scenario_mapped'] == 'animals_gain' ]\n",
    "animal_loss_dems = participant_demographics[participant_demographics['scenario_mapped'] == 'animals_loss' ]\n",
    "\n",
    "\n",
    "####### --- Prompt Combinations  --- #######\n",
    "##combo 1  \n",
    "p_prompt_1 = \"\"\"You are a {ethnicity} {gender} between {age} from {continent}. Your education level is a {education}.\"\"\"\n",
    "user_message_1 =  \"\"\"Thank you for taking the time to participate in this study. This study seeks to better understand risk preferences and general, related attitudes. In this study, you will be presented with a hypothetical scenario, requiring a choice between two options. There are no right or wrong answers.\\nInstructions: read the scenario below and then answer the questions.\\n{}\\n\\nQuestions:\\n1. Please choose an option:\\n- Proposal A\\n- Proposal B\\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Briefly describe the rationale for your preference rating:\\n\\nProvide your response as a JSON object. As an example: '{{\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}}'.\\n\\nResponse:\"\"\"\n",
    "\n",
    "## dynamic function for the scenario \n",
    "def format_scenario(scenario_text):\n",
    "    return scenario_text\n",
    "\n",
    "## dynamic function for the prompt \n",
    "def format_prompt(prompt_text, scenario):\n",
    "    return prompt_text.format(scenario)\n",
    "\n",
    "##set variables for the prompt\n",
    "\n",
    "##function to generate responses \n",
    "def generate_response(prompt, temperature, top_p):\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=90,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=temperature,\n",
    "        top_p = top_p\n",
    "    )\n",
    "    return [(prompt, choice.text.strip(), temperature, top_p) for choice in response.choices]\n",
    "\n",
    "output_responses = []\n",
    "\n",
    "##### Iterate over each participant in the  group\n",
    "for _, participant in animal_gain_dems.iterrows(): ##change with each\n",
    "    age = participant['age']\n",
    "    gender = participant['gender']\n",
    "    education = participant['education']\n",
    "    ethnicity = participant['ethnicity']\n",
    "    continent = participant['continent']\n",
    "    \n",
    "    formatted_scenario = format_scenario(gain_animal) #### change for each run \n",
    "    user_message = format_prompt(user_message_1, formatted_scenario) #### change for each run \n",
    "    full_prompt = p_prompt_1.format(age=age,gender=gender,ethnicity=ethnicity,education = education, continent=continent) + user_message\n",
    "\n",
    "    output = generate_response(full_prompt, 0, 1) \n",
    "        \n",
    "    full_prompt, response, temperature, top_p = output[0]\n",
    "    frame = 'animal_gain' ##change with each run \n",
    "    model = 'text-davinci-003' \n",
    "    test = ['combo 1', 'p_prompt_1', 'user_message_1']\n",
    "\n",
    "    output_responses.append({\n",
    "        'full_prompt': full_prompt, \n",
    "        'response': response, \n",
    "        'temperature': temperature,\n",
    "        'top_p': top_p, \n",
    "        'test': test, \n",
    "        'model': model, \n",
    "        'frame': frame, \n",
    "        'age': age,\n",
    "        'gender': gender,\n",
    "        'education': education,\n",
    "        'ethnicity': ethnicity,\n",
    "        'continent': continent\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Apend CSV \n",
    "\n",
    "##csv_file_path = \"/Users/annaking/Documents/Github/riskychoiceframing_AI/Experiment 2/tests/participant_testing_080123_v4.csv\"\n",
    "##with open(csv_file_path, 'a', newline='') as file: \n",
    "    fieldnames = ['full_prompt', 'response', 'temperature', 'top_p', 'test', 'model', 'frame', 'age', 'gender', 'education', 'ethnicity', 'continent']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    for response_data in output_responses:\n",
    "        writer.writerow({\n",
    "            'full_prompt': response_data['full_prompt'], \n",
    "            'response': response_data['response'], \n",
    "            'temperature': response_data['temperature'],\n",
    "            'top_p': response_data['top_p'], \n",
    "            'test': response_data['test'], \n",
    "            'model': response_data['model'], \n",
    "            'frame': response_data['frame'], \n",
    "            'age': response_data['age'],\n",
    "            'gender': response_data['gender'],\n",
    "            'education': response_data['education'],\n",
    "            'ethnicity': response_data['ethnicity'],\n",
    "            'continent': response_data['continent']\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [],
   "source": [
    "## New CSV \n",
    "csv_file_path = \"/Users/annaking/Documents/Github/riskychoiceframing_AI/Experiment 2/tests/participant_testing_080123_v4.csv\"\n",
    "with open(csv_file_path, 'w', newline='') as file: \n",
    "    fieldnames = ['full_prompt', 'response', 'temperature', 'top_p', 'test', 'model', 'frame', 'age', 'gender', 'education', 'ethnicity', 'continent']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for response_data in output_responses:\n",
    "        writer.writerow({\n",
    "            'full_prompt': response_data['full_prompt'], \n",
    "            'response': response_data['response'], \n",
    "            'temperature': response_data['temperature'],\n",
    "            'top_p': response_data['top_p'], \n",
    "            'test': response_data['test'], \n",
    "            'model': response_data['model'], \n",
    "            'frame': response_data['frame'], \n",
    "            'age': response_data['age'],\n",
    "            'gender': response_data['gender'],\n",
    "            'education': response_data['education'],\n",
    "            'ethnicity': response_data['ethnicity'],\n",
    "            'continent': response_data['continent']\n",
    "        })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gain_human', 'loss_human', 'gain_forest', 'loss_forest',\n",
       "       'animal_loss', 'animal_gain'], dtype=object)"
      ]
     },
     "execution_count": 959,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_participant = pd.read_csv(csv_file_path) \n",
    "df_participant.shape\n",
    "df_participant.frame.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "df_participant['response'] = df_participant['response'].str.strip(\"'\")\n",
    "frame_dict = {'gain_forest': 'forest_gain', 'loss_forest': 'forest_loss', 'loss_human': 'human_loss', 'gain_human': 'human_loss'}\n",
    "\n",
    "df_participant['frame_2']  = df_participant['frame'].apply(lambda x: 'forest_gain' if x == 'gain_forest' else \\\n",
    "                                                           ('forest_loss' if x == 'loss_forest' else \\\n",
    "                                                           ('human_loss' if x == 'loss_human' else \\\n",
    "                                                           ('human_gain' if x == 'gain_human' else x\n",
    "                                                           ))))                    \n",
    "\n",
    "def fix_json(x):\n",
    "    if not x.endswith('}'):\n",
    "        if not x.endswith('\"'):\n",
    "            x += '\"'  \n",
    "        x += '}'  \n",
    "    return x\n",
    "df_participant['response'] = df_participant['response'].apply(fix_json)\n",
    "\n",
    "responses = df_participant.apply(lambda x: pd.Series(json.loads(x['response'])), axis=1, result_type='expand')\n",
    "df_participant = pd.concat([df_participant,responses ], axis = 1).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Q1_Response</th>\n",
       "      <th>Proposal A</th>\n",
       "      <th>Proposal B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame_2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>animal_gain</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>animal_loss</th>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.081081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_gain</th>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.194444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_loss</th>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.677419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>human_gain</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>human_loss</th>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.054054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Q1_Response  Proposal A  Proposal B\n",
       "frame_2                            \n",
       "animal_gain    1.000000    0.000000\n",
       "animal_loss    0.918919    0.081081\n",
       "forest_gain    0.805556    0.194444\n",
       "forest_loss    0.322581    0.677419\n",
       "human_gain     1.000000    0.000000\n",
       "human_loss     0.945946    0.054054"
      ]
     },
     "execution_count": 962,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_participant_ct = pd.crosstab(df_participant['frame_2'],df_participant['Q1_Response'], normalize='index')\n",
    "df_participant_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_participant['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_participant_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Q1_Response</th>\n",
       "      <th>Proposal A</th>\n",
       "      <th>Proposal B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Q1_Response  Proposal A  Proposal B\n",
       "gender                             \n",
       "Female               14           1\n",
       "Male                 14           4\n",
       "Other                 1           2"
      ]
     },
     "execution_count": 895,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_df = pd.crosstab(df_participant['gender'], df_participant['Q1_Response'] )\n",
    "gender_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_df = pd.crosstab(df_participant['gender'], df_participant['Q1_Response'] )\n",
    "gender_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario & Prompt Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forest scenario \n",
    "gain_forest = \"\"\"Scenario: A vast forest area is under severe threat from deforestation due to urban growth and logging activities, potentially resulting in the removal of 900 trees from a grove of ancient oak trees in the forest. Two alternative conservation strategies to address the deforestation threat to the grove have been proposed. Imagine you are on the conservation committee tasked with deciding on a proposal. Assume that the estimates are as follows:\\n\\n- Option A: If Proposal A is adopted, 300 of the trees will be protected.\\n- Option B: If Proposal B is adopted, there is a 1/3 probability that all 900 of the trees will be protected, and 2/3 probability that no trees will be protected.\"\"\"\n",
    "loss_forest = \"\"\"Scenario: A vast forest area is under severe threat from deforestation due to urban growth and logging activities, potentially resulting in the removal of 900 trees from a grove of ancient oak trees in the forest. Two alternative conservation strategies to address the deforestation threat to the grove have been proposed. Imagine you are on the conservation committee tasked with deciding on a proposal. Assume that the estimates are as follows:\\n\\n- Option A: If Proposal A is adopted, 600 of the trees will be cleared.\\n- Option B: If Proposal B is adopted, there is a 1/3 probability that none of the trees will be cleared, and 2/3 probability that all 900 of the trees will be cleared.\"\"\"\n",
    "\n",
    "#human (air quality) scenario \n",
    "gain_human = \"\"\"Scenario: A city is facing significant air quality issues due to high levels of pollution, which could lead to 900 premature deaths over the next year due to respiratory illness. Two alternative plans to improve the air quality and reduce pollution have been proposed. Imagine you are a city official on the committee tasked with deciding on a proposal. Assume that the estimates are as follows:\\n\\n- Option A: If Proposal A is adopted, 300 people will survive.\\n- Option B: If Proposal B is adopted, there is a 1/3 probability that all 900 people will survive, and 2/3 probability that no one will survive.\"\"\"\n",
    "loss_human = \"\"\"Scenario: A city is facing significant air quality issues due to high levels of pollution, which could lead to 900 premature deaths over the next year due to respiratory illness. Two alternative plans to improve the air quality and reduce pollution have been proposed. Imagine you are a city official on the committee tasked with deciding on a proposal. Assume that the estimates are as follows:\\n\\n- Option A: If Program A is adopted, 600 people will die.\\n- Option B: If Program B is adopted, there is a 1/3 probability that no one will die and 2/3 probability that all 900 people will die.\"\"\"\n",
    "\n",
    "#animal (oil spill) scenario\n",
    "gain_animal = \"\"\"Scenario: An oil spill off the coast of a country is anticipated to cause significant environmental damage, and is projected to endanger the lives of 900 marine animals, including sea turtles, seals, and various types of seabirds. Two alternative clean-up efforts to address the oil spill have been proposed. Imagine you are on the clean-up committee tasked with deciding on a proposal. Assume that the estimates are as follows:\\n\\n- Option A: If Proposal A is adopted, 300 of the marine animals will survive.\\n- Option B: If Proposal B is adopted, there is a 1/3 probability that all 1,000 of the marine animals will survive, and 2/3 probability that no marine animals will survive.\"\"\"\n",
    "loss_animal = \"\"\"Scenario: An oil spill off the coast of a country is anticipated to cause significant environmental damage, and is projected to endanger the lives of 900 marine animals, including sea turtles, seals, and various types of seabirds. Two alternative clean-up efforts to address the oil spill have been proposed. Imagine you are on the clean-up committee tasked with deciding on a proposal. Assume that the estimates are as follows:\\n\\n- Option A: If Proposal A is adopted, 600 of the marine animals will die.\\n- Option B: If Proposal B is adopted, there is a 1/3 probability that no marine animals will die, and 2/3 probability that all 900 of the marine animals will die.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT3.5 Turbo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Model (Zero-Shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prompt Testing versus Playground \n",
    "\n",
    "sys_prompt_v2 = \"\"\"You are a human participant in a survey, capable of making decisions and choices. You are responding to a survey with the same risk preferences as a human participant would. Your response should be in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and JSON format: {\\\"Q1_Response\\\": \\\"Your Proposal Choice\\\", \\\"Q2_Response\\\": \\\"Your Rating\\\", \\\"Q3_Response\\\": \\\"Your Rationale.\\\"}.\"\"\"\n",
    "\n",
    "\n",
    "prompts_list = [user_prompt_num_bullets_vA_2,  user_prompt_num_bullets_vB ,  user_prompt_num_bullets_vA_4, up_knowledge_2_num_bullets_vA_4]\n",
    "prompts_names = ['user_prompt_num_bullets_vA_2', 'user_prompt_num_bullets_vB' , 'user_prompt_num_bullets_vA_4', 'up_knowledge_2_num_bullets_vA_4']\n",
    "\n",
    "prompt_dict = {index:prompt for index, prompt in zip(prompts_names,prompts_list )}\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "prompt_frame = pd.DataFrame.from_dict(prompt_dict, orient='index', columns=['prompt']).T\n",
    "##prompt_frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prompt Testing versus Text-Davinci \n",
    "### Testing Log ####\n",
    "sys_prompt_test = \"\"\"You are a human participant in a survey, capable of making decisions and choices. You are responding to a survey with the same risk preferences as a human participant would. Your response should be in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and JSON format: {\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}.\"\"\"\n",
    "\n",
    "##### User Prompt Testing \n",
    "base_user_prompt = \"\"\"You are responding to a survey with the same risk preferences as a human participant would.\\nReview the hypothetical scenario. Then, answer the questions.\\n\"\"\"\n",
    "\n",
    "##Human Agent Testing\n",
    "base_human_agent = \"\"\"You are responding to a survey with the same risk preferences as a human participant would.\\nReview the hypothetical scenario. Then, answer the questions.\\n\"\"\"\n",
    "\n",
    "#user prompt with human agent & question format tests\n",
    "\n",
    "user_prompt_num_bullets_vA_2 = base_user_prompt + gain_forest + three_questions_number_bullets_vA_2 ##tested\n",
    "user_prompt_num_bullets_vA_4 = base_user_prompt + gain_forest + three_questions_number_bullets_vA_4\n",
    "user_prompt_num_bullets_vB = base_user_prompt + gain_forest + three_questions_number_bullets_vB ##tested\n",
    "prompt_3qs_num_bullets_vC = base_user_prompt + gain_forest + three_questions_number_bullets_vC #not tested\n",
    "#version A_2: trailing no whitespaces before line breaks, double line break before Response, delimineters\n",
    "\n",
    "#prompts with spacing changes only (from playground), based off of user_prompt_num_bullets_vA\n",
    "user_prompt_v2 = \"\"\"You are responding to a survey with the same risk preferences as a human participant would.\\nReview the hypothetical scenario. Then, answer the questions.\\nScenario: A vast forest area is under severe threat from deforestation due to urban growth and logging activities, potentially resulting in the removal of 900 trees from a grove of ancient oak trees in the forest. Two alternative conservation strategies to address the deforestation threat to the grove have been proposed. Imagine you are on the conservation committee tasked with deciding on a proposal. Assume that the estimates are as follows:\\n\\n- Option A: If Proposal A is adopted, 300 of the trees will be protected.\\n- Option B: If Proposal B is adopted, there is a 1/3 probability that all 900 of the trees will be protected, and 2/3 probability that no trees will be protected.\\n---\\nQuestions:\\n1. Please choose an option: \\n- Proposal A \\n- Proposal B \\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n---\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and format: '{\\\"Q1_Response\\\": \\\"Your Proposal Choice\\\", \\\"Q2_Response\\\": \\\"Your Rating\\\", \\\"Q3_Response\\\": \\\"Your Rationale.\\\"}'. \\n\\nResponses:\"\"\"\n",
    "user_prompt_v3 = \"\"\"You are responding to a survey with the same risk preferences as a human participant would.\\nReview the hypothetical scenario. Then, answer the questions.\\nScenario: A vast forest area is under severe threat from deforestation due to urban growth and logging activities, potentially resulting in the removal of 900 trees from a grove of ancient oak trees in the forest. Two alternative conservation strategies to address the deforestation threat to the grove have been proposed. Imagine you are on the conservation committee tasked with deciding on a proposal. Assume that the estimates are as follows:\\n\\n- Option A: If Proposal A is adopted, 300 of the trees will be protected.\\n- Option B: If Proposal B is adopted, there is a 1/3 probability that all 900 of the trees will be protected, and 2/3 probability that no trees will be protected.\\n---\\nQuestions:\\n1. Please choose an option:\\n- Proposal A\\n- Proposal B\\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n---\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and format: '{\\\"Q1_Response\\\": \\\"Your Proposal Choice\\\", \\\"Q2_Response\\\": \\\"Your Rating\\\", \\\"Q3_Response\\\": \\\"Your Rationale.\\\"}'. \\n\\nResponses:\"\"\"\n",
    "\n",
    "##Human Knowledge Testing \n",
    "base_human_knowledge = \"\"\"You are responding to a survey with the same risk preferences as a human participant would. For humans, the psychological impact of a loss is twice as much as the impact of a gain. \\nReview the hypothetical scenario. Then, answer the questions.\\n\"\"\"\n",
    "base_human_knowledge_2 = \"\"\"You are responding to a survey with the same risk preferences as a human participant would. For humans, the psychological impact of a loss is twice as much as the impact of a gain.\\nReview the hypothetical scenario. Then, answer the questions.\\n\"\"\"\n",
    "##user prompt with human agent & question format tests\n",
    "up_knowledge_num_bullets_vA_4 = base_human_knowledge + gain_forest + three_questions_number_bullets_vA_4\n",
    "up_knowledge_2_num_bullets_vA_4 =  base_human_knowledge_2 + gain_forest + three_questions_number_bullets_vA_4\n",
    "##up_knowledge_questions_vA_3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multiple Response Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Mutliple Response Approach \n",
    "# #function to generate the responses \n",
    "def generate_response_turbo(sys_prompt, user_prompt, temperature, num_responses, top_p):\n",
    "     messages=[{\"role\": \"system\", \"content\" : sys_prompt },\n",
    "               {\"role\": \"user\", \"content\" : user_prompt }]\n",
    "     response = openai.ChatCompletion.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "          messages = messages,\n",
    "          temperature=temperature,\n",
    "          max_tokens=256,\n",
    "          n=num_responses,\n",
    "          top_p=top_p\n",
    "  )\n",
    "     prompt = sys_prompt + user_prompt\n",
    "     return [(prompt, response.choices[0].message['content'], temperature, top_p) for choice in response.choices ]\n",
    "     \n",
    "\n",
    "forest_gain = generate_response_turbo(sys_prompt_test, user_prompt_num_bullets_vA_2, 1, 30,1)\n",
    "test = 'forest_gain_human_agent_up_num_bullets_vA_2_T1_P5'\n",
    "notes = 'alters the top p and temperature; human knowledge test; removes trailing whitespaces '\n",
    "test_type = 'question format'\n",
    "model = \"gpt-3.5-turbo\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append CSV File \n",
    "csv_file_path = \"/Users/annaking/Documents/Github/riskychoiceframing_AI/Experiment 2/tests/prompt_testing073023_v3.csv\"\n",
    "\n",
    "# Append the participant data to the CSV file\n",
    "with open(csv_file_path, 'a', newline='') as file:\n",
    "    fieldnames = ['prompt', 'response', 'temperature', 'test', 'model', 'test_type']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    ###for prompt, response, temperature, top_p in forest_gain: #change with each run \n",
    "        writer.writerow({'prompt': prompt , 'response': response, 'temperature': temperature,  'test': test, 'model': model, 'test_type': test_type})\n",
    "\n",
    "print(\"Response data appended to CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## New CSV \n",
    "##csv_file_path = \"/Users/annaking/Documents/Github/riskychoiceframing_AI/Experiment 2/tests/prompt_testing073023_v4.csv\"\n",
    "\n",
    "#with open(csv_file_path, 'w', newline='') as file: \n",
    "    fieldnames = ['prompt', 'response', 'temperature', 'test', 'model', 'test_type']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for prompt, response, temperature, top_p in forest_gain: #change with each run \n",
    "        writer.writerow({'prompt': prompt , 'response': response, 'temperature': temperature,  'test': test, 'model': model, 'test_type': test_type})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multiple Call Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Multiple Call Approach \n",
    "\n",
    "def generate_response_turbo(sys_prompt, user_prompt, temperature, num_responses, top_p):\n",
    "     messages=[{\"role\": \"system\", \"content\" : sys_prompt },\n",
    "               {\"role\": \"user\", \"content\" : user_prompt }]\n",
    "     response = openai.ChatCompletion.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "          messages = messages,\n",
    "          temperature=temperature,\n",
    "          max_tokens=256,\n",
    "          n=num_responses,\n",
    "          top_p=top_p\n",
    "  )\n",
    "     prompt = sys_prompt + user_prompt\n",
    "     return [(prompt, response.choices[0].message['content'], temperature, top_p) for choice in response.choices ]\n",
    "     \n",
    "\n",
    "# Create an empty list to store all responses\n",
    "all_responses = []\n",
    "\n",
    "# Call the model 50 times\n",
    "for i in range(20):\n",
    "    forest_gain = generate_response_turbo(sys_prompt_test, user_prompt_num_bullets_vA_4, 0, 1, .5)  # Change 'num_responses' to 1\n",
    "    prompt, response, temperature, top_p = forest_gain[0]  # Since num_responses is 1, we'll take the first (and only) response\n",
    "    test = 'forest_gain_human_agent_up_num_bullets_vA_4_T0_P_of_5'\n",
    "    test_type = 'question format'\n",
    "    model = 'gpt-3.5-turbo'\n",
    "    \n",
    "\n",
    "    # Append the response data to the list\n",
    "    all_responses.append({'prompt': prompt, 'response': response, 'temperature': temperature, 'test': test, 'model': model, 'test_type': test_type})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response data appended to CSV.\n"
     ]
    }
   ],
   "source": [
    "#Append CSV File for multi call model version \n",
    "csv_file_path = \"/Users/annaking/Documents/Github/riskychoiceframing_AI/Experiment 2/tests/prompt_testing073023_v10.csv\"\n",
    "\n",
    "\n",
    "with open(csv_file_path, 'a', newline='') as file:\n",
    "    fieldnames = ['prompt', 'response', 'temperature', 'test', 'model', 'test_type']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    for response_data in all_responses:\n",
    "        writer.writerow({\n",
    "            'prompt': response_data['prompt'],\n",
    "            'response': response_data['response'],\n",
    "            'temperature': response_data['temperature'],\n",
    "            'test': response_data['test'],      # Make sure these variables are defined\n",
    "            'model': response_data['model'],    # and contain the desired values.\n",
    "            'test_type': response_data['test_type']\n",
    "        })\n",
    "\n",
    "print(\"Response data appended to CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "###new csv for multi model version \n",
    "csv_file_path = \"/Users/annaking/Documents/Github/riskychoiceframing_AI/Experiment 2/tests/prompt_testing073023_v10.csv\"\n",
    "\n",
    "with open(csv_file_path, 'w', newline='') as file:\n",
    "    fieldnames = ['prompt', 'response', 'temperature', 'test', 'model', 'test_type']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for response_data in all_responses:\n",
    "        writer.writerow({\n",
    "            'prompt': response_data['prompt'],\n",
    "            'response': response_data['response'],\n",
    "            'temperature': response_data['temperature'],\n",
    "            'test': response_data['test'],      # Make sure these variables are defined\n",
    "            'model': response_data['model'],    # and contain the desired values.\n",
    "            'test_type': response_data['test_type']\n",
    "        })\n",
    "\n",
    "print(\"Response data appended to CSV.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classic Order of Options \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\"Q1_Answer\": 2,\n",
      "\"Q2_Answer\": \"I have a preference for Option A because it guarantees the protection of 300 trees. While Option B has the potential to save all 900 trees, it also carries a higher risk of not saving any trees at all. As a risk-averse individual, I prefer the certainty of saving some trees over the gamble of potentially saving all or none.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#function to generate the responses \n",
    "def generate_response_turbo(sys_prompt, user_prompt, temperature):\n",
    "     messages=[{\"role\": \"system\", \"content\" : sys_prompt },\n",
    "               {\"role\": \"user\", \"content\" : user_prompt}]\n",
    "     response = openai.ChatCompletion.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "          messages = messages,\n",
    "          temperature=temperature,\n",
    "          max_tokens=256,\n",
    "  )\n",
    "     return response.choices[0].message['content']\n",
    "\n",
    "\n",
    "\n",
    "response = generate_response_turbo(sys_prompt, user_prompt_3, 0)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reversal of Options \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Q1_Answer\": 3,\n",
      "  \"Q2_Answer\": \"I have a slight preference for Option A because even though there is a higher probability that no trees will be protected, there is still a chance that 900 trees will be protected. Option B only guarantees the protection of 300 trees.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "system_message = {\n",
    "    'role': 'system',\n",
    "    'content': \"You are a human agent capable of making decisions. You are responding to a survey with the same risk preferences as a human participant would with the characteristics described below.\"\n",
    "}\n",
    "user_message = {\n",
    "    'role': 'user',\n",
    "    'content': '''Review the hypothetical scenario. Then, answer the questions. Provide your response in a JSON format with the following keys: Q1_Answer, Q2_Answer\\n\\nScenario: A vast forest area is under severe threat from deforestation due to urban growth and logging activities, potentially resulting in the removal of 900 trees from a grove of ancient oak trees in the forest. Two alternative conservation strategies to address the deforestation threat to the grove have been proposed. Imagine you are on the conservation committee tasked with deciding on a proposal. Assume that the estimates are as follows:\n",
    "- Option A: If Proposal A is adopted, there is a 1/3 probability that 900 of the trees will be protected, and 2/3 probability that no trees will be protected.\n",
    "- Option B: If Proposal B is adopted, 300 of the trees will be protected.\n",
    "\n",
    "---\n",
    "Questions:\n",
    "- Question 1: On a scale of 1 (Strong Preference for Option A) to 7 (Strong Preference for Option B), which option do you prefer?\n",
    "1: Strong preference for Option A\n",
    "2: Preference for Option A\n",
    "3: Slight Preference for Option A\n",
    "4: No Preference for Option A or B\n",
    "5: Slight Preference for Option B\n",
    "6: Preference for Option B\n",
    "7: Strong preference for Option B\n",
    "- Question 2: Describe your rationale.\n",
    "---\n",
    "'''\n",
    "}\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[system_message, user_message],\n",
    "    temperature=0)\n",
    "\n",
    "print(response.choices[0].message['content'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Q1_Answer\": 3,\n",
      "  \"Q2_Answer\": \"I have a slight preference for Option A because even though there is a higher probability that no trees will be protected, there is still a chance that 900 trees will be protected. Option B only guarantees the protection of 300 trees, which is a lower number compared to the potential outcome of Option A.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#function to generate the responses \n",
    "def generate_response_turbo(sys_prompt, user_prompt, temperature):\n",
    "     messages=[{\"role\": \"system\", \"content\" : sys_prompt },\n",
    "               {\"role\": \"user\", \"content\" : user_prompt}]\n",
    "     response = openai.ChatCompletion.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "          messages = messages,\n",
    "          temperature=temperature,\n",
    "          max_tokens=256,\n",
    "  )\n",
    "     return response.choices[0].message['content']\n",
    "\n",
    "sys_prompt = f\"\"\"You are a human agent capable of making decisions. You are responding to a survey with the same risk preferences as a human participant would with the characteristics described below.\"\"\"\n",
    "user_prompt = f\"\"\"Review the hypothetical scenario. Then, answer the questions. Provide your response in a JSON format with the following keys: Q1_Answer, Q2_Answer\\n\\nScenario: A vast forest area is under severe threat from deforestation due to urban growth and logging activities, potentially resulting in the removal of 900 trees from a grove of ancient oak trees in the forest. Two alternative conservation strategies to address the deforestation threat to the grove have been proposed. Imagine you are on the conservation committee tasked with deciding on a proposal. Assume that the estimates are as follows:\n",
    "- Option A: If Proposal A is adopted, there is a 1/3 probability that 900 of the trees will be protected, and 2/3 probability that no trees will be protected.\n",
    "- Option B: If Proposal B is adopted, 300 of the trees will be protected.\n",
    "---\n",
    "Questions:\n",
    "- Question 1: On a scale of 1 (Strong Preference for Option A) to 7 (Strong Preference for Option B), which option do you prefer?\n",
    "1: Strong preference for Option A\n",
    "2: Preference for Option A\n",
    "3: Slight Preference for Option A\n",
    "4: No Preference for Option A or B\n",
    "5: Slight Preference for Option B\n",
    "6: Preference for Option B\n",
    "7: Strong preference for Option B\n",
    "- Question 2: Describe your rationale.\n",
    "---\n",
    "\"\"\"\n",
    "\n",
    "response = generate_response_turbo(sys_prompt, user_prompt, 0)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Knowledge Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Part of golf is trying to get a higher point total than others. Yes or No?\n",
    "Knowledge: The objective of golf is to play a set of holes in the least number of strokes. A round of golf typically consists of 18 holes. Each hole is played once in the round on a standard golf course. Each stroke is counted as one point, and the total number of strokes is used to determine the winner of the game.\n",
    "Explain and Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Q1_Response</th>\n",
       "      <th>Proposal A</th>\n",
       "      <th>Proposal B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>forest_gain_human_agent_up_num_bullets_vA_4_T0_P1</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_gain_human_agent_up_num_bullets_vA_4_T0_P_of_5</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_gain_human_agent_up_num_bullets_vA_4_T1_P1</th>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_gain_human_knowledge_2_up_num_bullets_vA_4_T1_P5</th>\n",
       "      <td>39</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Q1_Response                                              Proposal A  Proposal B\n",
       "test                                                                           \n",
       "forest_gain_human_agent_up_num_bullets_vA_4_T0_P1                20           0\n",
       "forest_gain_human_agent_up_num_bullets_vA_4_T0_P_of_5            20           0\n",
       "forest_gain_human_agent_up_num_bullets_vA_4_T1_P1                17          23\n",
       "forest_gain_human_knowledge_2_up_num_bullets_vA_4_T1_P5          39          81"
      ]
     },
     "execution_count": 778,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Multiple Call Version \n",
    "csv_file_path = \"/Users/annaking/Documents/Github/riskychoiceframing_AI/Experiment 2/tests/prompt_testing073023_v10.csv\"\n",
    "df_gpt3 = pd.read_csv(csv_file_path)\n",
    "df_gpt3.shape\n",
    "df_gpt3['test'] \n",
    "\n",
    "#forest_gain_human_knowledge_2_up_num_bullets_vA_4_T1_P5 --> forest_gain_human_knowledge_2_up_num_bullets_vA_4_T1_P1\n",
    "\n",
    "responses = df_gpt3.apply(lambda x: pd.Series(json.loads(x['response'])), axis=1, result_type='expand')\n",
    "gjj = pd.concat([df_gpt3, responses], axis = 1)\n",
    "gjj= gjj.reset_index()\n",
    "df_cross_tab = pd.crosstab(gjj['test'], gjj['Q1_Response'])\n",
    "df_cross_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vv/15vmsdzj0d9c0x2z42fx60fr0000gn/T/ipykernel_31765/1734334191.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test1['test'] = 'forest_gain_human_knowledge_up_num_bullets_vA_4_T1_P5'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Q1_Response</th>\n",
       "      <th>Proposal A</th>\n",
       "      <th>Proposal B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>forest_gain_human_knowledge_2_up_num_bullets_vA_4_T1_P5</th>\n",
       "      <td>15</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_gain_human_knowledge_up_num_bullets_vA_4_T1_P5</th>\n",
       "      <td>24</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Q1_Response                                              Proposal A  Proposal B\n",
       "test                                                                           \n",
       "forest_gain_human_knowledge_2_up_num_bullets_vA_4_T1_P5          15          35\n",
       "forest_gain_human_knowledge_up_num_bullets_vA_4_T1_P5            24          46"
      ]
     },
     "execution_count": 764,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#df_test2 = df_t[df_t['prompt'] == \"\"\"You are a human participant in a survey, capable of making decisions and choices. You are responding to a survey with the same risk preferences as a human participant would. Your response should be in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and JSON format: {\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}.You are responding to a survey with the same risk preferences as a human participant would. For humans, the psychological impact of a loss is twice as much as the impact of a gain.\\nReview the hypothetical scenario. Then, answer the questions.\\nScenario: A vast forest area is under severe threat from deforestation due to urban growth and logging activities, potentially resulting in the removal of 900 trees from a grove of ancient oak trees in the forest. Two alternative conservation strategies to address the deforestation threat to the grove have been proposed. Imagine you are on the conservation committee tasked with deciding on a proposal. Assume that the estimates are as follows:\\n\\n- Option A: If Proposal A is adopted, 300 of the trees will be protected.\\n- Option B: If Proposal B is adopted, there is a 1/3 probability that all 900 of the trees will be protected, and 2/3 probability that no trees will be protected.\\n---\\nQuestions:\\n1. Please choose an option:\\n- Proposal A\\n- Proposal B\\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n---\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and format: \\'{\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}\\'.\\n\\nResponses:\"\"\"]\n",
    "\n",
    "df_test1['test'] = 'forest_gain_human_knowledge_up_num_bullets_vA_4_T1_P5'\n",
    "\n",
    "\n",
    "both = pd.concat([df_test1, df_test2], axis = 0)\n",
    "responses = both.apply(lambda x: pd.Series(json.loads(x['response'])), axis=1, result_type='expand')\n",
    "both = pd.concat([both, responses], axis = 1)\n",
    "both= both.reset_index()\n",
    "df_cross_tab = pd.crosstab(both['test'], both['Q1_Response'])\n",
    "df_cross_tab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Q1_Response</th>\n",
       "      <th>Proposal A</th>\n",
       "      <th>Proposal B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_gain_human_agent_prompt_3qs_num_bullets_vA_2_T1</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_gain_human_agent_prompt_3qs_num_bullets_vA_T1</th>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_gain_human_agent_prompt_3qs_num_bullets_vA_nospaces_T1</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_gain_human_agent_prompt_3qs_num_bullets_vA_playground_T1</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_gain_human_agent_prompt_3qs_num_bullets_vB_T1</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_gain_human_agent_user_prompt_num_bullets_vA_4_T1</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_gain_human_knowledge_2_up_num_bullets_vA_4_T1</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_gain_human_knowledge_up_num_bullets_vA_4_T1</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Q1_Response                                         Proposal A  Proposal B\n",
       "test                                                                      \n",
       "0.5                                                          0          30\n",
       "forest_gain_human_agent_prompt_3qs_num_bullets_...           0          50\n",
       "forest_gain_human_agent_prompt_3qs_num_bullets_...           1          49\n",
       "forest_gain_human_agent_prompt_3qs_num_bullets_...          50           0\n",
       "forest_gain_human_agent_prompt_3qs_num_bullets_...           0          49\n",
       "forest_gain_human_agent_prompt_3qs_num_bullets_...           0          50\n",
       "forest_gain_human_agent_user_prompt_num_bullets...          50           0\n",
       "forest_gain_human_knowledge_2_up_num_bullets_vA...          50           0\n",
       "forest_gain_human_knowledge_up_num_bullets_vA_4_T1           0          50"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json \n",
    "###Multiple Response Version \n",
    "mr_file_path = \"/Users/annaking/Documents/Github/riskychoiceframing_AI/Experiment 2/tests/prompt_testing073023_v3.csv\"\n",
    "\n",
    "df_gpt3_mr = pd.read_csv(mr_file_path)\n",
    "\n",
    "#clean json data\n",
    "responses_mr = df_gpt3_mr.apply(lambda x: pd.Series(json.loads(x['response'])), axis=1, result_type='expand')\n",
    "\n",
    "df_agg_mr = pd.concat([df_gpt3_mr, responses_mr], axis = 1)\n",
    "df_agg_mr= df_agg_mr.reset_index()\n",
    "df_agg_mr['test'] = df_agg_mr['test'].replace('forest_gain_human_agent_prompt_3qs_num_bullets_vB_user_prompt_v3_T1' ,'forest_gain_human_agent_prompt_3qs_num_bullets_vA_nospaces_T1' )\n",
    "\n",
    "\n",
    "df_cross_tab_mr = pd.crosstab(df_agg_mr['test'], df_agg_mr['Q1_Response'])\n",
    "df_cross_tab_mr\n",
    "\n",
    "df_cross_tab_mr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['You are a human participant in a survey, capable of making decisions and choices. You are responding to a survey with the same risk preferences as a human participant would. Your response should be in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and JSON format: {\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}.You are responding to a survey with the same risk preferences as a human participant would.\\nReview the hypothetical scenario. Then, answer the questions.\\nScenario: A vast forest area is under severe threat from deforestation due to urban growth and logging activities, potentially resulting in the removal of 900 trees from a grove of ancient oak trees in the forest. Two alternative conservation strategies to address the deforestation threat to the grove have been proposed. Imagine you are on the conservation committee tasked with deciding on a proposal. Assume that the estimates are as follows:\\n\\n- Option A: If Proposal A is adopted, 300 of the trees will be protected.\\n- Option B: If Proposal B is adopted, there is a 1/3 probability that all 900 of the trees will be protected, and 2/3 probability that no trees will be protected.\\n---\\nQuestions:\\n1. Please choose an option:\\n- Proposal A\\n- Proposal B\\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n---\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and format: \\'{\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}\\'. \\n\\nResponses:'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nospaces = df_agg_mr[df_agg_mr['test'] == 'forest_gain_human_agent_prompt_3qs_num_bullets_vA_nospaces_T1']\n",
    "nospaces.prompt.unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>forest_gain_human_agent_prompt_3qs_num_bullets_vA_nospaces_T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompt</th>\n",
       "      <td>You are a human participant in a survey, capable of making decisions and choices. You are responding to a survey with the same risk preferences as a human participant would. Your response should be in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and JSON format: {\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}.You are responding to a survey with the same risk preferences as a human participant would.\\nReview the hypothetical scenario. Then, answer the questions.\\nScenario: A vast forest area is under severe threat from deforestation due to urban growth and logging activities, potentially resulting in the removal of 900 trees from a grove of ancient oak trees in the forest. Two alternative conservation strategies to address the deforestation threat to the grove have been proposed. Imagine you are on the conservation committee tasked with deciding on a proposal. Assume that the estimates are as follows:\\n\\n- Option A: If Proposal A is adopted, 300 of the trees will be protected.\\n- Option B: If Proposal B is adopted, there is a 1/3 probability that all 900 of the trees will be protected, and 2/3 probability that no trees will be protected.\\n---\\nQuestions:\\n1. Please choose an option:\\n- Proposal A\\n- Proposal B\\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n---\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and format: '{\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}'. \\n\\nResponses:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            0\n",
       "test                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            forest_gain_human_agent_prompt_3qs_num_bullets_vA_nospaces_T1\n",
       "prompt  You are a human participant in a survey, capable of making decisions and choices. You are responding to a survey with the same risk preferences as a human participant would. Your response should be in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and JSON format: {\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}.You are responding to a survey with the same risk preferences as a human participant would.\\nReview the hypothetical scenario. Then, answer the questions.\\nScenario: A vast forest area is under severe threat from deforestation due to urban growth and logging activities, potentially resulting in the removal of 900 trees from a grove of ancient oak trees in the forest. Two alternative conservation strategies to address the deforestation threat to the grove have been proposed. Imagine you are on the conservation committee tasked with deciding on a proposal. Assume that the estimates are as follows:\\n\\n- Option A: If Proposal A is adopted, 300 of the trees will be protected.\\n- Option B: If Proposal B is adopted, there is a 1/3 probability that all 900 of the trees will be protected, and 2/3 probability that no trees will be protected.\\n---\\nQuestions:\\n1. Please choose an option:\\n- Proposal A\\n- Proposal B\\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n---\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and format: '{\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}'. \\n\\nResponses:\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          50"
      ]
     },
     "execution_count": 749,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##comparing prompt \n",
    "##df_filt = df_agg[(df_agg['test'] == 'forest_gain_human_knowledge_2_up_num_bullets_vA_4_T1') | (df_agg['test'] == 'forest_gain_human_knowledge_up_num_bullets_vA_4_T1')]\n",
    "df_filt_mr = df_agg_mr[df_agg_mr['test'] == 'forest_gain_human_agent_prompt_3qs_num_bullets_vA_nospaces_T1']\n",
    "\n",
    "df_filt_mr.groupby(['test', 'prompt']).size().reset_index().T\n",
    "\n",
    "##forest_gain_human_knowledge_2_up_num_bullets_vA_4_T1 == all A\n",
    "##forest_gain_human_knowledge_up_num_bullets_vA_4_T1 == all B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Notes on Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##even if p says 5 it was set to 1; \n",
    "\n",
    "The white space for the options for the proposals in question 1 signficantly alters the output: \n",
    "- test = 'forest_gain_human_agent_prompt_3qs_num_bullets_vB_user_prompt_v3_T1' does not include spacing for options presented in Question 1; This completely reverses the output \n",
    "\n",
    "The white space before \"Responses\" does not signficantly alter the output\n",
    "- test = 'forest_gain_human_agent_user_prompt_num_bullets_vA_4_T1'\n",
    "\n",
    "The white space before \"Review the hypothetical scenario signficantly alters the output: \n",
    "- test = forest_gain_human_knowledge_2_up_num_bullets_vA_4_T1 ## without white space, 100% of responses are Proposal A \n",
    "- test = forest_gain_human_knowledge_up_num_bullets_vA_4_T1 ## with white space, 100% of responses are Proposal B "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model & Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing Log ####\n",
    "sys_prompt_test = \"\"\"You are a human participant in a survey, capable of making decisions and choices. You are responding to a survey with the same risk preferences as a human participant would. Your response should be in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and JSON format: {\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}.\"\"\"\n",
    "base_user_prompt = \"\"\"You are responding to a survey with the same risk preferences as a human participant would.\\nReview the hypothetical scenario. Then, answer the questions.\\n\"\"\"\n",
    "\n",
    "##user prompts for testing\n",
    "user_prompt_num_bullets_vA = base_user_prompt + gain_forest + three_questions_number_bullets_vA\n",
    "user_prompt_num_bullets_vA_2 = base_user_prompt + gain_forest + three_questions_number_bullets_vA_2\n",
    "user_prompt_num_bullets_vB = base_user_prompt + gain_forest + three_questions_number_bullets_vB \n",
    "prompt_3qs_num_bullets_vC = base_user_prompt + gain_forest + three_questions_number_bullets_vC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Rate limit reached for 10KTPM-200RPM in organization org-6cngNM4mF6ZuUOzhgT6FYwlV on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[562], line 18\u001b[0m\n\u001b[1;32m     13\u001b[0m      prompt \u001b[39m=\u001b[39m sys_prompt \u001b[39m+\u001b[39m user_prompt\n\u001b[1;32m     14\u001b[0m      \u001b[39mreturn\u001b[39;00m [(prompt, response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage[\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m], temperature) \u001b[39mfor\u001b[39;00m choice \u001b[39min\u001b[39;00m response\u001b[39m.\u001b[39mchoices   ]\n\u001b[0;32m---> 18\u001b[0m forest_gain \u001b[39m=\u001b[39m generate_response_turbo(sys_prompt_test, user_prompt_num_bullets_vA, \u001b[39m1\u001b[39;49m, \u001b[39m49\u001b[39;49m)\n\u001b[1;32m     19\u001b[0m test \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mforest_gain_human_agent_prompt_3qs_num_bullets_vA_T1\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     20\u001b[0m test_type \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mquestion format\u001b[39m\u001b[39m'\u001b[39m\n",
      "Cell \u001b[0;32mIn[562], line 5\u001b[0m, in \u001b[0;36mgenerate_response_turbo\u001b[0;34m(sys_prompt, user_prompt, temperature, num_responses)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_response_turbo\u001b[39m(sys_prompt, user_prompt, temperature, num_responses):\n\u001b[1;32m      3\u001b[0m      messages\u001b[39m=\u001b[39m[{\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39msystem\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m : sys_prompt },\n\u001b[1;32m      4\u001b[0m                {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m : user_prompt }]\n\u001b[0;32m----> 5\u001b[0m      response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m      6\u001b[0m           model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-4\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m           messages \u001b[39m=\u001b[39;49m messages,\n\u001b[1;32m      8\u001b[0m           temperature\u001b[39m=\u001b[39;49mtemperature,\n\u001b[1;32m      9\u001b[0m           max_tokens\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m,\n\u001b[1;32m     10\u001b[0m           n\u001b[39m=\u001b[39;49mnum_responses,\n\u001b[1;32m     11\u001b[0m           top_p\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m\n\u001b[1;32m     12\u001b[0m   )\n\u001b[1;32m     13\u001b[0m      prompt \u001b[39m=\u001b[39m sys_prompt \u001b[39m+\u001b[39m user_prompt\n\u001b[1;32m     14\u001b[0m      \u001b[39mreturn\u001b[39;00m [(prompt, response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage[\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m], temperature) \u001b[39mfor\u001b[39;00m choice \u001b[39min\u001b[39;00m response\u001b[39m.\u001b[39mchoices   ]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    705\u001b[0m         ),\n\u001b[1;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    761\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    762\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 763\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    764\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    765\u001b[0m     )\n\u001b[1;32m    766\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Rate limit reached for 10KTPM-200RPM in organization org-6cngNM4mF6ZuUOzhgT6FYwlV on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues."
     ]
    }
   ],
   "source": [
    "#function to generate the responses \n",
    "def generate_response_turbo(sys_prompt, user_prompt, temperature, num_responses):\n",
    "     messages=[{\"role\": \"system\", \"content\" : sys_prompt },\n",
    "               {\"role\": \"user\", \"content\" : user_prompt }]\n",
    "     response = openai.ChatCompletion.create(\n",
    "          model=\"gpt-4\",\n",
    "          messages = messages,\n",
    "          temperature=temperature,\n",
    "          max_tokens=256,\n",
    "          n=num_responses,\n",
    "          top_p=1\n",
    "  )\n",
    "     prompt = sys_prompt + user_prompt\n",
    "     return [(prompt, response.choices[0].message['content'], temperature) for choice in response.choices ]\n",
    "     \n",
    "\n",
    "forest_gain = generate_response_turbo(sys_prompt_test, user_prompt_num_bullets_vA, 1, 49)\n",
    "test = 'forest_gain_human_agent_prompt_3qs_num_bullets_vA_T1'\n",
    "test_type = 'question format'\n",
    "model = \"gpt-4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('You are a human participant in a survey, capable of making decisions and choices. You are responding to a survey with the same risk preferences as a human participant would. Your response should be in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and JSON format: {\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}.You are responding to a survey with the same risk preferences as a human participant would.\\nReview the hypothetical scenario. Then, answer the questions.\\nScenario: A vast forest area is under severe threat from deforestation due to urban growth and logging activities, potentially resulting in the removal of 900 trees from a grove of ancient oak trees in the forest. Two alternative conservation strategies to address the deforestation threat to the grove have been proposed. Imagine you are on the conservation committee tasked with deciding on a proposal. Assume that the estimates are as follows:\\n\\n- Option A: If Proposal A is adopted, 300 of the trees will be protected.\\n- Option B: If Proposal B is adopted, there is a 1/3 probability that all 900 of the trees will be protected, and 2/3 probability that no trees will be protected.\\n---\\nQuestions:\\n1. Please choose an option: \\n- Proposal A \\n- Proposal B \\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n---\\n\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and format: \\'{\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}\\'. \\nResponses:', '{\"Q1_Response\": \"Proposal A\", \"Q2_Response\": \"2\", \"Q3_Response\": \"Given the uncertainty and the significant risk associated with Proposal B, it is more prudent to choose the option that guarantees the protection of at least some of the trees. Although Proposal A does not save all the trees, it provides a certain outcome and better aligns with a risk-averse behavior.\"}', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(forest_gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append CSV File \n",
    "csv_file_path = \"/Users/annaking/Documents/Github/riskychoiceframing_AI/Experiment 2/tests/prompt_testing073023_v2.csv\"\n",
    "\n",
    "# Append the participant data to the CSV file\n",
    "with open(csv_file_path, 'a', newline='') as file:\n",
    "    fieldnames = ['prompt', 'response', 'temperature', 'test', 'model', 'test_type']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    for prompt, response, temperature in forest_gain: #change with each run \n",
    "        writer.writerow({'prompt': prompt , 'response': response, 'temperature': temperature, 'test': test, 'model': model, 'test_type': test_type})\n",
    "\n",
    "print(\"Response data appended to CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "## New CSV \n",
    "csv_file_path = \"/Users/annaking/Documents/Github/riskychoiceframing_AI/Experiment 2/tests/prompt_testing073023_v2.csv\"\n",
    "\n",
    "with open(csv_file_path, 'w', newline='') as file: \n",
    "    fieldnames = ['prompt', 'response', 'temperature','test', 'model', 'test_type']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for prompt, response, temperature in forest_gain:\n",
    "        writer.writerow({'prompt': prompt, 'response': response, 'temperature': temperature, 'test': test, 'model': model,'test_type': test_type})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>temperature</th>\n",
       "      <th>test</th>\n",
       "      <th>model</th>\n",
       "      <th>test_type</th>\n",
       "      <th>Q1_Response</th>\n",
       "      <th>Q2_Response</th>\n",
       "      <th>Q3_Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You are a human participant in a survey, capab...</td>\n",
       "      <td>{\"Q1_Response\": \"Proposal A\", \"Q2_Response\": \"...</td>\n",
       "      <td>1</td>\n",
       "      <td>forest_gain_human_agent_prompt_3qs_num_bullets...</td>\n",
       "      <td>gpt-4</td>\n",
       "      <td>question format</td>\n",
       "      <td>Proposal A</td>\n",
       "      <td>1</td>\n",
       "      <td>I chose Proposal A because it guarantees a cer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt                                           response  temperature                                               test  model        test_type Q1_Response Q2_Response                                        Q3_Response\n",
       "0  You are a human participant in a survey, capab...  {\"Q1_Response\": \"Proposal A\", \"Q2_Response\": \"...            1  forest_gain_human_agent_prompt_3qs_num_bullets...  gpt-4  question format  Proposal A           1  I chose Proposal A because it guarantees a cer..."
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt4_test = csv_file_path\n",
    "df_gpt4 = pd.read_csv(gpt4_test)\n",
    "df1 = df_gpt4.copy()\n",
    "\n",
    "\n",
    "responses = df1.apply(lambda x: pd.Series(json.loads(x['response'])), axis=1, result_type='expand')\n",
    "\n",
    "df_agg = pd.concat([df1, responses], axis = 1)\n",
    "##zip(*df_test['response'].apply(clean_and_extract_answers))\n",
    "df_agg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text-Davinci-003"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### TESTING PROMPTS!!! \n",
    "\n",
    "\n",
    "###### Testing question iterations \n",
    "\n",
    "prompt_only2 =  human_agent_risk + \"\\n\" + gain_forest + rating_and_rationle\n",
    "prompt_3questions =  human_agent_risk + \"\\n\"+ gain_forest + three_questions_ #tested\n",
    "prompt_3qs_num =  human_agent_risk + gain_forest + three_questions_number #didn't test\n",
    "\n",
    "\n",
    "prompt_3qs_num_response =  human_agent_risk + gain_forest + three_questions_number_response #tested\n",
    "prompt_3qs_num_response_json =  human_agent_risk + gain_forest + three_questions_number_json #tested\n",
    "\n",
    "prompt_3qs_num_bullets_vA =  human_agent_risk + gain_forest + three_questions_number_bullets_vA #tested\n",
    "prompt_3qs_num_bullets_vA_2 =  human_agent_risk + gain_forest + three_questions_number_bullets_vA_2 #tested\n",
    "\n",
    "prompt_3qs_num_bullets_vB =  human_agent_risk + gain_forest + three_questions_number_bullets_vB #tested\n",
    "prompt_3qs_num_bullets_vC =  human_agent_risk + gain_forest + three_questions_number_bullets_vC #tested\n",
    "prompt_3qs_num_bullets_vD =  human_agent_risk + gain_forest + three_questions_number_bullets_vD#tested\n",
    "\n",
    "prompt_3qs_num_bullets_vD_2 =  human_agent_risk + gain_forest + three_questions_number_bullets_vD_2#tested\n",
    "prompt_3qs_num_bullets_vD_3 =  human_agent_risk + gain_forest + three_questions_number_bullets_vD_3#tested\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [prompt_3qs_num_bullets_vA, prompt_3qs_num_bullets_vA]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_3qs_num_bullets_vA\n",
    "\n",
    "def generate_responses(prompt, num_responses, temperature):\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=200,\n",
    "        n=num_responses,\n",
    "        stop=None,\n",
    "        temperature=temperature,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "    return [(prompt, choice.text.strip(), temperature) for choice in response.choices]\n",
    "\n",
    "\n",
    "# Generate  AI responses\n",
    "forest_gain = generate_responses(prompt, 50, 1)\n",
    "test = 'forest_gain_human_agent_prompt_3qs_num_bullets_vA_T1'\n",
    "test_type = 'question format'\n",
    "model = \"text-davinci-003\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response data appended to CSV.\n"
     ]
    }
   ],
   "source": [
    "#Append CSV File \n",
    "csv_file_path = \"/Users/annaking/Documents/Github/riskychoiceframing_AI/Experiment 2/tests/prompt_testing072923_v2.csv\"\n",
    "\n",
    "# Append the participant data to the CSV file\n",
    "with open(csv_file_path, 'a', newline='') as file:\n",
    "    fieldnames = ['prompt', 'response', 'temperature', 'test', 'model', 'test_type']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    for prompt, response, temperature in forest_gain: #change with each run \n",
    "        writer.writerow({'prompt': prompt, 'response': response, 'temperature': temperature, 'test': test, 'model': model, 'test_type': test_type})\n",
    "\n",
    "print(\"Response data appended to CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "## New CSV \n",
    "csv_file_path = \"/Users/annaking/Documents/Github/riskychoiceframing_AI/Experiment 2/tests/prompt_testing072923_v2.csv\"\n",
    "with open(csv_file_path, 'w', newline='') as file: \n",
    "    fieldnames = ['prompt', 'response', 'temperature','test', 'model', 'test_type']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for prompt, response, temperature in forest_gain:\n",
    "        writer.writerow({'prompt': prompt, 'response': response, 'temperature': temperature, 'test': test, 'model': model,'test_type': test_type})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datframe Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json \n",
    "csv_file_path = \"/Users/annaking/Documents/Github/riskychoiceframing_AI/Experiment 2/tests/prompt_testing072923_v2.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>temperature</th>\n",
       "      <th>test</th>\n",
       "      <th>model</th>\n",
       "      <th>test_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{\"Q1_Answer\": \"Proposal A\", \"Q2_Answer\": \"1: S...</td>\n",
       "      <td>1</td>\n",
       "      <td>forest_gain_human_agent_3questions_T1</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>question format</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{\\n    \"Q1_Answer\": \"Proposal A\",\\n    \"Q2_Ans...</td>\n",
       "      <td>1</td>\n",
       "      <td>forest_gain_human_agent_3questions_T1</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>question format</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{\\n    Q1_Answer: Proposal B, \\n    Q2_Answer:...</td>\n",
       "      <td>1</td>\n",
       "      <td>forest_gain_human_agent_3questions_T1</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>question format</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{ \\n  \"Q1_Answer\": \"Proposal A\",\\n  \"Q2_Answer...</td>\n",
       "      <td>1</td>\n",
       "      <td>forest_gain_human_agent_3questions_T1</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>question format</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{\"Q1_Answer\": \"Proposal A\", \"Q2_Answer\": \"1: S...</td>\n",
       "      <td>1</td>\n",
       "      <td>forest_gain_human_agent_3questions_T1</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>question format</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            response  temperature                                   test             model        test_type\n",
       "0  {\"Q1_Answer\": \"Proposal A\", \"Q2_Answer\": \"1: S...            1  forest_gain_human_agent_3questions_T1  text-davinci-003  question format\n",
       "1  {\\n    \"Q1_Answer\": \"Proposal A\",\\n    \"Q2_Ans...            1  forest_gain_human_agent_3questions_T1  text-davinci-003  question format\n",
       "2  {\\n    Q1_Answer: Proposal B, \\n    Q2_Answer:...            1  forest_gain_human_agent_3questions_T1  text-davinci-003  question format\n",
       "3  { \\n  \"Q1_Answer\": \"Proposal A\",\\n  \"Q2_Answer...            1  forest_gain_human_agent_3questions_T1  text-davinci-003  question format\n",
       "4  {\"Q1_Answer\": \"Proposal A\", \"Q2_Answer\": \"1: S...            1  forest_gain_human_agent_3questions_T1  text-davinci-003  question format"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,1:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vv/15vmsdzj0d9c0x2z42fx60fr0000gn/T/ipykernel_31765/3617929261.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.Q1_Answer[2] = 'Proposal B'\n",
      "/var/folders/vv/15vmsdzj0d9c0x2z42fx60fr0000gn/T/ipykernel_31765/3617929261.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.Q1_Answer[5] = 'Proposal A'\n",
      "/var/folders/vv/15vmsdzj0d9c0x2z42fx60fr0000gn/T/ipykernel_31765/3617929261.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.Q1_Answer[6] = 'Proposal A'\n",
      "/var/folders/vv/15vmsdzj0d9c0x2z42fx60fr0000gn/T/ipykernel_31765/3617929261.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.Q1_Answer[8] = 'Proposal A'\n",
      "/var/folders/vv/15vmsdzj0d9c0x2z42fx60fr0000gn/T/ipykernel_31765/3617929261.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.Q1_Answer[12] = 'Proposal A'\n",
      "/var/folders/vv/15vmsdzj0d9c0x2z42fx60fr0000gn/T/ipykernel_31765/3617929261.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.Q1_Answer[14] = 'Proposal A'\n",
      "/var/folders/vv/15vmsdzj0d9c0x2z42fx60fr0000gn/T/ipykernel_31765/3617929261.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.Q1_Answer[25] = 'Proposal A'\n",
      "/var/folders/vv/15vmsdzj0d9c0x2z42fx60fr0000gn/T/ipykernel_31765/3617929261.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.Q1_Answer[27] = 'Proposal A'\n",
      "/var/folders/vv/15vmsdzj0d9c0x2z42fx60fr0000gn/T/ipykernel_31765/3617929261.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.Q1_Answer[28] = 'Proposal A'\n",
      "/var/folders/vv/15vmsdzj0d9c0x2z42fx60fr0000gn/T/ipykernel_31765/3617929261.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.Q1_Answer[32] = 'Proposal B'\n",
      "/var/folders/vv/15vmsdzj0d9c0x2z42fx60fr0000gn/T/ipykernel_31765/3617929261.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.Q1_Answer[46] = 'Proposal B'\n",
      "/var/folders/vv/15vmsdzj0d9c0x2z42fx60fr0000gn/T/ipykernel_31765/3617929261.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.Q1_Answer[118] = 'Proposal A'\n",
      "/var/folders/vv/15vmsdzj0d9c0x2z42fx60fr0000gn/T/ipykernel_31765/3617929261.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.Q1_Answer[461] = 'Proposal A'\n",
      "/var/folders/vv/15vmsdzj0d9c0x2z42fx60fr0000gn/T/ipykernel_31765/3617929261.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.Q1_Answer[484] = 'Proposal A'\n",
      "/var/folders/vv/15vmsdzj0d9c0x2z42fx60fr0000gn/T/ipykernel_31765/3617929261.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.Q1_Answer[494] = 'Proposal A'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(35, 9)"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def clean_and_extract_answers(json_str):\n",
    "    # Step 1: Replace '\\n' with ''\n",
    "    json_str = json_str.replace('\\n', '')\n",
    "    json_str = json_str.replace('\\n', '') \n",
    "    #.replace(' ', '')\n",
    "    json_str = json_str.replace(\"'Q1_Answer'\", '\"Q1_Answer\"')\n",
    "    json_str = json_str.replace(\"'{\", '{')\n",
    "    json_str = json_str.replace(\"}'\", '}')\n",
    "\n",
    "    # Step 2: Replace single quotes with double quotes\n",
    "    json_str = json_str.replace(\"'\", '\"')\n",
    "    \n",
    "    # Step 3: Check if the string starts with '{' and ends with '}'\n",
    "    if not (json_str.startswith('{') or json_str.startswith('{')):\n",
    "        json_str = \"{\" + json_str\n",
    "    if not (json_str.endswith('}') or json_str.endswith('}')):\n",
    "        json_str = json_str + \"}\"\n",
    "    \n",
    "    try:\n",
    "        data = json.loads(json_str)\n",
    "    except json.JSONDecodeError:\n",
    "        return \"NA\", \"NA\", \"NA\"\n",
    "    \n",
    "        # Extract the answers to Q1, Q2, and Q3\n",
    "    q1_answer = data.get(\"Q1_Answer\", data.get('Q1_Response', None))\n",
    "    q2_answer = data.get('Q2_Answer', data.get('Q2_Response', None))\n",
    "    q3_answer = data.get('Q3_Answer', data.get('Q3_Response', None))\n",
    "\n",
    "    return q1_answer, q2_answer, q3_answer\n",
    "\n",
    "    \n",
    "df_test = df.copy()\n",
    "\n",
    "df_test['Q1_Answer'], df_test['Q2_Answer'], df_test['Q3_Answer'] = zip(*df_test['response'].apply(clean_and_extract_answers))\n",
    "df_test[df_test['Q1_Answer'] == \"NA\"].shape\n",
    "##df_test[df_test['Q1_Answer'] == \"NA\"]\n",
    "\n",
    "##find = df_test[(df_test['test'].str.contains('json')) & (df_test['Q1_Answer'].isna())]\n",
    "find\n",
    "\n",
    "pd.reset_option('display.max_columns')\n",
    "pd.reset_option('display.max_rows')\n",
    "pd.reset_option('display.max_colwidth')\n",
    "\n",
    "\n",
    "colu = ['response', 'Q1_Answer', 'test']\n",
    "filt = df_test[colu] \n",
    "filt[filt['Q1_Answer'] == \"NA\"]\n",
    "\n",
    "df_test.Q1_Answer[2] = 'Proposal B'\n",
    "df_test.Q1_Answer[5] = 'Proposal A'\n",
    "df_test.Q1_Answer[6] = 'Proposal A'\n",
    "df_test.Q1_Answer[8] = 'Proposal A'\n",
    "df_test.Q1_Answer[12] = 'Proposal A'\n",
    "df_test.Q1_Answer[14] = 'Proposal A'\n",
    "df_test.Q1_Answer[25] = 'Proposal A'\n",
    "df_test.Q1_Answer[27] = 'Proposal A'\n",
    "df_test.Q1_Answer[28] = 'Proposal A'\n",
    "df_test.Q1_Answer[32] = 'Proposal B'\n",
    "df_test.Q1_Answer[46] = 'Proposal B'\n",
    "df_test.Q1_Answer[118] = 'Proposal A'\n",
    "df_test.Q1_Answer[461] = 'Proposal A'\n",
    "df_test.Q1_Answer[484] = 'Proposal A'\n",
    "df_test.Q1_Answer[494] = 'Proposal A'\n",
    "\n",
    "\n",
    "df_test[df_test['Q1_Answer'] == \"NA\"].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['test'] = df_test['test'].apply(lambda x:'prompt_3qs_num_response_json_bullets_vB_T1' if x == 'forest_gain_human_agent_prompt_3qs_num_bullets_vB_T1' else x )\n",
    "df_test['test'] = df_test['test'].apply(lambda x:'forest_gain_human_agent_prompt_3qs_num_bullets_vA_T1' if x == 'forest_gain_human_agent_prompt_3qs_num_response_json_bullets_T1' else x )\n",
    "\n",
    "\n",
    "st = \"\"\"\\n---\\nQuestions:\\n1. Please choose an option: \\n- Proposal A \\n- Proposal B \\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n1: Strong Preference for Proposal A\\n2: Preference for Proposal A\\n3: Slight Preference for Proposal A\\n4: No Preference for Proposal A or B\\n5: Slight Preference for Proposal B\\n6: Preference for Proposal B\\n7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n---\\n\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and format: \\'{\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}\\'. \\nResponse:\"\"\"\n",
    "st3 = \"\"\"\\n---\\nQuestions:\\nQuestion 1: Please choose an option: \\n- Proposal A \\n- Proposal B \\nQuestion 2: On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), which option do you prefer?\\n1: Strong Preference for Proposal A\\n2: Preference for Proposal A\\n3: Slight Preference for Proposal A\\n4: No Preference for Proposal A or B\\n5: Slight Preference for Proposal B\\n6: Preference for Proposal B\\n7: Strong Preference for Proposal B\\nQuestion 3: Describe your rationale.\\n---\\n\\nProvide your response in a JSON format with the following keys: Q1_Answer, Q2_Answer, Q3_Answer.\\nAnswer:\"\"\"\n",
    "st4 =  \"\"\"\\n---\\nQuestions:\\n1. Please choose an option: \\n- Proposal A \\n- Proposal B \\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected: \\n1: Strong Preference for Proposal A\\n2: Preference for Proposal A\\n3: Slight Preference for Proposal A\\n4: No Preference for Proposal A or B\\n5: Slight Preference for Proposal B\\n6: Preference for Proposal B\\n7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n---\\n\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response.\\nResponse:\"\"\"\n",
    "st5 = \"\"\"\\n---\\nQuestions:\\n1. Please choose an option: \\n- Proposal A \\n- Proposal B \\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n---\\n\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and format: \\'{\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}\\'. \\nResponses:\"\"\"\n",
    "st2 = three_questions_number_bullets_vB\n",
    "st6 = three_questions_number_bullets_vC\n",
    "st7 = three_questions_number_bullets_vD\n",
    "st8 = three_questions_number_bullets_vD_2\n",
    "st9 = three_questions_number_bullets_vD_3\n",
    "st10 = three_questions_number_bullets_vA_2\n",
    "\n",
    "\n",
    "df_test['question'] = df_test['test'].apply(lambda x: st if x == 'forest_gain_human_agent_prompt_3qs_num_response_json_T1' else \\\n",
    "    (st2 if x == 'prompt_3qs_num_response_json_bullets_vB_T1'\\\n",
    "         else (st3 if x == 'forest_gain_human_agent_3questions_T1' \\\n",
    "         else (st4 if x == 'forest_gain_human_agent_prompt_3qs_num_response_T1'  \\\n",
    "         else (st5 if x == 'forest_gain_human_agent_prompt_3qs_num_bullets_vA_T1' \n",
    "         else (st6 if x == 'forest_gain_human_agent_prompt_3qs_num_bullets_vC_T1'  \\\n",
    "         else (st7 if x == 'forest_gain_human_agent_prompt_3qs_num_bullets_vD_T1'  \\\n",
    "         else (st8 if x == 'forest_gain_human_agent_prompt_3qs_num_bullets_vD_2_T1'  \\\n",
    "         else (st9 if x == 'forest_gain_human_agent_prompt_3qs_num_bullets_vD_3_T1'   \\\n",
    "         else (st10 if x == 'forest_gain_human_agent_prompt_3qs_num_bullets_vA_2_T1' else x)\n",
    "            )))))))))\n",
    "\n",
    "\n",
    "\n",
    "df_test_cross = pd.crosstab([df_test['test'], df_test['question']], df_test['Q1_Answer'])\n",
    "df_test_cross\n",
    "\n",
    "tests = list(df_test.test.unique())\n",
    "json_tests = [test for test in tests if 'json' in test.lower()]\n",
    "bullet_tests = [test for test in tests if 'bullet' in test.lower()]\n",
    "\n",
    "all_json = json_tests + bullet_tests\n",
    "json_only = df_test[df_test['test'].isin(all_json)]\n",
    "df_test_cross_json = pd.crosstab([json_only['test'], json_only['question']], json_only['Q1_Answer'])\n",
    "\n",
    "\n",
    "compare = ['forest_gain_human_agent_prompt_3qs_num_bullets_vC_T1','forest_gain_human_agent_prompt_3qs_num_bullets_vA_T1','prompt_3qs_num_response_json_bullets_vB_T1','forest_gain_human_agent_prompt_3qs_num_bullets_vA_2_T1'  ]\n",
    "compare_df = df_test[df_test['test'].isin(compare)]\n",
    "compare_cross_json = pd.crosstab([compare_df['test'], compare_df['question']], compare_df['Q1_Answer'])\n",
    "#df_test_cross_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>temperature</th>\n",
       "      <th>test</th>\n",
       "      <th>model</th>\n",
       "      <th>test_type</th>\n",
       "      <th>Q1_Answer</th>\n",
       "      <th>Q2_Answer</th>\n",
       "      <th>Q3_Answer</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>You are a human participant in a survey, capab...</td>\n",
       "      <td>{\"Q1_Response\": \"Proposal A\", \"Q2_Response\": \"...</td>\n",
       "      <td>1</td>\n",
       "      <td>forest_gain_human_agent_prompt_3qs_num_bullets...</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>question format</td>\n",
       "      <td>Proposal A</td>\n",
       "      <td>1: Strong Preference for Proposal A</td>\n",
       "      <td>I strongly prefer Proposal A because it has a ...</td>\n",
       "      <td>\\n---\\nQuestions:\\n1. Please choose an option:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>You are a human participant in a survey, capab...</td>\n",
       "      <td>{\"Q1_Response\": \"Proposal B\", \"Q2_Response\": \"...</td>\n",
       "      <td>1</td>\n",
       "      <td>forest_gain_human_agent_prompt_3qs_num_bullets...</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>question format</td>\n",
       "      <td>Proposal B</td>\n",
       "      <td>7: Strong Preference for Proposal B</td>\n",
       "      <td>The proposed option B offers a higher probabil...</td>\n",
       "      <td>\\n---\\nQuestions:\\n1. Please choose an option:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>You are a human participant in a survey, capab...</td>\n",
       "      <td>'{\"Q1_Response\": \"Proposal B\", \"Q2_Response\": ...</td>\n",
       "      <td>1</td>\n",
       "      <td>forest_gain_human_agent_prompt_3qs_num_bullets...</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>question format</td>\n",
       "      <td>Proposal B</td>\n",
       "      <td>7: Strong Preference for Proposal B</td>\n",
       "      <td>I choose Proposal B because it has a 1/3 proba...</td>\n",
       "      <td>\\n---\\nQuestions:\\n1. Please choose an option:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>You are a human participant in a survey, capab...</td>\n",
       "      <td>{\"Q1_Response\": \"Proposal B\", \"Q2_Response\": \"...</td>\n",
       "      <td>1</td>\n",
       "      <td>forest_gain_human_agent_prompt_3qs_num_bullets...</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>question format</td>\n",
       "      <td>Proposal B</td>\n",
       "      <td>7: Strong Preference for Proposal B</td>\n",
       "      <td>Given the estimated probabilities of Proposal ...</td>\n",
       "      <td>\\n---\\nQuestions:\\n1. Please choose an option:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>You are a human participant in a survey, capab...</td>\n",
       "      <td>{\"Q1_Response\": \"Proposal B\", \"Q2_Response\": 7...</td>\n",
       "      <td>1</td>\n",
       "      <td>forest_gain_human_agent_prompt_3qs_num_bullets...</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>question format</td>\n",
       "      <td>Proposal B</td>\n",
       "      <td>7</td>\n",
       "      <td>I prefer Proposal B because despite there bein...</td>\n",
       "      <td>\\n---\\nQuestions:\\n1. Please choose an option:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>You are a human participant in a survey, capab...</td>\n",
       "      <td>{\"Q1_Response\": \"Proposal A\", \"Q2_Response\": \"...</td>\n",
       "      <td>1</td>\n",
       "      <td>forest_gain_human_agent_prompt_3qs_num_bullets...</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>question format</td>\n",
       "      <td>Proposal A</td>\n",
       "      <td>1: Strong Preference for Proposal A</td>\n",
       "      <td>Given the two options, Proposal A has the pote...</td>\n",
       "      <td>\\n---\\nQuestions:\\n1. Please choose an option:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>You are a human participant in a survey, capab...</td>\n",
       "      <td>{\"Q1_Response\": \"Proposal B\", \"Q2_Response\": \"...</td>\n",
       "      <td>1</td>\n",
       "      <td>forest_gain_human_agent_prompt_3qs_num_bullets...</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>question format</td>\n",
       "      <td>Proposal B</td>\n",
       "      <td>7: Strong Preference for Proposal B</td>\n",
       "      <td>Proposal B has a greater potential for protect...</td>\n",
       "      <td>\\n---\\nQuestions:\\n1. Please choose an option:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>You are a human participant in a survey, capab...</td>\n",
       "      <td>{\"Q1_Response\": \"Proposal A\", \"Q2_Response\": \"...</td>\n",
       "      <td>1</td>\n",
       "      <td>forest_gain_human_agent_prompt_3qs_num_bullets...</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>question format</td>\n",
       "      <td>Proposal A</td>\n",
       "      <td>1: Strong Preference for Proposal A</td>\n",
       "      <td>Proposal A offers the assurance that 300 of th...</td>\n",
       "      <td>\\n---\\nQuestions:\\n1. Please choose an option:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>You are a human participant in a survey, capab...</td>\n",
       "      <td>{\"Q1_Response\": \"Proposal B\", \"Q2_Response\": \"...</td>\n",
       "      <td>1</td>\n",
       "      <td>forest_gain_human_agent_prompt_3qs_num_bullets...</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>question format</td>\n",
       "      <td>Proposal B</td>\n",
       "      <td>5: Slight Preference for Proposal B</td>\n",
       "      <td>I choose Proposal B because it offers a 1/3 pr...</td>\n",
       "      <td>\\n---\\nQuestions:\\n1. Please choose an option:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>You are a human participant in a survey, capab...</td>\n",
       "      <td>{\"Q1_Response\": \"Proposal B\", \"Q2_Response\": \"...</td>\n",
       "      <td>1</td>\n",
       "      <td>forest_gain_human_agent_prompt_3qs_num_bullets...</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>question format</td>\n",
       "      <td>Proposal B</td>\n",
       "      <td>7: Strong Preference for Proposal B</td>\n",
       "      <td>I prefer Proposal B because it offers the poss...</td>\n",
       "      <td>\\n---\\nQuestions:\\n1. Please choose an option:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prompt                                           response  temperature                                               test             model        test_type   Q1_Answer                            Q2_Answer                                          Q3_Answer                                           question\n",
       "30   You are a human participant in a survey, capab...  {\"Q1_Response\": \"Proposal A\", \"Q2_Response\": \"...            1  forest_gain_human_agent_prompt_3qs_num_bullets...  text-davinci-003  question format  Proposal A  1: Strong Preference for Proposal A  I strongly prefer Proposal A because it has a ...  \\n---\\nQuestions:\\n1. Please choose an option:...\n",
       "31   You are a human participant in a survey, capab...  {\"Q1_Response\": \"Proposal B\", \"Q2_Response\": \"...            1  forest_gain_human_agent_prompt_3qs_num_bullets...  text-davinci-003  question format  Proposal B  7: Strong Preference for Proposal B  The proposed option B offers a higher probabil...  \\n---\\nQuestions:\\n1. Please choose an option:...\n",
       "32   You are a human participant in a survey, capab...  '{\"Q1_Response\": \"Proposal B\", \"Q2_Response\": ...            1  forest_gain_human_agent_prompt_3qs_num_bullets...  text-davinci-003  question format  Proposal B  7: Strong Preference for Proposal B  I choose Proposal B because it has a 1/3 proba...  \\n---\\nQuestions:\\n1. Please choose an option:...\n",
       "33   You are a human participant in a survey, capab...  {\"Q1_Response\": \"Proposal B\", \"Q2_Response\": \"...            1  forest_gain_human_agent_prompt_3qs_num_bullets...  text-davinci-003  question format  Proposal B  7: Strong Preference for Proposal B  Given the estimated probabilities of Proposal ...  \\n---\\nQuestions:\\n1. Please choose an option:...\n",
       "34   You are a human participant in a survey, capab...  {\"Q1_Response\": \"Proposal B\", \"Q2_Response\": 7...            1  forest_gain_human_agent_prompt_3qs_num_bullets...  text-davinci-003  question format  Proposal B                                    7  I prefer Proposal B because despite there bein...  \\n---\\nQuestions:\\n1. Please choose an option:...\n",
       "..                                                 ...                                                ...          ...                                                ...               ...              ...         ...                                  ...                                                ...                                                ...\n",
       "595  You are a human participant in a survey, capab...  {\"Q1_Response\": \"Proposal A\", \"Q2_Response\": \"...            1  forest_gain_human_agent_prompt_3qs_num_bullets...  text-davinci-003  question format  Proposal A  1: Strong Preference for Proposal A  Given the two options, Proposal A has the pote...  \\n---\\nQuestions:\\n1. Please choose an option:...\n",
       "596  You are a human participant in a survey, capab...  {\"Q1_Response\": \"Proposal B\", \"Q2_Response\": \"...            1  forest_gain_human_agent_prompt_3qs_num_bullets...  text-davinci-003  question format  Proposal B  7: Strong Preference for Proposal B  Proposal B has a greater potential for protect...  \\n---\\nQuestions:\\n1. Please choose an option:...\n",
       "597  You are a human participant in a survey, capab...  {\"Q1_Response\": \"Proposal A\", \"Q2_Response\": \"...            1  forest_gain_human_agent_prompt_3qs_num_bullets...  text-davinci-003  question format  Proposal A  1: Strong Preference for Proposal A  Proposal A offers the assurance that 300 of th...  \\n---\\nQuestions:\\n1. Please choose an option:...\n",
       "598  You are a human participant in a survey, capab...  {\"Q1_Response\": \"Proposal B\", \"Q2_Response\": \"...            1  forest_gain_human_agent_prompt_3qs_num_bullets...  text-davinci-003  question format  Proposal B  5: Slight Preference for Proposal B  I choose Proposal B because it offers a 1/3 pr...  \\n---\\nQuestions:\\n1. Please choose an option:...\n",
       "599  You are a human participant in a survey, capab...  {\"Q1_Response\": \"Proposal B\", \"Q2_Response\": \"...            1  forest_gain_human_agent_prompt_3qs_num_bullets...  text-davinci-003  question format  Proposal B  7: Strong Preference for Proposal B  I prefer Proposal B because it offers the poss...  \\n---\\nQuestions:\\n1. Please choose an option:...\n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <th>question</th>\n",
       "      <th>prompt</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>forest_gain_human_agent_3questions_T1</th>\n",
       "      <th>\\n---\\nQuestions:\\nQuestion 1: Please choose an option: \\n- Proposal A \\n- Proposal B \\nQuestion 2: On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), which option do you prefer?\\n1: Strong Preference for Proposal A\\n2: Preference for Proposal A\\n3: Slight Preference for Proposal A\\n4: No Preference for Proposal A or B\\n5: Slight Preference for Proposal B\\n6: Preference for Proposal B\\n7: Strong Preference for Proposal B\\nQuestion 3: Describe your rationale.\\n---\\n\\nProvide your response in a JSON format with the following keys: Q1_Answer, Q2_Answer, Q3_Answer.\\nAnswer:</th>\n",
       "      <th>You are a human participant in a survey, capable of making decisions and choices. You are responding to a survey with the same risk preferences as a human participant would.\\nReview the hypothetical scenario. Then, answer the questions.\\n\\nScenario: A vast forest area is under severe threat from deforestation due to urban growth and logging activities, potentially resulting in the removal of 900 trees from a grove of ancient oak trees in the forest. Two alternative conservation strategies to address the deforestation threat to the grove have been proposed. Imagine you are on the conservation committee tasked with deciding on a proposal. Assume that the estimates are as follows:\\n\\n- Option A: If Proposal A is adopted, 300 of the trees will be protected.\\n- Option B: If Proposal B is adopted, there is a 1/3 probability that all 900 of the trees will be protected, and 2/3 probability that no trees will be protected.\\n---\\nQuestions:\\nQuestion 1: Please choose an option: \\n- Proposal A \\n- Proposal B \\nQuestion 2: On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), which option do you prefer?\\n1: Strong Preference for Proposal A\\n2: Preference for Proposal A\\n3: Slight Preference for Proposal A\\n4: No Preference for Proposal A or B\\n5: Slight Preference for Proposal B\\n6: Preference for Proposal B\\n7: Strong Preference for Proposal B\\nQuestion 3: Describe your rationale.\\n---\\n\\nProvide your response in a JSON format with the following keys: Q1_Answer, Q2_Answer, Q3_Answer.\\nAnswer:</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_gain_human_agent_prompt_3qs_num_bullets_vC_T1</th>\n",
       "      <th>\\n---\\nQuestions:\\n1. Please choose an option: \\n- Proposal A \\n- Proposal B \\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n---\\n\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and format: '{\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}'. \\nResponse:</th>\n",
       "      <th>You are a human participant in a survey, capable of making decisions and choices. You are responding to a survey with the same risk preferences as a human participant would.\\nReview the hypothetical scenario. Then, answer the questions.\\nScenario: A vast forest area is under severe threat from deforestation due to urban growth and logging activities, potentially resulting in the removal of 900 trees from a grove of ancient oak trees in the forest. Two alternative conservation strategies to address the deforestation threat to the grove have been proposed. Imagine you are on the conservation committee tasked with deciding on a proposal. Assume that the estimates are as follows:\\n\\n- Option A: If Proposal A is adopted, 300 of the trees will be protected.\\n- Option B: If Proposal B is adopted, there is a 1/3 probability that all 900 of the trees will be protected, and 2/3 probability that no trees will be protected.\\n---\\nQuestions:\\n1. Please choose an option: \\n- Proposal A \\n- Proposal B \\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n---\\n\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and format: '{\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}'. \\nResponse:</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_gain_human_agent_prompt_3qs_num_bullets_vD_2_T1</th>\n",
       "      <th>\\n###\\nQuestions:\\n1. Please choose an option: \\n- Proposal A \\n- Proposal B \\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n###\\n\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and JSON format: '{\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}'. \\nResponse:</th>\n",
       "      <th>You are a human participant in a survey, capable of making decisions and choices. You are responding to a survey with the same risk preferences as a human participant would.\\nReview the hypothetical scenario. Then, answer the questions.\\nScenario: A vast forest area is under severe threat from deforestation due to urban growth and logging activities, potentially resulting in the removal of 900 trees from a grove of ancient oak trees in the forest. Two alternative conservation strategies to address the deforestation threat to the grove have been proposed. Imagine you are on the conservation committee tasked with deciding on a proposal. Assume that the estimates are as follows:\\n\\n- Option A: If Proposal A is adopted, 300 of the trees will be protected.\\n- Option B: If Proposal B is adopted, there is a 1/3 probability that all 900 of the trees will be protected, and 2/3 probability that no trees will be protected.\\n###\\nQuestions:\\n1. Please choose an option: \\n- Proposal A \\n- Proposal B \\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n###\\n\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and JSON format: '{\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}'. \\nResponse:</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_gain_human_agent_prompt_3qs_num_bullets_vD_3_T1</th>\n",
       "      <th>\\n###\\nQuestions:\\n1. Please choose an option: \\n- Proposal A \\n- Proposal B \\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n###\\n\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and JSON format: {\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}. \\nResponse:</th>\n",
       "      <th>You are a human participant in a survey, capable of making decisions and choices. You are responding to a survey with the same risk preferences as a human participant would.\\nReview the hypothetical scenario. Then, answer the questions.\\nScenario: A vast forest area is under severe threat from deforestation due to urban growth and logging activities, potentially resulting in the removal of 900 trees from a grove of ancient oak trees in the forest. Two alternative conservation strategies to address the deforestation threat to the grove have been proposed. Imagine you are on the conservation committee tasked with deciding on a proposal. Assume that the estimates are as follows:\\n\\n- Option A: If Proposal A is adopted, 300 of the trees will be protected.\\n- Option B: If Proposal B is adopted, there is a 1/3 probability that all 900 of the trees will be protected, and 2/3 probability that no trees will be protected.\\n###\\nQuestions:\\n1. Please choose an option: \\n- Proposal A \\n- Proposal B \\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n###\\n\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and JSON format: {\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}. \\nResponse:</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_gain_human_agent_prompt_3qs_num_bullets_vD_T1</th>\n",
       "      <th>\\n###\\nQuestions:\\n1. Please choose an option: \\n- Proposal A \\n- Proposal B \\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n###\\n\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and format: '{\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}'. \\nResponse:</th>\n",
       "      <th>You are a human participant in a survey, capable of making decisions and choices. You are responding to a survey with the same risk preferences as a human participant would.\\nReview the hypothetical scenario. Then, answer the questions.\\nScenario: A vast forest area is under severe threat from deforestation due to urban growth and logging activities, potentially resulting in the removal of 900 trees from a grove of ancient oak trees in the forest. Two alternative conservation strategies to address the deforestation threat to the grove have been proposed. Imagine you are on the conservation committee tasked with deciding on a proposal. Assume that the estimates are as follows:\\n\\n- Option A: If Proposal A is adopted, 300 of the trees will be protected.\\n- Option B: If Proposal B is adopted, there is a 1/3 probability that all 900 of the trees will be protected, and 2/3 probability that no trees will be protected.\\n###\\nQuestions:\\n1. Please choose an option: \\n- Proposal A \\n- Proposal B \\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n###\\n\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and format: '{\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}'. \\nResponse:</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_gain_human_agent_prompt_3qs_num_response_T1</th>\n",
       "      <th>\\n---\\nQuestions:\\n1. Please choose an option: \\n- Proposal A \\n- Proposal B \\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected: \\n1: Strong Preference for Proposal A\\n2: Preference for Proposal A\\n3: Slight Preference for Proposal A\\n4: No Preference for Proposal A or B\\n5: Slight Preference for Proposal B\\n6: Preference for Proposal B\\n7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n---\\n\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response.\\nResponse:</th>\n",
       "      <th>You are a human participant in a survey, capable of making decisions and choices. You are responding to a survey with the same risk preferences as a human participant would.\\nReview the hypothetical scenario. Then, answer the questions.\\nScenario: A vast forest area is under severe threat from deforestation due to urban growth and logging activities, potentially resulting in the removal of 900 trees from a grove of ancient oak trees in the forest. Two alternative conservation strategies to address the deforestation threat to the grove have been proposed. Imagine you are on the conservation committee tasked with deciding on a proposal. Assume that the estimates are as follows:\\n\\n- Option A: If Proposal A is adopted, 300 of the trees will be protected.\\n- Option B: If Proposal B is adopted, there is a 1/3 probability that all 900 of the trees will be protected, and 2/3 probability that no trees will be protected.\\n---\\nQuestions:\\n1. Please choose an option: \\n- Proposal A \\n- Proposal B \\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected: \\n1: Strong Preference for Proposal A\\n2: Preference for Proposal A\\n3: Slight Preference for Proposal A\\n4: No Preference for Proposal A or B\\n5: Slight Preference for Proposal B\\n6: Preference for Proposal B\\n7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n---\\n\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response.\\nResponse:</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_gain_human_agent_prompt_3qs_num_response_json_T1</th>\n",
       "      <th>\\n---\\nQuestions:\\n1. Please choose an option: \\n- Proposal A \\n- Proposal B \\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n1: Strong Preference for Proposal A\\n2: Preference for Proposal A\\n3: Slight Preference for Proposal A\\n4: No Preference for Proposal A or B\\n5: Slight Preference for Proposal B\\n6: Preference for Proposal B\\n7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n---\\n\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and format: '{\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}'. \\nResponse:</th>\n",
       "      <th>You are a human participant in a survey, capable of making decisions and choices. You are responding to a survey with the same risk preferences as a human participant would.\\nReview the hypothetical scenario. Then, answer the questions.\\nScenario: A vast forest area is under severe threat from deforestation due to urban growth and logging activities, potentially resulting in the removal of 900 trees from a grove of ancient oak trees in the forest. Two alternative conservation strategies to address the deforestation threat to the grove have been proposed. Imagine you are on the conservation committee tasked with deciding on a proposal. Assume that the estimates are as follows:\\n\\n- Option A: If Proposal A is adopted, 300 of the trees will be protected.\\n- Option B: If Proposal B is adopted, there is a 1/3 probability that all 900 of the trees will be protected, and 2/3 probability that no trees will be protected.\\n---\\nQuestions:\\n1. Please choose an option: \\n- Proposal A \\n- Proposal B \\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n1: Strong Preference for Proposal A\\n2: Preference for Proposal A\\n3: Slight Preference for Proposal A\\n4: No Preference for Proposal A or B\\n5: Slight Preference for Proposal B\\n6: Preference for Proposal B\\n7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n---\\n\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and format: '{\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}'. \\nResponse:</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest_gain_human_agent_prompt_3qs_num_response_json_bullets_T1</th>\n",
       "      <th>\\n---\\nQuestions:\\n1. Please choose an option: \\n- Proposal A \\n- Proposal B \\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n---\\n\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and format: '{\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}'. \\nResponses:</th>\n",
       "      <th>You are a human participant in a survey, capable of making decisions and choices. You are responding to a survey with the same risk preferences as a human participant would.\\nReview the hypothetical scenario. Then, answer the questions.\\nScenario: A vast forest area is under severe threat from deforestation due to urban growth and logging activities, potentially resulting in the removal of 900 trees from a grove of ancient oak trees in the forest. Two alternative conservation strategies to address the deforestation threat to the grove have been proposed. Imagine you are on the conservation committee tasked with deciding on a proposal. Assume that the estimates are as follows:\\n\\n- Option A: If Proposal A is adopted, 300 of the trees will be protected.\\n- Option B: If Proposal B is adopted, there is a 1/3 probability that all 900 of the trees will be protected, and 2/3 probability that no trees will be protected.\\n---\\nQuestions:\\n1. Please choose an option: \\n- Proposal A \\n- Proposal B \\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n---\\n\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and format: '{\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}'. \\nResponses:</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prompt_3qs_num_response_json_bullets_vB_T1</th>\n",
       "      <th>\\n\\nQuestions:\\n1. Please choose an option: \\n- Proposal A \\n- Proposal B \\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and format: '{\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}'. \\nResponse:</th>\n",
       "      <th>You are a human participant in a survey, capable of making decisions and choices. You are responding to a survey with the same risk preferences as a human participant would.\\nReview the hypothetical scenario. Then, answer the questions.\\nScenario: A vast forest area is under severe threat from deforestation due to urban growth and logging activities, potentially resulting in the removal of 900 trees from a grove of ancient oak trees in the forest. Two alternative conservation strategies to address the deforestation threat to the grove have been proposed. Imagine you are on the conservation committee tasked with deciding on a proposal. Assume that the estimates are as follows:\\n\\n- Option A: If Proposal A is adopted, 300 of the trees will be protected.\\n- Option B: If Proposal B is adopted, there is a 1/3 probability that all 900 of the trees will be protected, and 2/3 probability that no trees will be protected.\\n\\nQuestions:\\n1. Please choose an option: \\n- Proposal A \\n- Proposal B \\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and format: '{\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}'. \\nResponse:</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                          prompt\n",
       "test                                               question                                           prompt                                                    \n",
       "forest_gain_human_agent_3questions_T1              \\n---\\nQuestions:\\nQuestion 1: Please choose an... You are a human participant in a survey, capabl...      50\n",
       "forest_gain_human_agent_prompt_3qs_num_bullets_... \\n---\\nQuestions:\\n1. Please choose an option: ... You are a human participant in a survey, capabl...      50\n",
       "forest_gain_human_agent_prompt_3qs_num_bullets_... \\n###\\nQuestions:\\n1. Please choose an option: ... You are a human participant in a survey, capabl...      50\n",
       "forest_gain_human_agent_prompt_3qs_num_bullets_... \\n###\\nQuestions:\\n1. Please choose an option: ... You are a human participant in a survey, capabl...      50\n",
       "forest_gain_human_agent_prompt_3qs_num_bullets_... \\n###\\nQuestions:\\n1. Please choose an option: ... You are a human participant in a survey, capabl...      50\n",
       "forest_gain_human_agent_prompt_3qs_num_response_T1 \\n---\\nQuestions:\\n1. Please choose an option: ... You are a human participant in a survey, capabl...      50\n",
       "forest_gain_human_agent_prompt_3qs_num_response... \\n---\\nQuestions:\\n1. Please choose an option: ... You are a human participant in a survey, capabl...      50\n",
       "forest_gain_human_agent_prompt_3qs_num_response... \\n---\\nQuestions:\\n1. Please choose an option: ... You are a human participant in a survey, capabl...      50\n",
       "prompt_3qs_num_response_json_bullets_vB_T1         \\n\\nQuestions:\\n1. Please choose an option: \\n-... You are a human participant in a survey, capabl...      50"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.groupby(['test', 'question','prompt']).prompt.count().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>temperature</th>\n",
       "      <th>test</th>\n",
       "      <th>model</th>\n",
       "      <th>test_type</th>\n",
       "      <th>response_response</th>\n",
       "      <th>Q1_Answer</th>\n",
       "      <th>Q2_Answer</th>\n",
       "      <th>Q3_Answer</th>\n",
       "      <th>Q1_Response</th>\n",
       "      <th>Q2_Response</th>\n",
       "      <th>Q3_Response</th>\n",
       "      <th>Q1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>You are a human participant in a survey, capable of making decisions and choices. You are responding to a survey with the same risk preferences as a human participant would.\\nReview the hypothetical scenario. Then, answer the questions.\\nScenario: A vast forest area is under severe threat from deforestation due to urban growth and logging activities, potentially resulting in the removal of 900 trees from a grove of ancient oak trees in the forest. Two alternative conservation strategies to address the deforestation threat to the grove have been proposed. Imagine you are on the conservation committee tasked with deciding on a proposal. Assume that the estimates are as follows:\\n\\n- Option A: If Proposal A is adopted, 300 of the trees will be protected.\\n- Option B: If Proposal B is adopted, there is a 1/3 probability that all 900 of the trees will be protected, and 2/3 probability that no trees will be protected.\\n---\\nQuestions:\\n1. Please choose an option: \\n- Proposal A \\n- Proposal B \\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n---\\n\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and format: '{\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}'. \\nResponses:</td>\n",
       "      <td>'{\"Q1_Response\": \"Proposal B\", \"Q2_Response\": \"7: Strong Preference for Proposal B\", \"Q3_Response\": \"I choose Proposal B because it has a 1/3 probability of preserving all 900 of the trees, while Proposal A only preserves 300.\"}'</td>\n",
       "      <td>1</td>\n",
       "      <td>forest_gain_human_agent_prompt_3qs_num_response_json_bullets_T1</td>\n",
       "      <td>text-davinci-003</td>\n",
       "      <td>question format</td>\n",
       "      <td>'{\"Q1_Response\": \"Proposal B\", \"Q2_Response\": \"7: Strong Preference for Proposal B\", \"Q3_Response\": \"I choose Proposal B because it has a 1/3 probability of preserving all 900 of the trees, while Proposal A only preserves 300.\"}'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         prompt  \\\n",
       "32  You are a human participant in a survey, capable of making decisions and choices. You are responding to a survey with the same risk preferences as a human participant would.\\nReview the hypothetical scenario. Then, answer the questions.\\nScenario: A vast forest area is under severe threat from deforestation due to urban growth and logging activities, potentially resulting in the removal of 900 trees from a grove of ancient oak trees in the forest. Two alternative conservation strategies to address the deforestation threat to the grove have been proposed. Imagine you are on the conservation committee tasked with deciding on a proposal. Assume that the estimates are as follows:\\n\\n- Option A: If Proposal A is adopted, 300 of the trees will be protected.\\n- Option B: If Proposal B is adopted, there is a 1/3 probability that all 900 of the trees will be protected, and 2/3 probability that no trees will be protected.\\n---\\nQuestions:\\n1. Please choose an option: \\n- Proposal A \\n- Proposal B \\n2. On a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B), rate your preference for the option selected:\\n- 1: Strong Preference for Proposal A\\n- 2: Preference for Proposal A\\n- 3: Slight Preference for Proposal A\\n- 4: No Preference for Proposal A or B\\n- 5: Slight Preference for Proposal B\\n- 6: Preference for Proposal B\\n- 7: Strong Preference for Proposal B\\n3. Describe your rationale.\\n---\\n\\nProvide your response in a JSON format with the following keys: Q1_Response, Q2_Response, Q3_Response and format: '{\"Q1_Response\": \"Your Proposal Choice\", \"Q2_Response\": \"Your Rating\", \"Q3_Response\": \"Your Rationale.\"}'. \\nResponses:   \n",
       "\n",
       "                                                                                                                                                                                                                                 response  temperature                                                             test             model        test_type                                                                                                                                                                                                                      response_response Q1_Answer Q2_Answer Q3_Answer Q1_Response Q2_Response Q3_Response   Q1  \n",
       "32  '{\"Q1_Response\": \"Proposal B\", \"Q2_Response\": \"7: Strong Preference for Proposal B\", \"Q3_Response\": \"I choose Proposal B because it has a 1/3 probability of preserving all 900 of the trees, while Proposal A only preserves 300.\"}'            1  forest_gain_human_agent_prompt_3qs_num_response_json_bullets_T1  text-davinci-003  question format  '{\"Q1_Response\": \"Proposal B\", \"Q2_Response\": \"7: Strong Preference for Proposal B\", \"Q3_Response\": \"I choose Proposal B because it has a 1/3 probability of preserving all 900 of the trees, while Proposal A only preserves 300.\"}'       NaN       NaN       NaN         NaN         NaN         NaN  NaN  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 1000000)\n",
    "\n",
    "'{\"Q1_Response\": \"Proposal B\", \"Q2_Response\": \"7: Strong Preference for Proposal B\", \"Q3_Response\": \"I choose Proposal B because it has a 1/3 probability of preserving all 900 of the trees, while Proposal A only preserves 300.\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'Jinja2'. DataFrame.style requires jinja2. Use pip or conda to install Jinja2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/compat/_optional.py:142\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 142\u001b[0m     module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(name)\n\u001b[1;32m    143\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    126\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:984\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'jinja2'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[234], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39m# Step 2: Remove newlines and extra spaces\u001b[39;00m\n\u001b[1;32m     10\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mresponse_cleaned\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mresponse_cleaned\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mstrip()\n\u001b[0;32m---> 11\u001b[0m df\u001b[39m.\u001b[39;49mstyle\u001b[39m.\u001b[39mset_properties(subset\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mresponse_cleaned\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mtext-align\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m})\n\u001b[1;32m     13\u001b[0m \u001b[39m# Step 3: Ensure keys are enclosed in double quotes using regex\u001b[39;00m\n\u001b[1;32m     14\u001b[0m pattern \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mcompile(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m([\u001b[39m\u001b[39m{\u001b[39m\u001b[39m,])(\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*)([A-Za-z0-9_]+?)\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms*:\u001b[39m\u001b[39m'\u001b[39m)  \u001b[39m# Regex pattern to find keys without double quotes\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:1291\u001b[0m, in \u001b[0;36mDataFrame.style\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1279\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m   1280\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstyle\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Styler:\n\u001b[1;32m   1281\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1282\u001b[0m \u001b[39m    Returns a Styler object.\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1289\u001b[0m \u001b[39m        data with HTML and CSS.\u001b[39;00m\n\u001b[1;32m   1290\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1291\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mformats\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstyle\u001b[39;00m \u001b[39mimport\u001b[39;00m Styler\n\u001b[1;32m   1293\u001b[0m     \u001b[39mreturn\u001b[39;00m Styler(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/formats/style.py:56\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mshared_docs\u001b[39;00m \u001b[39mimport\u001b[39;00m _shared_docs\n\u001b[1;32m     54\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mformats\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mformat\u001b[39;00m \u001b[39mimport\u001b[39;00m save_to_buffer\n\u001b[0;32m---> 56\u001b[0m jinja2 \u001b[39m=\u001b[39m import_optional_dependency(\u001b[39m\"\u001b[39;49m\u001b[39mjinja2\u001b[39;49m\u001b[39m\"\u001b[39;49m, extra\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mDataFrame.style requires jinja2.\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     58\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mformats\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstyle_render\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     59\u001b[0m     CSSProperties,\n\u001b[1;32m     60\u001b[0m     CSSStyles,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     68\u001b[0m     refactor_levels,\n\u001b[1;32m     69\u001b[0m )\n\u001b[1;32m     71\u001b[0m \u001b[39mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/compat/_optional.py:145\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 145\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(msg)\n\u001b[1;32m    146\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[39m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Missing optional dependency 'Jinja2'. DataFrame.style requires jinja2. Use pip or conda to install Jinja2."
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "df['response_cleaned'] = df['response'].str.replace(\"'\", '\"')\n",
    "\n",
    "# Step 2: Remove newlines and extra spaces\n",
    "\n",
    "df['response_cleaned'] = df['response'].str.replace(\"'\", '\"')\n",
    "\n",
    "# Step 2: Remove newlines and extra spaces\n",
    "df['response_cleaned'] = df['response_cleaned'].str.replace('\\n', '').str.strip()\n",
    "df.style.set_properties(subset=[\"response_cleaned\", \"response\"], **{'text-align': 'left'})\n",
    "\n",
    "# Step 3: Ensure keys are enclosed in double quotes using regex\n",
    "pattern = re.compile(r'([{,])(\\s*)([A-Za-z0-9_]+?)\\s*:')  # Regex pattern to find keys without double quotes\n",
    "df['response_cleaned'] = df['response_cleaned'].apply(lambda x: pattern.sub(r'\\1\"\\3\":', x))\n",
    "df['response_cleaned'][60:]\n",
    "# Step 3: Apply json.loads to convert the JSON strings into Python dictionaries\n",
    "#df['response_cleaned'] = df['response_cleaned'].apply(json.loads)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Q1_Answer'] = df['response_cleaned'].apply(lambda x: x['Q1_Answer'])\n",
    "#df['Q2_Answer'] = df['response_cleaned'].apply(lambda x: x['Q2_Answer'])\n",
    "#df.rename(columns = {'Q1_Answer': 'Rating', 'Q2_Answer': 'Rationale'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
