library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(car)
library(apaTables)
library(huxtable)
library(jtools)
library(broom)
library(stargazer)
library(writexl)
library(gtsummary)
library(MASS)
library(lme4)
library(logistf)

# ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ----
############################ Experiment 1 ############################
# ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ----

## Load in Data
data_path <- "/Users/annaking/Documents/Github/riskychoiceframing_AI/Experiment 1/analysis/main_analysis_forR.csv"
main_analysis <- read_csv(data_path)
table(main_analysis$ethnicity_grouped )

#Set reference groups for cat variables 
main_analysis$ethnicity_grouped <- factor(main_analysis$ethnicity_grouped, levels = c("White or Caucasian", "Asian", "Black/African/Caribbean", "Not Provided/Other"))
main_analysis$education <- factor(main_analysis$education, levels = c("Bachelor's degree", "Associates or technical degree", "Graduate or professional degree (MA, MS, MBA, PHd, JD, MD, etc.)", "Completed high school / secondary school"))
main_analysis$scenario_clean <- factor(main_analysis$scenario_clean, levels = c("forest", "animals", "humans"))
main_analysis$continent_grouped <- factor(main_analysis$continent_grouped, levels = c("North America", "Europe", "Other / Not Provided", "Asia"))
main_analysis$age_grouped <- factor(main_analysis$age_grouped, levels = c("25 - 34 years old", "18 - 24 years old",  "35+"))
main_analysis$reversed_rating_num = factor(main_analysis$reversed_rating_num, levels = c(1,2,3,4,5,6,7))

##Create subset dataframes for regression robustness checks 
#where rationale is provided
rationale_incl = subset(main_analysis, !is.na(rationale))

#gain & loss conditions -- rationale incl
gain_condition_rationale = subset(rationale_incl,frame == 'gain')
loss_condition_rationale  = subset(rationale_incl,frame == 'loss')

#where ADP not indicated as familiar
noADP  = subset(main_analysis,ADP_familiar != "Yes")
rationale_incl_noADP = subset(rationale_incl,ADP_familiar != "Yes")


############## H1: Logistic regression ##############
#Basic 
logit_basic_v1 <- glm(option_selected_A ~ frame_gain, data = main_analysis, family = binomial())
#Scenario 
logit_scn <- glm(option_selected_A ~ frame_gain + scenario_clean, data = main_analysis, family = binomial())
#Dem Basic
logit_dembasic <- glm(option_selected_A ~ frame_gain + scenario_clean + age_grouped + ethnicity_grouped + education + gender_grouped, data = main_analysis, family = binomial())
#All Controls  
logit_cont <- glm(option_selected_A ~ frame_gain + scenario_clean + age_grouped + ethnicity_grouped + education + gender_grouped +  continent_grouped + ADP_familiar + student, data = main_analysis, family = binomial())

#table
stargazer(logit_basic_v1, logit_scn, logit_dembasic,logit_cont, 
type = "text", 
dep.var.labels=c("Option Selected (A)"),
covariate.labels=c("Frame (Gain)", "Scenario (Human)", "Scenario (Animal)", "Age (25 - 34)", "Age (35+)", "Ethnicity (Asian)", "Ethnicity (Black/African/Caribbean)", 
"Ethnicity (Not Provided/Other)", "Education (Associates or technical degree)", "Education (Graduate or professional degree)", "Education (Completed high school / secondary school)", "Gender (Male)", "Gender (Other / Prefer not to say)", "Continent (Europe)", "Continent (Other / Not Provided)", "Continent (Asia)", "ADP Familiar (Yes)", "Student (Yes)", "Constant"),
out="H1.1_results_table.html")
#OR table 
stargazer(logit_basic_v1, logit_scn, logit_dembasic,logit_cont, 
          apply.coef = exp,
          apply.se   = exp,
          type = 'text'
          ,covariate.labels=c("Frame (Gain)", "Scenario (Animal)", "Scenario (Human)", "Age (18 - 24)", "Age (35+)","Ethnicity (Asian)", "Ethnicity (Black/African/Caribbean)", "Ethnicity (Not Provided/Other)", "Education (Associates or technical degree)", "Education (Graduate or professional degree)", "Education (Completed high school / secondary school)", "Gender (Male)", "Gender (Other / Prefer not to say)", "Constant")
          ,out="H.1_results_table_or.html")


#########  ADP Versions ##########
###Robustness Check (ADP Version)
#Control for ADP 
logit_ADPNo_con =  glm(option_selected_A ~ frame_gain + scenario_clean + ADP_No, data = main_analysis, family = binomial())
summary(logit_ADPNo_con)
#Control for ADP ; Rationle = Yes
logit_ADPNo_rationale_incl_con = glm(option_selected_A ~ frame_gain + scenario_clean + ADP_No, data = rationale_incl,family = binomial())
##ADP Familiar excluded
logit_noADP = glm(option_selected_A ~ frame_gain + scenario_clean, data = noADP , family = binomial())
##Rationle = Yes with ADP Familiar excluded
logit_noADP2 = glm(option_selected_A ~ frame_gain + scenario_clean, data = rationale_incl_noADP,family = binomial())

#table
stargazer(logit_ADPNo_con,logit_reg_noADP, logit_ADPNo_rationale_incl_con, 
type = "text", 
dep.var.labels=c("Option Selected (A)"), 
covariate.labels=c("Frame (Gain)", "Scenario (Animal)", "Scenario (Human)", "ADP Familiar (Yes)", "Constant"),
out="ADP_results_table.html")
#table2
stargazer(logit_noADP2,
type = "text",
dep.var.labels=c("Option Selected (A)"),
covariate.labels=c("Frame (Gain)", "Scenario (Animal)", "Scenario (Human)", "Constant"),
out="ADP_results_table2.html")

#table OR
stargazer(logit_ADPNo_con,logit_reg_noADP, logit_ADPNo_rationale_incl_con,
          apply.coef = exp,
          apply.se   = exp,
          type = 'text'
          ,out="H.ADP_results_table_or.html")
#table2 OR
stargazer(logit_noADP2,
          apply.coef = exp,
          apply.se   = exp,
          type = 'text'
          ,out="H.ADP_results_table_or2.html")

table(rationale_incl$ethnicity_grouped)


###Robustness Check (Rationale)
logit_basic_rationale =glm(option_selected_A ~ frame_gain,data = rationale_incl,family = binomial())
#Scenario
logit_scn_rationale =glm(option_selected_A ~ frame_gain + scenario_clean,data = rationale_incl,family = binomial())
summary(logit_scn_rationale)
logit_dem_rationale =glm(option_selected_A ~ frame_gain + scenario_clean + age_grouped + ethnicity_grouped + education + gender_grouped,data = rationale_incl,family = binomial())
#All Controls  
logit_con_rationale =glm(option_selected_A ~ frame_gain + scenario_clean + age_grouped + ethnicity_grouped + education + gender_grouped +  continent_grouped + ADP_familiar + student,data = rationale_incl,family = binomial())
#table 1
stargazer(logit_basic_rationale,logit_scn_rationale, logit_dem_rationale,
type = 'text',
dep.var.labels=c("Option Selected (A)"),
covariate.labels=c("Frame (Gain)", "Scenario (Animal)", "Scenario (Human)", "Age (18 - 24)", "Age (35+)","Ethnicity (Asian)", "Ethnicity (Black/African/Caribbean)", "Ethnicity (Not Provided/Other)", "Education (Associates or technical degree)", "Education (Graduate or professional degree)", "Education (Completed high school / secondary school)", "Gender (Male)", "Gender (Other / Prefer not to say)", "Constant")
,out="logit_rationle.html")
#table 2
stargazer(logit_con_rationale,
type = 'text',
dep.var.labels=c("Rating Scale^"),
covariate.labels=c("Frame (Gain)", "Scenario (Animal)", "Scenario (Human)", "Age (18 - 24)", "Age (35+)","Ethnicity (Asian)", "Ethnicity (Black/African/Caribbean)", "Ethnicity (Not Provided/Other)", "Education (Associates or technical degree)", "Education (Graduate or professional degree)", "Education (Completed high school / secondary school)", "Gender (Male)", "Gender (Other / Prefer not to say)", "Continent (Europe)", "Continent (Other / Not Provided)", "Continent (Asia)", "ADP Familiar (Yes)", "Student (Yes)", "Constant")
,out="logit_rationle2.html")
#OR table 1
stargazer(logit_basic_rationale, logit_scn_rationale,logit_dem_rationale,
          apply.coef = exp,
          apply.se   = exp,
          type = 'text'
          ,covariate.labels=c("Frame (Gain)", "Scenario (Animal)", "Scenario (Human)", "Age (18 - 24)", "Age (35+)","Ethnicity (Asian)", "Ethnicity (Black/African/Caribbean)", "Ethnicity (Not Provided/Other)", "Education (Associates or technical degree)", "Education (Graduate or professional degree)", "Education (Completed high school / secondary school)", "Gender (Male)", "Gender (Other / Prefer not to say)", "Constant")
          ,out="logit_rationle_or.html")
#OR table 2
stargazer(logit_con_rationale,
          apply.coef = exp,
          apply.se   = exp,
          type = 'text'
          ,covariate.labels=c("Frame (Gain)", "Scenario (Animal)", "Scenario (Human)", "Age (18 - 24)", "Age (35+)","Ethnicity (Asian)", "Ethnicity (Black/African/Caribbean)", "Ethnicity (Not Provided/Other)", "Education (Associates or technical degree)", "Education (Graduate or professional degree)", "Education (Completed high school / secondary school)", "Gender (Male)", "Gender (Other / Prefer not to say)", "Continent (Europe)", "Continent (Other / Not Provided)", "Continent (Asia)", "ADP Familiar (Yes)", "Student (Yes)", "Constant")
          ,out="logit_rationle_or2.html")


############## H2: Ordinal regression ##############

#Basic
ordinal_basic =clm(reversed_rating_num ~ frame_gain,data = main_analysis)
summary(ordinal_basic)
#Scenario
ordinal_scn =clm(reversed_rating_num ~ frame_gain + scenario_clean,data = main_analysis)
summary(ordinal_scn)
#Demographics
ordinal_dem =clm(reversed_rating_num ~ frame_gain + scenario_clean + age_grouped + ethnicity_grouped + education + gender_grouped,data = main_analysis)
summary(ordinal_dem)
#All Controls  
ordinal_conall =c lm(reversed_rating_num ~ frame_gain + scenario_clean + age_grouped + ethnicity_grouped + education + gender_grouped +  continent_grouped + ADP_familiar + student,data = main_analysis)
summary(ordinal_conall)

library(sjPlot)
tab_model(ordinal_conall)


#table 1
stargazer(ordinal_basic,ordinal_scn, ordinal_dem,ordinal_conall,
type = 'text',
dep.var.labels=c("Rating Scale^"),
covariate.labels=c("Frame (Gain)", "Scenario (Animal)", "Scenario (Human)", "Age (18 - 24)", "Age (35+)","Ethnicity (Asian)", "Ethnicity (Black/African/Caribbean)", "Ethnicity (Not Provided/Other)", "Education (Associates or technical degree)", "Education (Graduate or professional degree)", "Education (Completed high school / secondary school)", "Gender (Male)", "Gender (Other / Prefer not to say)", "Continent (Europe)", "Continent (Other / Not Provided)", "Continent (Asia)", "ADP Familiar (Yes)", "Student (Yes)", "Constant"),
out="ordinal_results.html")
#OR table 1
stargazer(ordinal_basic,ordinal_scn, ordinal_dem,
          apply.coef = exp,
          apply.se   = exp,
          type = 'text',
          covariate.labels=c("Frame (Gain)", "Scenario (Animal)", "Scenario (Human)", "Age (18 - 24)", "Age (35+)","Ethnicity (Asian)", "Ethnicity (Black/African/Caribbean)", "Ethnicity (Not Provided/Other)", "Education (Associates or technical degree)", "Education (Graduate or professional degree)", "Education (Completed high school / secondary school)", "Gender (Male)", "Gender (Other / Prefer not to say)"),
          out="ordinal_results_or.html")
#OR table 2
stargazer(ordinal_conall,
          apply.coef = exp,
          apply.se   = exp,
          type = 'text',
          covariate.labels=c("Frame (Gain)", "Scenario (Animal)", "Scenario (Human)", "Age (18 - 24)", "Age (35+)","Ethnicity (Asian)", "Ethnicity (Black/African/Caribbean)", "Ethnicity (Not Provided/Other)", "Education (Associates or technical degree)", "Education (Graduate or professional degree)", "Education (Completed high school / secondary school)", "Gender (Male)", "Gender (Other / Prefer not to say)", "Continent (Europe)", "Continent (Other / Not Provided)", "Continent (Asia)", "ADP Familiar (Yes)", "Student (Yes)"),
          out="ordinal_results_or2.html")

## Robustness Check (rationale)
#Scenario
rationale_incl_scn = clm(reversed_rating_num ~ frame_gain + scenario_clean, data = rationale_incl)
#Demographics
rationale_incl_dem = clm(reversed_rating_num ~ frame_gain + scenario_clean + age_grouped + ethnicity_grouped + education + gender_grouped, data = rationale_incl)
#All Controls  
rationale_incl_dem_conall =c lm(reversed_rating_num ~ frame_gain + scenario_clean + age_grouped + ethnicity_grouped + education + gender_grouped +  continent_grouped + ADP_familiar + student,data = rationale_incl)

#table
stargazer(rationale_incl_scn,rationale_incl_dem, rationale_incl_dem_conall, 
type = 'text',
dep.var.labels=c("Rating Scale^"),
covariate.labels=c("Frame (Gain)", "Scenario (Animal)", "Scenario (Human)", "Age (18 - 24)", "Age (35+)","Ethnicity (Asian)" "Ethnicity (Black/African/Caribbean)", "Ethnicity (Not Provided/Other)", "Education (Associates or technical degree)", "Education (Graduate or professional degree)", "Education (Completed high school / secondary school)", "Gender (Male)", "Gender (Other / Prefer not to say)", "Continent (Europe)", "Continent (Other / Not Provided)", "Continent (Asia)", "ADP Familiar (Yes)", "Student (Yes)", "Constant"),
out="ordinal_rationle.html")

#OR table
stargazer(rationale_incl_scn,rationale_incl_dem, rationale_incl_dem_conall, 
          apply.coef = exp,
          apply.se   = exp,
          type = 'text',
          covariate.labels=c("Frame (Gain)", "Scenario (Animal)", "Scenario (Human)", "Age (18 - 24)", "Age (35+)","Ethnicity (Asian)", "Ethnicity (Black/African/Caribbean)", "Ethnicity (Not Provided/Other)", "Education (Associates or technical degree)", "Education (Graduate or professional degree)", "Education (Completed high school / secondary school)", "Gender (Male)", "Gender (Other / Prefer not to say)"),
          out="ordinal_rationle_or.html")



# ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ----
#################################################### Experiment 2 ############################################
# ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ----
df_gpt3 <- "/Users/annaking/Documents/Github/riskychoiceframing_AI/Experiment 1/analysis/df_gpt3_t7.csv"
gpt3 <- read_csv(df_gpt3)


##Set Reference Groups for Scearnio & clean variables
gpt3$scenario <- factor(gpt3$scenario, levels = c("forest", "human", "animal"))
gpt3$sys_role <- factor(gpt3$sys_role, levels = c("neutral_system", "human"))
gpt3$instructions <- factor(gpt3$instructions, levels = c("simple", "task_order", "chain"))
gpt3$reversed_rating_num = factor(gpt3$reversed_rating_num, levels = c(1,2,3,4,5,6,7))


df_hum = subset(gpt3, scenario == "human") ## simple 
df_an = subset(gpt3, scenario == "animal") ## simple 
df_for = subset(gpt3, scenario == "forest") ## simple 


###Sep data frames by Combo 
df_combo1A = subset(gpt3, test == "['combo 1A', 'system_message_baseline1', 'user_message_baseline1', 'system role']") ## simple 
df_combo2 = subset(gpt3, test == "['combo 2', 'system_message_hum', 'user_message_baseline1', 'human']") ## simple 
df_combo3 = subset(gpt3, test == "['combo 3', 'system_message_risk', 'user_message_baseline1', 'risk system']") ## simple 
df_combo3B = subset(gpt3, test == "['combo 3B', 'system_message_risk', 'user_message_risk', 'hum + risk + risk']") ## simple 
df_combo5 = subset(gpt3, test == "['combo 5', 'system_message_hum_json', 'user_message_taskord', 'hum + task order']") ## task ord 
df_combo5B = subset(gpt3, test == "['combo 5B', 'system_message_risk_json', 'user_message_taskord', 'risk + task order']") ## task ord 

####### Statistical Tests

####Contigency Table Choice & Frame 
contingency_table <- table(gpt3$option_selected, gpt3$frame)
chi_test_result <- chisq.test(contingency_table)
print(chi_test_result)
    #X-squared = 163.62, df = 1, p-value < 2.2e-16 --> reject null 

####Contigency Table Choice & Test 
contingency_table <- table(gpt3$option_selected, gpt3$test)
chi_test_result <- chisq.test(contingency_table)
print(chi_test_result)
    ##X-squared = 2.7361, df = 1, p-value = 0.0981 --> fail to reject the null hypothesis

table(gpt3$test)

######################## H2.1 Risky Choice Framing Effect ######################## 
##frame_gain A: gain = 1, loss = 0
##option_selected_A: A (certain B (loss) =0 

#Basic Model
logit_ai_basic <- glm(option_selected_A ~ frame_gain , data = gpt3, family = "binomial")
summary(logit_ai_basic) 
#With scenario 
logit_ai_scn <- glm(option_selected_A ~ frame_gain + scenario, data = gpt3, family = "binomial")
summary(logit_ai_scn) 
#with all prompt / model variables 
logit_ai_conall <- glm(option_selected_A ~ frame_gain + scenario  + risk + instructions + sys_role, data = gpt3, family = "binomial")
summary(logit_ai_conall) 
##(ROBUSTNESS CHECK) with all prompt / model variables +  random effects 
logit_ai_conall_re <- lmer(option_selected_A ~ frame_gain + (1|test)  + scenario  + risk + instructions + sys_role, data = gpt3)
summary(logit_ai_conall_re)

###Table regression(logit_ai_conall,logit_ai_scn ) ##, exponentiate = TRUE)
stargazer(logit_ai_basic, logit_ai_scn, logit_ai_conall,
        type = "text",
        out="results_table.html",
        covariate.labels=c("Frame (Gain)", "Scenario (Human)", "Scenario (Animal)", "Risk (Risk)", "Risk (Risk Human Risk)", "Instructions (Task Order)", "Sys Role (Human)"))


######################## H2.2 Influence of AI prompt on framing effect ########################
  # - Investigate the interaction between the type of AI prompt and frame (gain/loss) in influencing the AI's choices.
  # - Include an interaction term between AI prompt and frame in a logistic regression with Option_selected as the dependent variable.

#risk + scenario
logit_ai_risk <- glm(option_selected_A ~ frame_gain * risk + scenario , data = gpt3, family = "binomial")
summary(logit_ai_risk)       

#system + scenario 
logit_ai_system <- glm(option_selected_A ~ frame_gain * sys_role + scenario , data = gpt3, family = "binomial")
summary(logit_ai_system)

#Instructions + scenario 
logit_ai_ins <- glm(option_selected_A ~ frame_gain * instructions + scenario , data = gpt3, family = "binomial")
summary(logit_ai_ins)
#All 
logit_ai_all <- glm(option_selected_A ~ frame_gain * risk + frame_gain * instructions + frame_gain * sys_role + scenario , data = gpt3, family = "binomial")
summary(logit_ai_all)


##Looking at Each Scenario 
logit_human <- glm(option_selected_A ~ frame_gain   , data = df_hum, family = "binomial")
summary(logit_human)
logit_for <- glm(option_selected_A ~ frame_gain   , data = df_for, family = "binomial")
summary(logit_for)
logit_an <- glm(option_selected_A ~ frame_gain   , data = df_an, family = "binomial")
summary(logit_an)
stargazer(logit_human, logit_for, logit_an, type = "text", out="H2.2_results_table.html")


##Looking at Each Scenario 
logit_human <- glm(option_selected_A ~ frame_gain * test   , data = df_hum, family = "binomial")
summary(logit_human)
logit_for <- glm(option_selected_A ~ frame_gain * test  , data = df_for, family = "binomial")
summary(logit_for)
logit_an <- glm(option_selected_A ~ frame_gain * test  , data = df_an, family = "binomial")
summary(logit_an)
stargazer(logit_human, logit_for, logit_an, type = "text", out="H2.2_results_table.html")


##fremove combo 1A

df_hum2 = subset(df_hum, test != "['combo 1A', 'system_message_baseline1', 'user_message_baseline1', 'system role']") ## simple 
df_an2 = subset(df_an, test != "['combo 1A', 'system_message_baseline1', 'user_message_baseline1', 'system role']") ## simple 
df_for2 = subset(df_for, test != "['combo 1A', 'system_message_baseline1', 'user_message_baseline1', 'system role']") ## simple 


logit_human2 <- glm(option_selected_A ~ frame_gain * test   , data = df_hum2, family = "binomial")
summary(logit_human2)
logit_for2 <- glm(option_selected_A ~ frame_gain * test  , data = df_for2, family = "binomial")
summary(logit_for2)
logit_an2 <- glm(option_selected_A ~ frame_gain * test  , data = df_an2, family = "binomial")
summary(logit_an2)
stargazer(logit_human2, logit_for2, logit_an2, type = "text", out="H2.2_results_table.html")






### Tables 
stargazer(logit_ai_risk, logit_ai_system, logit_ai_ins,logit_ai_all, type = "text", out="H2.2_results_table.html")


######################## Framing Effect by Each Mini-Experiment ########################

##All Temp Levels
logit_combo1A <- glm(option_selected_A ~ frame_gain + scenario , data = df_combo1A, family = "binomial")
summary(logit_combo1A) 
logit_combo2 <- glm(option_selected_A ~ frame_gain + scenario , data = df_combo2, family = "binomial")
summary(logit_combo2) 
logit_combo3 <- glm(option_selected_A ~ frame_gain + scenario , data = df_combo3, family = "binomial")
summary(logit_combo3) 
logit_combo3B <- glm(option_selected_A ~ frame_gain + scenario , data = df_combo3B, family = "binomial")
summary(logit_combo3B) 
logit_combo5 <- glm(option_selected_A ~ frame_gain + scenario , data = df_combo5, family = "binomial")
summary(logit_combo5) 
logit_combo5B <- glm(option_selected_A ~ frame_gain + scenario , data = df_combo5B, family = "binomial")
summary(logit_combo5B) 

stargazer(logit_combo1A, logit_combo2, logit_combo3, logit_combo3B,
          type="text", 
          out="combos.html",
          title="Table X - Framing  Effects on Risky Choices by Mini Experiment",
          covariate.labels=c("Frame (Gain)", "Scenario (Human)", "Scenario (Animal)", "Constant" ) )
stargazer(logit_combo5, logit_combo5B,
          type="text", 
          out="combos2.html",
          title="Table X - Framing  Effects on Risky Choices by Mini Experiment",
          covariate.labels=c("Frame (Gain)", "Scenario (Human)", "Scenario (Animal)", "Constabt" ) )

######################## H2.4 Framing Effect by Rating Num ##################

##gpt3$rating_num = factor(gpt3$rating_num, levels = c(1,2,3,4,5,6,7))
##gpt3$rating_cat = factor(gpt3$rating_cat, levels = c('Strong Preference for Proposal A', 'Preference for Proposal A', 'Slight Preference for Proposal A', 'No Preference for Proposal A or B', 'Slight Preference for Propsal B', 'Preference for Proposal B', 'Strong Preference for Proposal B'))

##rating scale reversed from the orginal which was: on a scale of 1 (Strong Preference for Proposal A) to 7 (Strong Preference for Proposal B) and converted to ---> 1 (Strong Preference for Proposal B) to 7(Strong Preference for Proposal A)

ordinal_basic =clm(reversed_rating_num ~ frame_gain ,data = gpt3)
summary(ordinal_basic) 

ordinal_scn =clm(reversed_rating_num ~ frame_gain + scenario,data = gpt3)
summary(ordinal_scn) 

ordinal_all =clm(reversed_rating_num ~ frame_gain + scenario + risk + instructions + sys_role,data = gpt3)
summary(ordinal_all) 

stargazer(ordinal_basic, ordinal_scn, ordinal_all, 
        type="text", 
        out="ordinal_results.html")


##For Each Combo
ordinal_combo1A  =clm(reversed_rating_num ~ frame_gain + scenario,data = df_combo1A)
summary(ordinal_combo1A) 
ordinal_combo2  =clm(reversed_rating_num ~ frame_gain + scenario,data = df_combo2)
summary(ordinal_combo1A) 
ordinal_combo3  =clm(reversed_rating_num ~ frame_gain + scenario,data = df_combo3)
summary(ordinal_combo3) 
ordinal_combo3B  =clm(reversed_rating_num ~ frame_gain + scenario,data = df_combo3B)
summary(ordinal_combo3B) 
ordinal_combo5  =clm(reversed_rating_num ~ frame_gain + scenario,data = df_combo5)
summary(ordinal_combo3B) 
ordinal_combo5B  =clm(reversed_rating_num ~ frame_gain + scenario,data = df_combo5B)
summary(ordinal_combo5B) 

stargazer(ordinal_combo1A, ordinal_combo2, ordinal_combo3, ordinal_combo3B,
        type="text", 
        out="ordinal_results_by_combo.html")
stargazer(ordinal_combo5, ordinal_combo5B,
        type="text", 
        out="ordinal_results_by_combo2.html")



######################## H2.5 Framing Effect by Rating Num & Prompt Conditions ##################

ordinal_sys =clm(reversed_rating_num ~ frame_gain * sys_role + scenario ,data = gpt3)
summary(ordinal_sys) 
  #effect of frame_gain for the "neutral_system" group is -1.03584.
  #effect of frame_gain for the "human" group is (frame_gain + interaction) -1.03584 + 0.79727 = -0.23857.
  #frame_gain:sys_rolehuman: effect of being in the gain frame increases for the human prompt versus neutral;suggests that this preference changes more toward Option A in the gain frame compared to when the sys_role is "neutral_system".
  
ordinal_ins =clm(reversed_rating_num ~ frame_gain * instructions + scenario ,data = gpt3)
summary(ordinal_ins) 
ordinal_risk =clm(reversed_rating_num ~ frame_gain * risk + scenario ,data = gpt3)
summary(ordinal_risk) 
ordinal_all <- clm(reversed_rating_num ~ frame_gain * risk + frame_gain * instructions + frame_gain * sys_role + scenario, data = gpt3)
summary(ordinal_all) 
  #when moving from a loss frame (coded as 0) to a gain frame (coded as 1), there's a decrease in the preference for Proposal A
  #when the risk is explicitly mentioned, there is an increased preference for Proposal A compared to when risk is not mentioned; Becomes even stronger if included in the system role and in the user message. 
stargazer(ordinal_sys, ordinal_ins,ordinal_risk, ordinal_all, 
        type = "text", 
     out="ordinalpromptvars.html", 
    covariate.labels=c("Frame (Gain)", "Sys Role (Human)",  "Instructions (Task Order)", "Risk (Risk)", "Risk (Risk 2x)", "Scenario (Human)", "Scenario (Animal)", 
    "Frame (Gain) x Sys Role (Human)", "Frame (Gain) x Ins. (Task Order)", "Frame (Gain) x Risk (Risk)", "Frame (Gain) x Risk (Risk 2x)"))




###############################################################################################################

# ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ----
################################### Cross Comparative Analysis ################################################
# ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ----

###############################################################################################################


df_combo3B$source = 'AI'
main_analysis$source = 'human'


## Load in Data
combined <- "/Users/annaking/Documents/Github/riskychoiceframing_AI/Experiment 1/analysis/human_and_AI_combined.csv"

#combined <- "/Users/annaking/Documents/Github/riskychoiceframing_AI/Experiment 1/analysis/human_and_AI_3B_combined_.csv"
df_combined <- read_csv(combined)

df_combo3B = subset(gpt3, test == "['combo 3B', 'system_message_risk', 'user_message_risk', 'hum + risk + risk']") ## simple 

#set cat order for source var
df_combined$source_1 = factor(df_combined$source, levels = c("human", "AI"))
df_combined$source_2 = factor(df_combined$source, levels = c("AI", "human"))

#set cat order for scenario var
df_combined$scenario = factor(df_combined$scenario, levels = c("forest", "human", "animal"))

table(df_combined$scenario)

### Hypotheses Testing ###
###### H3A: Preference for Option A in the gain frame with logistic regression
    #coeff frame_gain: the change in humans' odds of choosing Option A when they move from the loss to the gain frame.
    #coeff source_1: the difference between AI and humans in the loss frame (since loss is the reference).
    #coeff source_1:frame_gain: whether the change in odds for AI (from loss to gain frame) is different from that of humans.
    #a model to understand how the choice between Option A and Option B changes based on two main factors: frame (gain vs loss); participant type (human vs. AI)

logit_source_A <- glm(option_selected_A ~ frame_gain * source_1 + scenario , data = df_combined, family = binomial())

summary(logit_source_A)   

logit_source_3B <- glm(option_selected_A ~ frame_gain +scenario , data = df_combo3B, family = binomial())
summary(logit_source_3B)   






##Basic Model 
logit_source_A <- glm(option_selected_A ~ frame_gain * source_1 , data = df_combined, family = binomial())
summary(logit_sourcehum_A)   
coefs_A <- coef(logit_sourcehum_A)
odds_ratio_AI_A <- exp(coef_A["source_1AI"] + coef_A["frame_gain:source_1AI"])
print(odds_ratio_AI_A) 
    #odds_ratio_AI_A: Represents the odds of AI choosing Option A over Option B in the gain frame (relative to the loss frame) compared to the same odds for humans
odds_ratio_AI_Hum <- exp(coef_A["frame_gain:source_1AI"])
print(odds_ratio_AI_Hum) 
     #odds_ratio_AI_A: Represents how the odds of AI choosing Option A over Option B when transitioning from the loss frame to the gain frame differ from the odds of humans making the same transition.

o_prob(odds_example)
print(probability_example)
## + Scenario Control 
logit_source_scn <- glm(option_selected_A ~ frame_gain * source_1 + scenario, data = df_combined, family = binomial())
summary(logit_source_scn)

### + Temp Control 
logit_source_temp <- glm(option_selected_A ~ frame_gain * source_1 + scenario + temp_alt, data = df_combined, family = binomial())
summary(logit_source_temp)

######### Investigate Gain versus Loss Condition

###Split by gain and loss
##I believe i need to boostrap the human as the power is too low?????? 
df_gain = subset(df_combined, frame_gain == 1)
df_gain$source_1 <- factor(df_gain$source, levels = c("human", "AI"))
df_gain$source_2 <- factor(df_gain$source, levels = c("AI", "human"))

df_loss = subset(df_combined, frame_loss == 0)
df_loss$source_1 <- factor(df_loss$source, levels = c("human", "AI"))
df_loss$source_2 <- factor(df_loss$source, levels = c("AI", "human"))

logit_gain_A_AI <- glm(option_selected_A ~ source_1, data = df_gain, family = binomial())
logit_gain_A_hum <- glm(option_selected_A ~ source_2, data = df_gain, family = binomial())
summary(logit_gain_B_AI)
summary(logit_gain_B_hum)

logit_loss_B_AI <- glm(option_selected_B ~ source_1, data = df_loss, family = binomial())
logit_loss_B_hum <- glm(option_selected_B ~ source_2, data = df_loss, family = binomial())
summary(logit_loss_B_AI)
summary(logit_loss_B_hum)

####### Create Tables

############### ################ ############### ################
get_model_values <- function(model) {
  coef_sum <- coef(summary(model))
  results <- c()
  for (name in rownames(coef_sum)) {
    est <- coef_sum[name, 1]
    se <- coef_sum[name, 2]
    pvalue <- coef_sum[name, 4]
    significance <- if (pvalue < 0.05) "*" else ""
    results[name] <- paste0(round(est, 3), " (", round(se, 3), ") ", significance)
  }
  results["Observations"] <- length(model$fitted.values)
  results["Pseudo R^2"] <- round(1 - model$deviance / model$null.deviance, 3)
  return(results)
}
results_A <- get_model_values(logit_sourcehum_A)
results_B2 <- get_model_values(logit_sourcehum_B2)
results_B <- get_model_values(logit_sourcehum_B)
results_A2 <- get_model_values(logit_sourcehum_A2)

table <- data.frame(
  `Model A` = results_A,
  `Model B2` = results_B2,
  `Model B` = results_B,
  `Model A2` = results_A2
)
print(table, row.names=TRUE)
write_xlsx(table, "modelcompare_cross.xlsx")


 ############### ################ ############### ################

###### H4B: Influence of AI prompt on similarity
# - Investigate the interaction between the type of AI prompt and frame (gain/loss) in influencing the AI's choices.
# - Include an interaction term between AI prompt and frame in a logistic regression with Option_selected as the dependent variable.







############ ARCHIVE - CROSS COMAPRE ############
logit_sourcehum_A <- glm(option_selected_B ~ frame_loss * source_1 , data = df_combined, family = binomial())
summary(logit_sourcehum_A) 

'option_selected_A ~ frame_gain * source_1'

""" Coefficients:
                      Estimate Std. Error z value Pr(>|z|)    
(Intercept)             0.6035     0.2102   2.871  0.00409 ** 
frame_gain              0.5879     0.3139   1.873  0.06109 .  
source_1AI             -0.4097     0.2169  -1.889  0.05888 .  
frame_gain:source_1AI  -1.5875     0.3236  -4.905 9.33e-07 *** """

'option_selected_B ~ frame_gain * source_1' 

"""Coefficients:
                      Estimate Std. Error z value Pr(>|z|)    
(Intercept)            -0.6035     0.2102  -2.871  0.00409 ** 
frame_gain             -0.5879     0.3139  -1.873  0.06109 .  
source_1AI              0.4097     0.2169   1.889  0.05888 .  
frame_gain:source_1AI   1.5875     0.3236   4.905 9.33e-07 ***"""

'option_selected_A ~ frame_loss * source_1' 
#going from gain to loss frame
##option A to Option B 
"""                      Estimate Std. Error z value Pr(>|z|)    
(Intercept)             1.1914     0.2331   5.112 3.19e-07 ***
frame_loss             -0.5879     0.3139  -1.873   0.0611 .  
source_1AI             -1.9971     0.2402  -8.314  < 2e-16 ***
frame_loss:source_1AI   1.5875     0.3236   4.905 9.33e-07 ***"""  ##A negative combined effect indicates that AI has lower log odds of choosing Option B over Option A than humans in the loss frame.

'option_selected_B ~ frame_loss * source_1' 
#going from gain to loss frame
##option B to Option A

"""Coefficients:
                      Estimate Std. Error z value Pr(>|z|)    
(Intercept)            -1.1914     0.2331  -5.112 3.19e-07 ***
frame_loss              0.5879     0.3139   1.873   0.0611 .  
source_1AI              1.9971     0.2402   8.314  < 2e-16 ***
frame_loss:source_1AI  -1.5875     0.3236  -4.905 9.33e-07 ***"""

#define bootstrap function
bootstrap_coefs <- function(data, cell_sizes, n_iterations = 10000) {
  coefs <- matrix(NA, ncol = 4, nrow = n_iterations) 
  colnames(coefs) <- c("(Intercept)", "scenariohuman", "scenarioanimal", "frameloss")
  
  for(i in 1:n_iterations) {
    sample_data <- do.call(rbind, 
                           lapply(names(cell_sizes), function(cell) {
                             cell_data <- data[data$scenario == unlist(strsplit(cell, split=", "))[1] & 
                                               data$frame == unlist(strsplit(cell, split=", "))[2], ]
                             cell_data[sample(nrow(cell_data), cell_sizes[[cell]], replace = TRUE), ]
                           }))
    
    model <- glm(option_selected ~ scenario + frame, family = binomial(), data = sample_data)
    
    current_coefs <- coef(model)
    # If the model produces fewer coefficients than expected, fill the missing ones with NA
    coefs[i, names(current_coefs)] <- current_coefs
  }
  
  return(coefs)
}

extract_and_pivot <- function(models_list){
  tidy_data <- lapply(names(models_list), function(model_name){
    model <- models_list[[model_name]]
    tidy(model) %>%
      select(term, estimate) %>%
      rename(Variable = term) %>%
      mutate(Source = model_name)
  }) %>% bind_rows()
  
  pivoted_data <- tidy_data %>%
    pivot_wider(names_from = Source, values_from = estimate)
  
  return(pivoted_data)
}

##Combo1A

df = df_combo1A
df$scenario <- as.factor(df$scenario)
df$frame <- as.numeric(df$frame == 'gain')
df$option_selected <- as.numeric(df$option_selected == 'Proposal A') 

##Combo2
df = df_combo2
df$scenario <- as.factor(df$scenario)
df <- df %>%
  mutate(frame = recode(frame, "gain" = 1, "loss" = 0))
df$option_selected <- as.numeric(df$option_selected == 'Proposal A') 

table(df$frame, df$scenario)
set.seed(20000)
coefs <- bootstrap_coefs(df, cell_sizes)

coef_summary <- data.frame(
  Coefficient = colnames(coefs),
  Mean = apply(coefs, 2, mean),
  SE = apply(coefs, 2, sd),
  CI_low = apply(coefs, 2, function(x) quantile(x, 0.025)),
  CI_high = apply(coefs, 2, function(x) quantile(x, 0.975))
)
print(coef_summary)

df_1 = subset(df, run_type == 'round 1')
df_all = glm(option_selected ~ scenario + frame, family = binomial(), data = df)
summary(df_all)
df_r1 = glm(option_selected ~ scenario + frame, family = binomial(), data = df_1)
summary(df_r1)

install.packages("tidyverse")
library(tidyverse)


###########
bootstrap_results <- bootstrap_coefs(df, cell_sizes, n_iterations = 10000)
bootstrap_means <- colMeans(bootstrap_results, na.rm = TRUE)

coefs_list <- list(
  Bootstrap = bootstrap_means,
  df_all = coef(df_all),
  df_r1 = coef(df_r1)
)
extract_and_pivot_coefs <- function(coefs_list){
  tidy_data <- enframe(unlist(coefs_list), name = "Source", value = "estimate") %>%
               separate(name, into = c("Source", "Variable"), sep = "\\.")
  
  pivoted_data <- tidy_data %>%
    pivot_wider(names_from = Source, values_from = estimate)
  
  return(pivoted_data)
}

result_table <- extract_and_pivot_coefs(coefs_list)
print(result_table)

