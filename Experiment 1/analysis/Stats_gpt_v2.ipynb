{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import rpy2.robjects as robjects\n",
    "#from rpy2.robjects import pandas2ri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare & Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4462, 8)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Load Data \n",
    "gpt3 = \"/Users/annaking/Documents/Github/riskychoiceframing_AI/Experiment 2/tests/variable_prompt_test_turbo.csv\"\n",
    "####gpt3 = \"/Users/annaking/Documents/Github/riskychoiceframing_AI/Experiment 2/tests/prompt_testing073123_v1.csv\"\n",
    "df_gpt3 = pd.read_csv(gpt3)\n",
    "df_gpt3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test                                                                                               frame      \n",
       "['combo 1A', 'system_message_baseline1', 'user_message_baseline1', 'system role', 'gain_animal2']  gain_animal      3\n",
       "['combo 1A', 'system_message_baseline1', 'user_message_baseline1', 'system role']                  gain_animal    102\n",
       "                                                                                                   gain_forest    105\n",
       "                                                                                                   gain_human      60\n",
       "                                                                                                   loss_animal     74\n",
       "                                                                                                                 ... \n",
       "['combo 8C3', 'system_message_1C', 'user_message_4_p', 'instructions: task order & output']        loss_human       2\n",
       "['combo 8D', 'system_message_1_json', 'user_message_6B2', 'instructions: task order & output']     gain_human       2\n",
       "                                                                                                   loss_human       2\n",
       "['combo 9', 'system_message_1', 'user_message_5']                                                  gain_human      60\n",
       "                                                                                                   loss_human      74\n",
       "Length: 101, dtype: int64"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##check test runs\n",
    "df_gpt3.groupby(['test','frame']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cleaning\n",
    "\n",
    "#clean test names\n",
    "df_gpt3['test'] = df_gpt3['test'].replace(\"['combo 7', 'system_message_1D', 'user_message_7']\", \"['combo 7', 'system_message_1B', 'user_message_7']\")\n",
    "##df_gpt3['test'] = df_gpt3['test'].replace(\"\", \"['combo 8C3', 'system_message_1C', 'user_message_4', 'instructions: task order & output']\")\n",
    "df_gpt3['test'] = df_gpt3['test'].replace(\"['combo 4', 'system_message_4', 'user_message_4']\", \"['combo 3', 'system_message_risk', 'user_message_baseline1', 'risk system']\")\n",
    "df_gpt3['test'] = df_gpt3['test'].replace(\"['combo 8A', 'system_message_1C', 'user_message_4', 'instructions: task order & output']\", \"['combo 2', 'system_message_hum', 'user_message_baseline1', 'human']\")\n",
    "df_gpt3['test'] = df_gpt3['test'].replace(\"['combo 3', 'system_message_1C', 'user_message_baseline1', 'human']\", \"['combo 2', 'system_message_hum', 'user_message_baseline1', 'human']\")\n",
    "df_gpt3['test'] = df_gpt3['test'].replace(\"['combo 4B', 'system_message_4', 'user_message_5']\", \"['combo 6B', 'system_message_risk', 'user_message_chain', 'risk + chain']\")\n",
    "df_gpt3['test'] = df_gpt3['test'].replace(\"['combo 9', 'system_message_1', 'user_message_5']\", \"['combo 6', 'system_message_1', 'user_message_chain', 'flag for re-run']\")\n",
    "df_gpt3['test'] = df_gpt3['test'].replace(\"['combo 5', 'system_message_baseline1', 'user_message_q1', 'q1 options']\", \"['combo 7', 'system_message_baseline1', 'user_message_q1', 'q1 options']\")\n",
    "df_gpt3['test'] = df_gpt3['test'].replace(\"['combo 8D', 'system_message_1_json', 'user_message_6B2', 'instructions: task order & output']\", \"['combo 5', 'system_message_hum_json', 'user_message_taskord', 'hum + task order']\")\n",
    "\n",
    "conditions1 = (df_gpt3['test'] == \"['combo 8', 'system_message_1', 'user_message_4']\") & (df_gpt3['temperature'] == .7)\n",
    "df_gpt3.loc[conditions1, 'test'] = \"['combo 2', 'system_message_hum', 'user_message_baseline1', 'human']\"\n",
    "\n",
    "##beg prompt \n",
    "pattern = r'(.*?)\\s*Scenario:'\n",
    "df_gpt3['prompt_start'] = df_gpt3['prompt'].str.extract(pattern,  flags=re.DOTALL)\n",
    "df_gpt3[['frame', 'scenario']] = df_gpt3['frame'].str.split('_', n=1, expand=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "##drop  tests \n",
    "bad_tests = [\"['combo 8C', 'system_message_1_json', 'user_message_6B2', 'instructions: task order & output']\",\n",
    " \"['combo 6', 'system_message_1B', 'user_message_6']\", \n",
    " \"['combo 8C2', 'system_message_1_jsonjp', 'user_message_4_p', 'instructions: task order & output']\",\n",
    " \"['combo 6D', 'system_message_1B', 'user_message_6B']\" , ##included too many changes in user message and odd spacing\n",
    " \"['combo 6B', 'system_message_1C', 'user_message_6B']\", ##mismatch in JSON output instructions\n",
    " \"['combo 7', 'system_message_1B', 'user_message_7']\",##odd spacing and mismatch \n",
    " \"['combo 6C', 'system_message_1C', 'user_message_6C']\", ##mismatch in JSON output instructions; removed options for question 1 \n",
    " \"['combo 8C3', 'system_message_1C', 'user_message_4_p', 'instructions: task order & output']\" ,##included plural responses \n",
    " ###\"['combo 9', 'system_message_1', 'user_message_5']\", ##mispelling ###not droppping yet\n",
    " \"['combo 8A', 'system_message_1C', 'user_message_4', 'instructions: task order & output']\" ,\n",
    " \"['combo 8', 'system_message_1', 'user_message_4']\",\n",
    " ###\"['combo 7', 'system_message_hum', 'user_message_q1', 'q1 options']\",\n",
    " \"['combo 7', 'system_message_baseline1', 'user_message_q1', 'q1 options']\", \n",
    " \"['combo 7', 'system_message_baseline1', 'user_message_noq3', 'hum + simple + noq3']\",\n",
    " \"['combo 5_2', 'system_message_hum_json', 'user_message_taskord_2', 'hum + task order']\"\t, ###Â testing the effect of spacing in the sep JSON object\n",
    " \"['combo 7', 'system_message_hum', 'user_message_noq3', 'hum + simple + noq3']\", ##doesnt appear to ahve sig impact \n",
    " \"['combo 7B', 'system_message_baseline1', 'user_message_noq3', 'hum + simple + noq3']\" ,##doesnt appear to ahve sig impact \n",
    " \"['combo 1A', 'system_message_baseline1', 'user_message_baseline1', 'system role', 'gain_animal2']\", \n",
    " \"['combo 6', 'system_message_1', 'user_message_chain', 'flag for re-run']\", ##wrong system message,\n",
    " \"['combo 2', 'system_message_hum', 'user_message_baseline1', 'human', 'gain_animal3']\", ##test for altered animal scenario framing\n",
    " \"['combo 2', 'system_message_hum', 'user_message_baseline1', 'human', 'loss_forest5']\"\t,\n",
    " \"['combo 2', 'system_message_hum', 'user_message_baseline1', 'human', 'loss_forest3']\",\n",
    " \"['combo 2', 'system_message_hum', 'user_message_baseline1', 'human', 'gain_forest2']\",\t\n",
    " \"['combo 2', 'system_message_hum', 'user_message_baseline1', 'human', 'gain_forest3']\",\n",
    " \"['combo 2', 'system_message_hum', 'user_message_baseline1', 'human', 'gain_forest4']\",\n",
    " \"['combo 2', 'system_message_hum', 'user_message_baseline1', 'human', 'gain_forest5']\"\t,\n",
    " \"['combo 5A', 'system_message_hum', 'user_message_taskord_simp', 'hum + taskordsimp']\"\t,\n",
    " \"['combo 7C', 'system_message_hum', 'user_message_q1_options', 'hum + q1_options']\" , ## will bring back\n",
    "\"['combo 7', 'system_message_hum', 'user_message_q1', 'q1 options']\", \n",
    "\"['combo 3B', 'system_message_risk', 'user_message_risk', 'hum + risk + risk']\" ##should bring back\n",
    "]## will bring back\n",
    "df_gpt3 = df_gpt3[~df_gpt3['test'].isin(bad_tests)]\n",
    "\n",
    "#remove wrong animal gain test\n",
    "df_gpt3 = df_gpt3[~df_gpt3['prompt'].str.contains('1,000')]\n",
    "\n",
    "#remove where scenario did not get included \n",
    "df_gpt3 = df_gpt3[~df_gpt3['prompt'].str.contains(\"\"\"{}\"\"\")]\n",
    "\n",
    "#drop accidental test duplicate \n",
    "gain_6B_hum_ext = (df_gpt3['test'] == \"['combo 6B', 'system_message_risk', 'user_message_chain', 'risk + chain']\") & (df_gpt3['scenario'] == 'human') & (df_gpt3['frame'] == 'gain') & (df_gpt3['temperature'] == 0)\n",
    "loss_6B_hum_ext = (df_gpt3['test'] == \"['combo 6B', 'system_message_risk', 'user_message_chain', 'risk + chain']\") & (df_gpt3['scenario'] == 'human') & (df_gpt3['frame'] == 'loss') & (df_gpt3['temperature'] == 0)\n",
    "gain_2_hum_ext = (df_gpt3['test'] == \"['combo 2', 'system_message_hum', 'user_message_baseline1', 'human']\") & (df_gpt3['scenario'] == 'human') & (df_gpt3['frame'] == 'gain') & (df_gpt3['temperature'] == 0)\n",
    "gain_3B_hum_ext = (df_gpt3['test'] == \"['combo 3B', 'system_message_risk', 'user_message_risk', 'hum + risk + risk']\") & (df_gpt3['scenario'] == 'human') & (df_gpt3['frame'] == 'gain') & (df_gpt3['temperature'] == 0)\n",
    "\n",
    "\n",
    "loss_3_ani_ext = (df_gpt3['test'] == \"['combo 3', 'system_message_risk', 'user_message_baseline1', 'risk system']\") & (df_gpt3['scenario'] == 'animal') & (df_gpt3['frame'] == 'loss') & (df_gpt3['temperature'] == .7)\n",
    "\n",
    "loss_5B_for_ext = (df_gpt3['test'] == \"['combo 5B', 'system_message_risk_json', 'user_message_taskord', 'risk + task order']\") & (df_gpt3['scenario'] == 'forest') & (df_gpt3['frame'] == 'loss') & (df_gpt3['temperature'] == .7)\n",
    "gain_5B_for_ext = (df_gpt3['test'] == \"['combo 5B', 'system_message_risk_json', 'user_message_taskord', 'risk + task order']\") & (df_gpt3['scenario'] == 'forest') & (df_gpt3['frame'] == 'gain') & (df_gpt3['temperature'] == .7)\n",
    "loss_7C_for_ext = (df_gpt3['test'] == \"['combo 7C', 'system_message_hum', 'user_message_q1_options', 'hum + q1_options']\") & (df_gpt3['scenario'] == 'forest') & (df_gpt3['frame'] == 'loss') & (df_gpt3['temperature'] == 0)\n",
    "gain_7C_for_ext = (df_gpt3['test'] == \"['combo 7C', 'system_message_hum', 'user_message_q1_options', 'hum + q1_options']\") & (df_gpt3['scenario'] == 'forest') & (df_gpt3['frame'] == 'gain') & (df_gpt3['temperature'] == 0)\n",
    "gain_6_for_ext = (df_gpt3['test'] == \"['combo 6', 'system_message_hum', 'user_message_chain', 'hum + chain']\") & (df_gpt3['scenario'] == 'forest') & (df_gpt3['frame'] == 'gain') & (df_gpt3['temperature'] == 0)\n",
    "loss_6_for_ext = (df_gpt3['test'] == \"['combo 6', 'system_message_hum', 'user_message_chain', 'hum + chain']\") & (df_gpt3['scenario'] == 'forest') & (df_gpt3['frame'] == 'loss') & (df_gpt3['temperature'] == 0)\n",
    "\n",
    "\n",
    "drop_gain_6B_hum_ext = df_gpt3[gain_6B_hum_ext].index[-45:]  \n",
    "drop_loss_6B_hum_ext = df_gpt3[loss_6B_hum_ext].index[-52:] \n",
    "drop_gain_2_hum_ext = df_gpt3[gain_2_hum_ext].index[-2:]  \n",
    "drop_gain_3B_hum_ext = df_gpt3[gain_3B_hum_ext].index[-7:]  \n",
    "\n",
    "\n",
    "drop_loss_3_ani_ext = df_gpt3[loss_3_ani_ext].index[-37:]  \n",
    "\n",
    "drop_gain_5B_for_ext = df_gpt3[gain_5B_for_ext].index[-35:]  \n",
    "drop_loss_5B_for_ext = df_gpt3[loss_5B_for_ext].index[-28:]  \n",
    "drop_gain_7C_for_ext = df_gpt3[gain_7C_for_ext].index[-32:]  \n",
    "drop_loss_7C_for_ext = df_gpt3[loss_7C_for_ext].index[-25:]  \n",
    "drop_gain_6_for_ext = df_gpt3[gain_6_for_ext].index[-3:]  \n",
    "drop_loss_6_for_ext = df_gpt3[loss_6_for_ext].index[-3:]  \n",
    "\n",
    "df_gpt3 = df_gpt3.drop(drop_gain_6B_hum_ext)\n",
    "df_gpt3 = df_gpt3.drop(drop_loss_6B_hum_ext)\n",
    "df_gpt3 = df_gpt3.drop(drop_gain_2_hum_ext)\n",
    "df_gpt3 = df_gpt3.drop(drop_gain_3B_hum_ext)\n",
    "\n",
    "df_gpt3 = df_gpt3.drop(drop_loss_3_ani_ext)\n",
    "\n",
    "df_gpt3 = df_gpt3.drop(drop_gain_5B_for_ext)\n",
    "df_gpt3 = df_gpt3.drop(drop_loss_5B_for_ext)\n",
    "df_gpt3 = df_gpt3.drop(drop_gain_7C_for_ext)\n",
    "df_gpt3 = df_gpt3.drop(drop_loss_7C_for_ext)\n",
    "df_gpt3 = df_gpt3.drop(drop_gain_6_for_ext)\n",
    "df_gpt3 = df_gpt3.drop(drop_loss_6_for_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2830, 10)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gpt3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "##clean json \n",
    "# import json \n",
    "def clean_json(x):\n",
    "    x = x.strip(\"'\")  # remove leading/trailing single quotes\n",
    "    x = x.strip(\"\\n\")  # remove leading/trailing newline characters\n",
    "    x = x.encode('utf-8', 'ignore').decode('utf-8')  # ignore non utf-8 characters\n",
    "    x = re.sub(r'\"\\s*\"', '\",\"', x)  # replace spaces between quotes with commas\n",
    "    #replace incorrect JSON keys with correct keys\n",
    "    for key in [\"Q1_Response\", \"Q2_Response\", \"Q3_Response\"]:\n",
    "        x = re.sub(f'(?<=[{{,])\\s*{key}\\s*(?=:)', f' \"{key}\"', x)\n",
    "    # make sure quotes \n",
    "    x = re.sub(r':\\s*([0-9]+)\\s*(?=[,}])', r': \"\\1\"', x)\n",
    "\n",
    "    # cleaning steps\n",
    "    x = x.replace('Q1_response','Q1_Response')\n",
    "    x = x.replace('Q2_response','Q2_Response')\n",
    "    x = x.replace('Q3_response','Q3_Response')\n",
    "    x = x.replace('it\"s', 'it\\'s')\n",
    "    x = x.replace('B\"s', \"B's\")\n",
    "    x = x.replace(\"}, {\", \",\")\n",
    "    x = x.replace(\"},{\", \",\")\n",
    "\n",
    "    for proposal in [\"Proposal A\", \"Proposal B\"]:\n",
    "        x = re.sub(f'(?<=:)\\s*{proposal}(?=\\s*[^\"]\\w*,)', f' \"{proposal}\"', x)\n",
    "    x = re.sub(r'}\\s*{', ', ', x)\n",
    "    if not x.startswith('{'):\n",
    "        x = '{' + x\n",
    "    if not x.endswith('}'):\n",
    "        x = x + '}'\n",
    "    try:\n",
    "        x = x.replace('\\n', ' ')\n",
    "        x = json.dumps(json.loads(x))\n",
    "    except json.JSONDecodeError:\n",
    "        return x\n",
    "    return x\n",
    "\n",
    "def try_loads(x):\n",
    "    try:\n",
    "        return pd.Series(json.loads(x))\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error decoding: {x}\")\n",
    "        return pd.Series()\n",
    "\n",
    "df_gpt3['response'] = df_gpt3['response'].apply(clean_json)\n",
    "responses = df_gpt3.apply(lambda x: pd.Series(json.loads(x['response'])), axis=1, result_type='expand')\n",
    "df_gpt3 = pd.concat([df_gpt3, responses], axis = 1)\n",
    "df_gpt3 = df_gpt3.reset_index()\n",
    "df_gpt3['Q1_Response']  = df_gpt3['Q1_Response'].apply(lambda x: 'Proposal B' if x == 'Option B' else x)\n",
    "df_gpt3['Q1_Response']  = df_gpt3['Q1_Response'].apply(lambda x: 'Proposal A' if x == 'Option A' else x)\n",
    "df_gpt3 = df_gpt3[~df_gpt3['Q2_Response'].isna()]\n",
    "\n",
    "###responses = df_gpt3['response'].apply(try_loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "##define variables for each test \n",
    "import ast\n",
    "test_dict = {\n",
    "    \"['combo 1A', 'system_message_baseline1', 'user_message_baseline1', 'system role']\": \"['neutral_system','simple','neutral_risk']\",\n",
    "    \"['combo 2', 'system_message_hum', 'user_message_baseline1', 'human']\":\"['human','simple', 'neutral_risk']\",\n",
    "    \"['combo 3', 'system_message_risk', 'user_message_baseline1', 'risk system']\":\"['human','simple', 'risk']\",  \n",
    "    \"['combo 5', 'system_message_hum_json', 'user_message_taskord', 'hum + task order']\": \"['human','task_order', 'neutral_risk']\",\n",
    "    \"['combo 5B', 'system_message_risk_json', 'user_message_taskord', 'risk + task order']\": \"['human','task_order', 'risk']\",\n",
    "    \"['combo 6', 'system_message_1', 'user_message_chain', 'flag for re-run']\": \"['human','chain','neutral_risk' ]\",\n",
    "    \"['combo 6', 'system_mÄssage_hum', 'user_message_chain', 'hum + chain']\": \"['human','chain','neutral_risk' ]\",\n",
    "    \"['combo 6B', 'system_message_risk', 'user_message_chain', 'risk + chain']\": \"['human','chain','risk']\"\n",
    "    }\n",
    "\n",
    "var_dict = {'sys_role': ['human', 'neutral_system'],\n",
    "            'instructions': ['simple', 'chain', 'task_order'],\n",
    "            'risk': ['neutral_risk', 'risk']}\n",
    "\n",
    "\n",
    "new_test_dict = {}\n",
    "for key, value in test_dict.items():\n",
    "    new_key = ast.literal_eval(key)\n",
    "    new_value = ast.literal_eval(value)\n",
    "    new_test_dict[tuple(new_key)] = new_value\n",
    "\n",
    "\n",
    "def map_values(test_name):\n",
    "    # Dictionary to hold our results\n",
    "    result = {}\n",
    "    test_list = ast.literal_eval(test_name)\n",
    "    variable_list = test_dict.get(test_name, [])\n",
    "    \n",
    "    # Iterate over the variable dictionary\n",
    "    for var_type, values in var_dict.items():\n",
    "        # Check if any value from var_dict is in the variable_list\n",
    "        for val in values:\n",
    "            if val in variable_list:\n",
    "                result[var_type] = val\n",
    "                break  # break once we find a match\n",
    "                \n",
    "    # Return as a Series\n",
    "    return pd.Series(result)\n",
    "df_gpt3 = df_gpt3.join(df_gpt3['test'].apply(map_values))\n",
    "\n",
    "##order into dummies \n",
    "ins = ['simple', 'chain', 'task_order']\n",
    "sys = ['human', 'neutral_system']\n",
    "rsk = ['neutral_risk', 'risk']\n",
    "\n",
    "df_gpt3['instructions'] = df_gpt3['instructions'].astype('category').cat.reorder_categories(ins, ordered=True)\n",
    "df_gpt3['sys_role'] = df_gpt3['sys_role'].astype('category').cat.reorder_categories(sys, ordered=True)\n",
    "df_gpt3['risk'] = df_gpt3['risk'].astype('category').cat.reorder_categories(rsk, ordered=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (3) does not match length of index (2818)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[161], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_gpt3[\u001b[39m'\u001b[39;49m\u001b[39mtest_name\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m=\u001b[39m(df_gpt3[\u001b[39m'\u001b[39m\u001b[39msys_role\u001b[39m\u001b[39m'\u001b[39m], df_gpt3[\u001b[39m'\u001b[39m\u001b[39minstructions\u001b[39m\u001b[39m'\u001b[39m], df_gpt3[\u001b[39m'\u001b[39m\u001b[39mrisk\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:3950\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3947\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3948\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3949\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[0;32m-> 3950\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:4143\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4133\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4134\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4135\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4136\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4141\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4142\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4143\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[1;32m   4145\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   4146\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m   4147\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   4148\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   4149\u001b[0m     ):\n\u001b[1;32m   4150\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4151\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:4870\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4867\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[1;32m   4869\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4870\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[1;32m   4871\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/common.py:576\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    575\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[0;32m--> 576\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    577\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (3) does not match length of index (2818)"
     ]
    }
   ],
   "source": [
    "df_gpt3['test_name'] =(df_gpt3['sys_role'], df_gpt3['instructions'], df_gpt3['risk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean Dependent Variables\n",
    "import re\n",
    "#Option Selected\n",
    "df_gpt3['option_selected'] =  df_gpt3['Q1_Response']\n",
    "\n",
    "#Rating Number\n",
    "df_gpt3['Q2_Response'] = df_gpt3['Q2_Response'].astype('str')\n",
    "df_gpt3['rating_num'] = df_gpt3['Q2_Response'].str.extract(r'(\\d+)')\n",
    "df_gpt3['rating_num'] = df_gpt3['rating_num'].astype('int')\n",
    "\n",
    "\n",
    "##categorize\n",
    "ratings =  { 'Strong Preference for Proposal A': 1, 2: 'Preference for Proposal A', 3:'Slight Preference for Proposal A',  4:'No Preference for Proposal A or B',  5:'Slight Preference for Propsal B',  6:'Preference for Proposal B',7:'Strong Preference for Proposal B'}\n",
    "##df_gpt3['rating_num'] = pd.to_numeric(df_gpt3['rating_num'], errors='coerce')\n",
    "##df_gpt3['rating_cat'] = df_gpt3['rating_num'].map(ratings)\n",
    "###df_gpt3 = df_gpt3[~df_gpt3['rating_num'].isna()]\n",
    "##df_gpt3['rating_cat'] = df_gpt3['rating_num'].map(ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Dummy Variables \n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "##prompt variables \n",
    "df_gpt3['sys_role'] = df_gpt3['sys_role'].astype(pd.CategoricalDtype(categories=['neutral_system', 'human'], ordered=True))\n",
    "\n",
    "sys_role_dummy = pd.get_dummies(df_gpt3['sys_role'], prefix='sys_role', drop_first=True)\n",
    "instructions_dummy  = pd.get_dummies(df_gpt3['instructions'], prefix='instructions', drop_first=True)\n",
    "risk_dummy = pd.get_dummies(df_gpt3['risk'], prefix='risk', drop_first=True)\n",
    "\n",
    "#create variables for dep. and indp. \n",
    "df_gpt3['frame_gain'] = (df_gpt3['frame'] == 'gain').astype(int)\n",
    "df_gpt3['option_selected_B'] = le.fit_transform(df_gpt3['option_selected']) ##0 = Prop A, 1 = Prop B\n",
    "df_gpt3['option_selected_A'] = 1 - df_gpt3['option_selected_B']  ## Reversing the encoding\n",
    "df_gpt3['scenario_c'] = df_gpt3['scenario'].astype(pd.CategoricalDtype(categories=['forest', 'animal', 'human'], ordered=True))\n",
    "df_gpt3['reversed_rating_num'] = 8 - df_gpt3['rating_num']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "##save for cross compare \n",
    "df_gpt3.to_csv('df_gpt3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at each Test Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Q1_Response</th>\n",
       "      <th>frame</th>\n",
       "      <th>Proposal A</th>\n",
       "      <th>Proposal B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gain</td>\n",
       "      <td>0.2909</td>\n",
       "      <td>0.7091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>loss</td>\n",
       "      <td>0.5416</td>\n",
       "      <td>0.4584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Q1_Response frame  Proposal A  Proposal B\n",
       "0            gain      0.2909      0.7091\n",
       "1            loss      0.5416      0.4584"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Choice Cross tab \n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "t0 = df_gpt3[df_gpt3['temperature'] == 0 ]\n",
    "t7 = df_gpt3[df_gpt3['temperature'] == .7 ]\n",
    "\n",
    "#t7_ct = pd.crosstab([t7['test'] ,t7['scenario'] ] ,[t7['frame'], t7['Q1_Response']]) ###\n",
    "#t0_ct = pd.crosstab([t0['test'] ,t0['scenario'] ] ,[t0['frame'], t0['Q1_Response']])\n",
    "#t0_ct = pd.crosstab([t0['test'] ] ,[t0['frame'], t0['Q1_Response']])\n",
    "t0_ct = pd.crosstab(t0['frame'], t0['Q1_Response'], normalize='index').reset_index()\n",
    "\n",
    "t0_ct.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Archive -- new columns \n",
    "\n",
    "new_columns = []\n",
    "for column in df_cross_tab.columns:\n",
    "    if isinstance(column, tuple):  # this will be true for the temperature-related columns\n",
    "        if column[0] == 0.0 and column[1] == 'Proposal A':\n",
    "            new_columns.append('PA_t0')\n",
    "        elif column[0] == 0.0 and column[1] == 'Proposal B':\n",
    "            new_columns.append('PB_t0')\n",
    "        elif column[0] == 0.7 and column[1] == 'Proposal A':\n",
    "            new_columns.append('PA_t.7')\n",
    "        elif column[0] == 0.7 and column[1] == 'Proposal B':\n",
    "            new_columns.append('PB_t.7')\n",
    "        elif column[0] == 1 and column[1] == 'Proposal A':\n",
    "            new_columns.append('PA_t1')\n",
    "        else: \n",
    "             new_columns.append('PB_t1')\n",
    "    else:  # this will be true for 'test' and 'frame' columns\n",
    "        new_columns.append(column)\n",
    "df_cross_tab.columns = new_columns\n",
    "df_cross_tab.reset_index(inplace=True)\n",
    "df_cross_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>frame</th>\n",
       "      <th>PA_t0_pct</th>\n",
       "      <th>PA_t.7_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['combo 1A', 'system_message_baseline1', 'user_message_baseline1', 'system role']</td>\n",
       "      <td>gain</td>\n",
       "      <td>30.30</td>\n",
       "      <td>34.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['combo 1A', 'system_message_baseline1', 'user_message_baseline1', 'system role']</td>\n",
       "      <td>loss</td>\n",
       "      <td>72.55</td>\n",
       "      <td>64.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['combo 2', 'system_message_hum', 'user_message_baseline1', 'human']</td>\n",
       "      <td>gain</td>\n",
       "      <td>30.30</td>\n",
       "      <td>36.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['combo 2', 'system_message_hum', 'user_message_baseline1', 'human']</td>\n",
       "      <td>loss</td>\n",
       "      <td>72.55</td>\n",
       "      <td>51.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['combo 3', 'system_message_risk', 'user_message_baseline1', 'risk system']</td>\n",
       "      <td>gain</td>\n",
       "      <td>30.30</td>\n",
       "      <td>35.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>['combo 3', 'system_message_risk', 'user_message_baseline1', 'risk system']</td>\n",
       "      <td>loss</td>\n",
       "      <td>72.55</td>\n",
       "      <td>59.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>['combo 3B', 'system_message_risk', 'user_message_risk', 'hum + risk + risk']</td>\n",
       "      <td>gain</td>\n",
       "      <td>96.97</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>['combo 3B', 'system_message_risk', 'user_message_risk', 'hum + risk + risk']</td>\n",
       "      <td>loss</td>\n",
       "      <td>72.55</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>['combo 5', 'system_message_hum_json', 'user_message_taskord', 'hum + task order']</td>\n",
       "      <td>gain</td>\n",
       "      <td>4.04</td>\n",
       "      <td>26.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>['combo 5', 'system_message_hum_json', 'user_message_taskord', 'hum + task order']</td>\n",
       "      <td>loss</td>\n",
       "      <td>0.00</td>\n",
       "      <td>44.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>['combo 5B', 'system_message_risk_json', 'user_message_taskord', 'risk + task order']</td>\n",
       "      <td>gain</td>\n",
       "      <td>10.10</td>\n",
       "      <td>32.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>['combo 5B', 'system_message_risk_json', 'user_message_taskord', 'risk + task order']</td>\n",
       "      <td>loss</td>\n",
       "      <td>36.27</td>\n",
       "      <td>45.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>['combo 6', 'system_message_hum', 'user_message_chain', 'hum + chain']</td>\n",
       "      <td>gain</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>['combo 6', 'system_message_hum', 'user_message_chain', 'hum + chain']</td>\n",
       "      <td>loss</td>\n",
       "      <td>33.33</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>['combo 6B', 'system_message_risk', 'user_message_chain', 'risk + chain']</td>\n",
       "      <td>gain</td>\n",
       "      <td>29.29</td>\n",
       "      <td>36.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>['combo 6B', 'system_message_risk', 'user_message_chain', 'risk + chain']</td>\n",
       "      <td>loss</td>\n",
       "      <td>72.55</td>\n",
       "      <td>69.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>['combo 7', 'system_message_baseline1', 'user_message_noq3', 'hum + simple + noq3']</td>\n",
       "      <td>gain</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>['combo 7', 'system_message_baseline1', 'user_message_noq3', 'hum + simple + noq3']</td>\n",
       "      <td>loss</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                     test  \\\n",
       "0       ['combo 1A', 'system_message_baseline1', 'user_message_baseline1', 'system role']   \n",
       "1       ['combo 1A', 'system_message_baseline1', 'user_message_baseline1', 'system role']   \n",
       "2                    ['combo 2', 'system_message_hum', 'user_message_baseline1', 'human']   \n",
       "3                    ['combo 2', 'system_message_hum', 'user_message_baseline1', 'human']   \n",
       "4             ['combo 3', 'system_message_risk', 'user_message_baseline1', 'risk system']   \n",
       "5             ['combo 3', 'system_message_risk', 'user_message_baseline1', 'risk system']   \n",
       "6           ['combo 3B', 'system_message_risk', 'user_message_risk', 'hum + risk + risk']   \n",
       "7           ['combo 3B', 'system_message_risk', 'user_message_risk', 'hum + risk + risk']   \n",
       "8      ['combo 5', 'system_message_hum_json', 'user_message_taskord', 'hum + task order']   \n",
       "9      ['combo 5', 'system_message_hum_json', 'user_message_taskord', 'hum + task order']   \n",
       "10  ['combo 5B', 'system_message_risk_json', 'user_message_taskord', 'risk + task order']   \n",
       "11  ['combo 5B', 'system_message_risk_json', 'user_message_taskord', 'risk + task order']   \n",
       "12                 ['combo 6', 'system_message_hum', 'user_message_chain', 'hum + chain']   \n",
       "13                 ['combo 6', 'system_message_hum', 'user_message_chain', 'hum + chain']   \n",
       "14              ['combo 6B', 'system_message_risk', 'user_message_chain', 'risk + chain']   \n",
       "15              ['combo 6B', 'system_message_risk', 'user_message_chain', 'risk + chain']   \n",
       "16    ['combo 7', 'system_message_baseline1', 'user_message_noq3', 'hum + simple + noq3']   \n",
       "17    ['combo 7', 'system_message_baseline1', 'user_message_noq3', 'hum + simple + noq3']   \n",
       "\n",
       "   frame  PA_t0_pct  PA_t.7_pct  \n",
       "0   gain      30.30       34.34  \n",
       "1   loss      72.55       64.71  \n",
       "2   gain      30.30       36.36  \n",
       "3   loss      72.55       51.96  \n",
       "4   gain      30.30       35.35  \n",
       "5   loss      72.55       59.80  \n",
       "6   gain      96.97         NaN  \n",
       "7   loss      72.55         NaN  \n",
       "8   gain       4.04       26.26  \n",
       "9   loss       0.00       44.12  \n",
       "10  gain      10.10       32.32  \n",
       "11  loss      36.27       45.10  \n",
       "12  gain       0.00         NaN  \n",
       "13  loss      33.33         NaN  \n",
       "14  gain      29.29       36.36  \n",
       "15  loss      72.55       69.61  \n",
       "16  gain     100.00         NaN  \n",
       "17  loss     100.00         NaN  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Prop A Crosstab\n",
    "df_cross_tab['PA_t0_pct'] = (df_cross_tab['PA_t0'] / (df_cross_tab['PA_t0'] + df_cross_tab['PB_t0']))*100\n",
    "df_cross_tab['PA_t0_pct'] = df_cross_tab['PA_t0_pct'].round(2)\n",
    "##df_cross_tab['PA_t1_pct'] = (df_cross_tab['PA_t1'] / (df_cross_tab['PA_t1'] + df_cross_tab['PB_t1']))\n",
    "##df_cross_tab['PA_t1_pct'] = df_cross_tab['PA_t1_pct'].round(2)\n",
    "df_cross_tab['PA_t.7_pct'] = (df_cross_tab['PA_t.7'] / (df_cross_tab['PA_t.7'] + df_cross_tab['PB_t.7']))*100\n",
    "df_cross_tab['PA_t.7_pct'] = df_cross_tab['PA_t.7_pct'].round(2)\n",
    "###prop_A = df_cross_tab.drop(columns = ['PA_t0','PB_t0', 'PA_t.7', 'PB_t.7', 'PA_t1', 'PB_t1'])\n",
    "prop_A = df_cross_tab.drop(columns = ['PA_t0','PB_t0', 'PA_t.7', 'PB_t.7'])\n",
    "prop_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "temperature\n",
       "0.0    201\n",
       "dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sixb = df_gpt3[df_gpt3['test'] == \"['combo 6', 'system_message_hum', 'user_message_chain', 'hum + chain']\"]\n",
    "\n",
    "sixb.groupby(['temperature']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>temperature</th>\n",
       "      <th colspan=\"2\" halign=\"left\">0.0</th>\n",
       "      <th colspan=\"2\" halign=\"left\">0.7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frame</th>\n",
       "      <th>gain</th>\n",
       "      <th>loss</th>\n",
       "      <th>gain</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>['combo 1A', 'system_message_baseline1', 'user_message_baseline1', 'system role']</th>\n",
       "      <td>4.79</td>\n",
       "      <td>3.10</td>\n",
       "      <td>4.69</td>\n",
       "      <td>3.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['combo 2', 'system_message_hum', 'user_message_baseline1', 'human']</th>\n",
       "      <td>4.79</td>\n",
       "      <td>3.10</td>\n",
       "      <td>4.73</td>\n",
       "      <td>4.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['combo 3', 'system_message_risk', 'user_message_baseline1', 'risk system']</th>\n",
       "      <td>4.79</td>\n",
       "      <td>3.10</td>\n",
       "      <td>4.46</td>\n",
       "      <td>3.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['combo 3B', 'system_message_risk', 'user_message_risk', 'hum + risk + risk']</th>\n",
       "      <td>2.13</td>\n",
       "      <td>3.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['combo 5', 'system_message_hum_json', 'user_message_taskord', 'hum + task order']</th>\n",
       "      <td>6.49</td>\n",
       "      <td>7.00</td>\n",
       "      <td>5.12</td>\n",
       "      <td>4.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['combo 5B', 'system_message_risk_json', 'user_message_taskord', 'risk + task order']</th>\n",
       "      <td>5.53</td>\n",
       "      <td>5.05</td>\n",
       "      <td>4.68</td>\n",
       "      <td>4.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['combo 6', 'system_message_hum', 'user_message_chain', 'hum + chain']</th>\n",
       "      <td>6.08</td>\n",
       "      <td>4.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['combo 6B', 'system_message_risk', 'user_message_chain', 'risk + chain']</th>\n",
       "      <td>4.14</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4.45</td>\n",
       "      <td>3.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['combo 7', 'system_message_baseline1', 'user_message_noq3', 'hum + simple + noq3']</th>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "temperature                                                                             0.0  \\\n",
       "frame                                                                                  gain   \n",
       "test                                                                                          \n",
       "['combo 1A', 'system_message_baseline1', 'user_message_baseline1', 'system role']      4.79   \n",
       "['combo 2', 'system_message_hum', 'user_message_baseline1', 'human']                   4.79   \n",
       "['combo 3', 'system_message_risk', 'user_message_baseline1', 'risk system']            4.79   \n",
       "['combo 3B', 'system_message_risk', 'user_message_risk', 'hum + risk + risk']          2.13   \n",
       "['combo 5', 'system_message_hum_json', 'user_message_taskord', 'hum + task order']     6.49   \n",
       "['combo 5B', 'system_message_risk_json', 'user_message_taskord', 'risk + task order']  5.53   \n",
       "['combo 6', 'system_message_hum', 'user_message_chain', 'hum + chain']                 6.08   \n",
       "['combo 6B', 'system_message_risk', 'user_message_chain', 'risk + chain']              4.14   \n",
       "['combo 7', 'system_message_baseline1', 'user_message_noq3', 'hum + simple + noq3']    2.00   \n",
       "\n",
       "temperature                                                                                  \\\n",
       "frame                                                                                  loss   \n",
       "test                                                                                          \n",
       "['combo 1A', 'system_message_baseline1', 'user_message_baseline1', 'system role']      3.10   \n",
       "['combo 2', 'system_message_hum', 'user_message_baseline1', 'human']                   3.10   \n",
       "['combo 3', 'system_message_risk', 'user_message_baseline1', 'risk system']            3.10   \n",
       "['combo 3B', 'system_message_risk', 'user_message_risk', 'hum + risk + risk']          3.10   \n",
       "['combo 5', 'system_message_hum_json', 'user_message_taskord', 'hum + task order']     7.00   \n",
       "['combo 5B', 'system_message_risk_json', 'user_message_taskord', 'risk + task order']  5.05   \n",
       "['combo 6', 'system_message_hum', 'user_message_chain', 'hum + chain']                 4.70   \n",
       "['combo 6B', 'system_message_risk', 'user_message_chain', 'risk + chain']              3.19   \n",
       "['combo 7', 'system_message_baseline1', 'user_message_noq3', 'hum + simple + noq3']    2.00   \n",
       "\n",
       "temperature                                                                             0.7  \\\n",
       "frame                                                                                  gain   \n",
       "test                                                                                          \n",
       "['combo 1A', 'system_message_baseline1', 'user_message_baseline1', 'system role']      4.69   \n",
       "['combo 2', 'system_message_hum', 'user_message_baseline1', 'human']                   4.73   \n",
       "['combo 3', 'system_message_risk', 'user_message_baseline1', 'risk system']            4.46   \n",
       "['combo 3B', 'system_message_risk', 'user_message_risk', 'hum + risk + risk']           NaN   \n",
       "['combo 5', 'system_message_hum_json', 'user_message_taskord', 'hum + task order']     5.12   \n",
       "['combo 5B', 'system_message_risk_json', 'user_message_taskord', 'risk + task order']  4.68   \n",
       "['combo 6', 'system_message_hum', 'user_message_chain', 'hum + chain']                  NaN   \n",
       "['combo 6B', 'system_message_risk', 'user_message_chain', 'risk + chain']              4.45   \n",
       "['combo 7', 'system_message_baseline1', 'user_message_noq3', 'hum + simple + noq3']     NaN   \n",
       "\n",
       "temperature                                                                                  \n",
       "frame                                                                                  loss  \n",
       "test                                                                                         \n",
       "['combo 1A', 'system_message_baseline1', 'user_message_baseline1', 'system role']      3.72  \n",
       "['combo 2', 'system_message_hum', 'user_message_baseline1', 'human']                   4.16  \n",
       "['combo 3', 'system_message_risk', 'user_message_baseline1', 'risk system']            3.83  \n",
       "['combo 3B', 'system_message_risk', 'user_message_risk', 'hum + risk + risk']           NaN  \n",
       "['combo 5', 'system_message_hum_json', 'user_message_taskord', 'hum + task order']     4.64  \n",
       "['combo 5B', 'system_message_risk_json', 'user_message_taskord', 'risk + task order']  4.39  \n",
       "['combo 6', 'system_message_hum', 'user_message_chain', 'hum + chain']                  NaN  \n",
       "['combo 6B', 'system_message_risk', 'user_message_chain', 'risk + chain']              3.36  \n",
       "['combo 7', 'system_message_baseline1', 'user_message_noq3', 'hum + simple + noq3']     NaN  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Rating Crosstab\n",
    "rating_cross_t0 = pd.crosstab(df_gpt3['test'] ,[df_gpt3['temperature'],df_gpt3['frame']], values = df_gpt3['rating_num'], aggfunc= 'mean')\n",
    "rating_cross_t0.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptive Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "option_selected\n",
      "Proposal A    0.605655\n",
      "Proposal B    0.394345\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "\n",
      "\n",
      "frame  option_selected\n",
      "gain   Proposal B         0.501534\n",
      "       Proposal A         0.498466\n",
      "loss   Proposal A         0.706647\n",
      "       Proposal B         0.293353\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_gpt3['option_selected'].value_counts(normalize=True))\n",
    "print('\\n\\n')\n",
    "print(df_gpt3.groupby('frame')['option_selected'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='rating_num', ylabel='Count'>"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Graphing\n",
    "\n",
    "sns.histplot(df_gpt3['rating_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##histogram of probabilites \n",
    "import seaborn as sns\n",
    "##proba = 1 / (1 + np.exp( - logit_reg_rev.fittedvalues ))\n",
    "sns.histplot(proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- H4: GPT-3.5 Turbo will also exhibit a framing effect, mirroring the tendencies observed in human decision-making.\n",
    "- H5: The scenario will influence the strength of the framing effect in GPT-3.5 Turbo's choices.\n",
    "- H6: The model prompt conditions (risk, system role, and instructions) will moderate the framing effect observed in GPT-3.5 Turbo's choices.\n",
    "- H7: A higher temperature (0.7) will introduce more randomness in GPT-3.5 Turbo's responses, leading to a weaker or less consistent framing effect.\n",
    "- H8: The scenario will have an interaction effect with the frame (gain/loss) on the choices made by the GPT-3.5 Turbo model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stat Tests for Hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H1 & H2: Framing Effect and Preference Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>option selected</th>\n",
       "      <th>rating number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>chi2/stat</th>\n",
       "      <td>163.277173</td>\n",
       "      <td>1163582.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_val</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sig effect</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           option selected rating number\n",
       "chi2/stat       163.277173     1163582.0\n",
       "p_val                  0.0           0.0\n",
       "sig effect            True          True"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###H1: Chi-squared Test (or Fisher's Exact Test) for Option Selected:\n",
    "contingency_table = pd.crosstab(df_gpt3['frame'], df_gpt3['option_selected'])\n",
    "chi2, pval, _, _ = stats.chi2_contingency(contingency_table)\n",
    "\n",
    "###H2: Kruskal-Wallis Test for Rating ##CHECK\n",
    "stat, p_val2 = stats.mannwhitneyu(df_gpt3[df_gpt3['frame']=='gain']['rating_num'], df_gpt3[df_gpt3['frame']=='loss']['rating_num'])\n",
    "\n",
    "\n",
    "###Output as a table\n",
    "results = {\n",
    "    ('option selected'): {\n",
    "        'chi2/stat': chi2,\n",
    "        'p_val': pval,\n",
    "        'sig effect': pval < .05\n",
    "    },\n",
    "    ('rating number'): {\n",
    "        'chi2/stat': stat,\n",
    "        'p_val': p_val2,\n",
    "        'sig effect': p_val2 < .05\n",
    "    }}\n",
    "\n",
    "df_op = pd.DataFrame.from_dict(results)\n",
    "df_op\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H3 - H5: Influence of Prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## ---- Instructions ---- ###############\n",
    "#Instructions (Op Selected)\n",
    "ins_cont_table = pd.crosstab(df_gpt3['instructions'], df_gpt3['option_selected'])\n",
    "chi2_i, pval_i, _, _ = stats.chi2_contingency(ins_cont_table)\n",
    "#Instructions (Rating)\n",
    "stat_i, pval_i2 = stats.kruskal(df_gpt3[df_gpt3['instructions']=='simple']['rating_num'], df_gpt3[df_gpt3['instructions']=='chain']['rating_num'], df_gpt3[df_gpt3['instructions']=='task_order']['rating_num'])\n",
    "\n",
    "############## ---- System Role ---- ###############\n",
    "\n",
    "#Sys Role (Op Selected)\n",
    "sys_cont_table = pd.crosstab(df_gpt3['sys_role'], df_gpt3['option_selected'])\n",
    "chi2_s, pval_s, _, _ = stats.chi2_contingency(ins_cont_table)\n",
    "#Sys Rol (Rating)\n",
    "stat_s, pval_s2= stats.kruskal(df_gpt3[df_gpt3['sys_role']=='neutral']['rating_num'], df_gpt3[df_gpt3['sys_role']=='human']['rating_num'])\n",
    "\n",
    "############## ---- Risk ---- ###############\n",
    "\n",
    "#Risk (Op Selected)\n",
    "risk_cont_table = pd.crosstab(df_gpt3['risk'], df_gpt3['option_selected'])\n",
    "chi2_r, pval_r, _, _ = stats.chi2_contingency(ins_cont_table)\n",
    "#Risk (Rating)\n",
    "stat_r, pval_r2= stats.kruskal(df_gpt3[df_gpt3['risk']=='neutral']['rating_num'], df_gpt3[df_gpt3['risk']=='risk']['rating_num'])\n",
    "\n",
    "############## ---- Temp ---- ###############\n",
    "#Temp (Op Selected)\n",
    "risk_cont_table = pd.crosstab(df_gpt3['temperature'], df_gpt3['option_selected'])\n",
    "chi2_t, pval_t, _, _ = stats.chi2_contingency(ins_cont_table)\n",
    "#Temp (Rating)\n",
    "stat_t, pval_t2= stats.kruskal(df_gpt3[df_gpt3['temperature']==0]['rating_num'], df_gpt3[df_gpt3['temperature']==.7]['rating_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Output as a table\n",
    "dict_instructions = {\n",
    "    ('instructions', 'option selected'): {\n",
    "        'chi2/stat': chi2_i,\n",
    "        'p_val': pval_i,\n",
    "        'sig effect': pval_i < .05\n",
    "    },\n",
    "    ('instructions', 'rating number'): {\n",
    "        'chi2/stat': stat_i,\n",
    "        'p_val': pval_i2,\n",
    "        'sig effect': pval_i2 < .05\n",
    "    }\n",
    "}\n",
    "dict_sys_role = {\n",
    "    ('sys role', 'option selected'): {\n",
    "        'chi2/stat': chi2_s,\n",
    "        'p_val': pval_s,\n",
    "        'sig effect': pval_s < .05\n",
    "    },\n",
    "    ('sys role', 'rating number'): {\n",
    "        'chi2/stat': stat_s,\n",
    "        'p_val': pval_s2,\n",
    "        'sig effect': pval_s2 < .05\n",
    "    }\n",
    "}\n",
    "dict_risk = {\n",
    "    ('risk', 'option selected'): {\n",
    "        'chi2/stat': chi2_r,\n",
    "        'p_val': pval_r,\n",
    "        'sig effect': pval_r < .05\n",
    "    },\n",
    "    ('risk', 'rating number'): {\n",
    "        'chi2/stat': stat_r,\n",
    "        'p_val': pval_r2,\n",
    "        'sig effect': pval_r2 < .05\n",
    "    }\n",
    "}\n",
    "dict_temp = {\n",
    "    ('temp', 'option selected'): {\n",
    "        'chi2/stat': chi2_t,\n",
    "        'p_val': pval_t,\n",
    "        'sig effect': pval_t < .05\n",
    "    },\n",
    "    ('temp', 'rating number'): {\n",
    "        'chi2/stat': stat_t,\n",
    "        'p_val': pval_t2,\n",
    "        'sig effect': pval_t2 < .05,\n",
    "    }\n",
    "}\n",
    "df_instructions = pd.DataFrame(dict_instructions)\n",
    "df_sys_role = pd.DataFrame(dict_sys_role)\n",
    "df_risk = pd.DataFrame(dict_risk)\n",
    "df_temp = pd.DataFrame(dict_temp)\n",
    "test_results_df = pd.concat([df_instructions, df_sys_role, df_risk, df_temp], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Tests for Hypotheses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "##prep variables \n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "\n",
    "##data cleaning & dummy coding \n",
    "df_gpt3_w_dummy = pd.get_dummies(df_gpt3, columns=['test'], prefix='participant_type', drop_first=True)\n",
    "    #participant_type_['combo 2', 'system_message_hum', 'user_message_baseline1', 'human']\t\n",
    "    #participant_type_['combo 3', 'system_message_risk', 'user_message_baseline1', 'risk system']\t   \n",
    "    #participant_type_['combo 5', 'system_message_hum_json', 'user_message_taskord', 'hum + task order']\t\n",
    "    #participant_type_['combo 5B', 'system_message_risk_json', 'user_message_taskord', 'risk + task order']\t\t\n",
    "    #participant_type_['combo 6', 'system_message_1', 'user_message_chain', 'flag for re-run']\t\n",
    "    #participant_type_['combo 6B', 'system_message_risk', 'user_message_chain', 'risk + chain']\n",
    "    \n",
    "##cat code temperature variable \n",
    "\n",
    "##rename variables for \n",
    "df_gpt3_w_dummy= df_gpt3_w_dummy.rename(columns = {\n",
    "    \"participant_type_['combo 2', 'system_message_hum', 'user_message_baseline1', 'human']\":'human', \n",
    "    \"participant_type_['combo 3', 'system_message_risk', 'user_message_baseline1', 'risk system']\": 'hum_risk',\n",
    "    \"participant_type_['combo 5', 'system_message_hum_json', 'user_message_taskord', 'hum + task order']\": 'hum_taskord',\n",
    "    \"participant_type_['combo 5B', 'system_message_risk_json', 'user_message_taskord', 'risk + task order']\": 'hum_risk_taskord',\n",
    "    \"participant_type_['combo 6', 'system_message_1', 'user_message_chain', 'flag for re-run']\": 'hum_chain',\n",
    "    \"participant_type_['combo 6B', 'system_message_risk', 'user_message_chain', 'risk + chain']\": 'hum_risk_chain'\n",
    "    })\n",
    "##dummy_cols = ['human', 'hum_risk', 'hum_taskord', 'hum_risk_taskord', 'hum_chain', 'hum_risk_chain']\n",
    "##df_gpt3_w_dummy[dummy_cols] = df_gpt3_w_dummy[dummy_cols].astype(int)\n",
    "\n",
    "df_gpt3['temp_var'] = df_gpt3.temperature.astype('category').cat.codes ##temp 0 = 0; temp .7 = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: trying URL 'https://cran.r-project.org/bin/macosx/big-sur-arm64/contrib/4.2/stargazer_5.2.3.tgz'\n",
      "\n",
      "R[write to console]: Content type 'application/x-gzip'\n",
      "R[write to console]:  length 616438 bytes (601 KB)\n",
      "\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: downloaded 601 KB\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/vv/15vmsdzj0d9c0x2z42fx60fr0000gn/T//RtmplKPxdU/downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: \n",
      "Please cite as: \n",
      "\n",
      "\n",
      "R[write to console]:  Hlavac, Marek (2022). stargazer: Well-Formatted Regression and Summary Statistics Tables.\n",
      "\n",
      "R[write to console]:  R package version 5.2.3. https://CRAN.R-project.org/package=stargazer \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <span>StrVector with 9 elements.</span>\n",
       "        <table>\n",
       "        <tbody>\n",
       "          <tr>\n",
       "          \n",
       "            <td>\n",
       "            'stargazer'\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            'tools'\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            'stats'\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            ...\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            'datasets'\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            'methods'\n",
       "            </td>\n",
       "          \n",
       "            <td>\n",
       "            'base'\n",
       "            </td>\n",
       "          \n",
       "          </tr>\n",
       "        </tbody>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<rpy2.robjects.vectors.StrVector object at 0x16c712200> [RTYPES.STRSXP]\n",
       "R classes: ('character',)\n",
       "['stargazer', 'tools', 'stats', 'graphics', ..., 'utils', 'datasets', 'methods', 'base']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Error in if (is.na(s)) { : the condition has length > 1\n",
      "\n"
     ]
    },
    {
     "ename": "RRuntimeError",
     "evalue": "Error in if (is.na(s)) { : the condition has length > 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRRuntimeError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m formula \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39moption_selected_cat ~ frame_cat\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     24\u001b[0m model \u001b[39m=\u001b[39m R\u001b[39m.\u001b[39mglm(formula, data\u001b[39m=\u001b[39mdf_gpt3, family\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbinomial\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m summary_output \u001b[39m=\u001b[39m robjects\u001b[39m.\u001b[39;49mr(\u001b[39m'\u001b[39;49m\u001b[39mstargazer\u001b[39;49m\u001b[39m'\u001b[39;49m)(model, \u001b[39mtype\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     26\u001b[0m \u001b[39mprint\u001b[39m(summary_output[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/rpy2/robjects/functions.py:203\u001b[0m, in \u001b[0;36mSignatureTranslatedFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m         v \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(k)\n\u001b[1;32m    202\u001b[0m         kwargs[r_k] \u001b[39m=\u001b[39m v\n\u001b[0;32m--> 203\u001b[0m \u001b[39mreturn\u001b[39;00m (\u001b[39msuper\u001b[39;49m(SignatureTranslatedFunction, \u001b[39mself\u001b[39;49m)\n\u001b[1;32m    204\u001b[0m         \u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/rpy2/robjects/functions.py:126\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m         new_kwargs[k] \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39mpy2rpy(v)\n\u001b[0;32m--> 126\u001b[0m res \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Function, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49mnew_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnew_kwargs)\n\u001b[1;32m    127\u001b[0m res \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39mrpy2py(res)\n\u001b[1;32m    128\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/rpy2/rinterface_lib/conversion.py:45\u001b[0m, in \u001b[0;36m_cdata_res_to_rinterface.<locals>._\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 45\u001b[0m     cdata \u001b[39m=\u001b[39m function(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     46\u001b[0m     \u001b[39m# TODO: test cdata is of the expected CType\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     \u001b[39mreturn\u001b[39;00m _cdata_to_rinterface(cdata)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/rpy2/rinterface.py:815\u001b[0m, in \u001b[0;36mSexpClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    808\u001b[0m     res \u001b[39m=\u001b[39m rmemory\u001b[39m.\u001b[39mprotect(\n\u001b[1;32m    809\u001b[0m         openrlib\u001b[39m.\u001b[39mrlib\u001b[39m.\u001b[39mR_tryEval(\n\u001b[1;32m    810\u001b[0m             call_r,\n\u001b[1;32m    811\u001b[0m             call_context\u001b[39m.\u001b[39m__sexp__\u001b[39m.\u001b[39m_cdata,\n\u001b[1;32m    812\u001b[0m             error_occured)\n\u001b[1;32m    813\u001b[0m     )\n\u001b[1;32m    814\u001b[0m     \u001b[39mif\u001b[39;00m error_occured[\u001b[39m0\u001b[39m]:\n\u001b[0;32m--> 815\u001b[0m         \u001b[39mraise\u001b[39;00m embedded\u001b[39m.\u001b[39mRRuntimeError(_rinterface\u001b[39m.\u001b[39m_geterrmessage())\n\u001b[1;32m    816\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "\u001b[0;31mRRuntimeError\u001b[0m: Error in if (is.na(s)) { : the condition has length > 1\n"
     ]
    }
   ],
   "source": [
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "\n",
    "### R Packages\n",
    "##R = robjects.r\n",
    "##robjects.r('options(repos = c(CRAN=\"https://cran.r-project.org/\"))')\n",
    "##robjects.r('install.packages(\"ggplot2\")')\n",
    "##robjects.r('install.packages(\"glm\")')\n",
    "##R('library(glm)')\n",
    "#robjects.r('install.packages(\"broom\", repos=\"https://cran.r-project.org/\")')\n",
    "#robjects.r('library(broom)')\n",
    "##robjects.r('install.packages(\"stargazer\", repos=\"https://cran.r-project.org/\")')\n",
    "##robjects.r('library(stargazer)')\n",
    "\n",
    "\n",
    "\n",
    "R = robjects.r\n",
    "\n",
    "df_gpt3_r = pandas2ri.py2rpy(df_gpt3)\n",
    "\n",
    "\n",
    "formula = 'option_selected_cat ~ frame_cat'\n",
    "model = R.glm(formula, data=df_gpt3, family=\"binomial\")\n",
    "summary_output = robjects.r('stargazer')(model, type=\"text\")\n",
    "print(summary_output[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_['combo 2', 'system_message_hum', 'user_message_baseline1', 'human']\n",
      "df_['combo 3', 'system_message_risk', 'user_message_baseline1', 'risk system']\n",
      "df_['combo 6B', 'system_message_risk', 'user_message_chain', 'risk + chain']\n",
      "df_['combo 5', 'system_message_hum_json', 'user_message_taskord', 'hum + task order']\n",
      "df_['combo 1A', 'system_message_baseline1', 'user_message_baseline1', 'system role']\n",
      "df_['combo 5B', 'system_message_risk_json', 'user_message_taskord', 'risk + task order']\n",
      "df_['combo 6', 'system_message_hum', 'user_message_chain', 'hum + chain']\n"
     ]
    }
   ],
   "source": [
    "##sep conditions for gain and loss \n",
    "gain_cond = df_gpt3[df_gpt3['frame'] == 'gain']\n",
    "loss_cond = df_gpt3[df_gpt3['frame'] == 'loss']\n",
    "##crete df for each test \n",
    "tests = {f'df_{test}': df_gpt3[df_gpt3['test'] == test] for test in df_gpt3['test'].unique()}\n",
    "for key in tests.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logit Regression (Hyp 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis 1.1: All AI models will exhibit the framing effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.635516\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:      option_selected_A   No. Observations:                 2814\n",
      "Model:                          Logit   Df Residuals:                     2812\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Mon, 14 Aug 2023   Pseudo R-squ.:                 0.05539\n",
      "Time:                        18:31:56   Log-Likelihood:                -1788.3\n",
      "converged:                       True   LL-Null:                       -1893.2\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.579e-47\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.1206      0.053      2.274      0.023       0.017       0.225\n",
      "frame_gain    -1.1418      0.081    -14.143      0.000      -1.300      -0.984\n",
      "==============================================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.567079\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:      option_selected_A   No. Observations:                 2814\n",
      "Model:                          Logit   Df Residuals:                     2810\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Mon, 14 Aug 2023   Pseudo R-squ.:                  0.1571\n",
      "Time:                        18:31:56   Log-Likelihood:                -1595.8\n",
      "converged:                       True   LL-Null:                       -1893.2\n",
      "Covariance Type:            nonrobust   LLR p-value:                1.292e-128\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                 0.0160      0.077      0.208      0.835      -0.134       0.166\n",
      "C(scenario)[T.forest]    -1.0006      0.113     -8.840      0.000      -1.222      -0.779\n",
      "C(scenario)[T.human]      1.0786      0.098     10.966      0.000       0.886       1.271\n",
      "frame_gain               -1.1756      0.087    -13.455      0.000      -1.347      -1.004\n",
      "=========================================================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.631139\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:      option_selected_A   No. Observations:                 2814\n",
      "Model:                          Logit   Df Residuals:                     2811\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Mon, 14 Aug 2023   Pseudo R-squ.:                 0.06189\n",
      "Time:                        18:31:56   Log-Likelihood:                -1776.0\n",
      "converged:                       True   LL-Null:                       -1893.2\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.289e-51\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                -0.0773      0.066     -1.163      0.245      -0.208       0.053\n",
      "C(temperature)[T.0.7]     0.3982      0.080      4.947      0.000       0.240       0.556\n",
      "frame_gain               -1.1523      0.081    -14.193      0.000      -1.311      -0.993\n",
      "=========================================================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.605534\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:      option_selected_A   No. Observations:                 2412\n",
      "Model:                          Logit   Df Residuals:                     2406\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Mon, 14 Aug 2023   Pseudo R-squ.:                  0.1088\n",
      "Time:                        18:31:57   Log-Likelihood:                -1460.5\n",
      "converged:                       True   LL-Null:                       -1638.9\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.408e-75\n",
      "=================================================================================================\n",
      "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Intercept                         0.3845      0.102      3.773      0.000       0.185       0.584\n",
      "C(instructions)[T.chain]         -0.0287      0.140     -0.205      0.837      -0.303       0.245\n",
      "C(instructions)[T.task_order]    -1.1594      0.113    -10.228      0.000      -1.382      -0.937\n",
      "C(risk)[T.risk]                   0.3534      0.112      3.163      0.002       0.134       0.572\n",
      "C(sys_role)[T.neutral_system]     0.2590      0.140      1.851      0.064      -0.015       0.533\n",
      "frame_gain                       -1.2411      0.090    -13.714      0.000      -1.418      -1.064\n",
      "=================================================================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.562212\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:      option_selected_A   No. Observations:                 2814\n",
      "Model:                          Logit   Df Residuals:                     2809\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Mon, 14 Aug 2023   Pseudo R-squ.:                  0.1643\n",
      "Time:                        18:31:57   Log-Likelihood:                -1582.1\n",
      "converged:                       True   LL-Null:                       -1893.2\n",
      "Covariance Type:            nonrobust   LLR p-value:                2.335e-133\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                -0.2084      0.088     -2.358      0.018      -0.382      -0.035\n",
      "C(scenario)[T.forest]    -1.0119      0.114     -8.892      0.000      -1.235      -0.789\n",
      "C(scenario)[T.human]      1.0869      0.099     10.983      0.000       0.893       1.281\n",
      "C(temperature)[T.0.7]     0.4519      0.087      5.209      0.000       0.282       0.622\n",
      "frame_gain               -1.1882      0.088    -13.511      0.000      -1.361      -1.016\n",
      "=========================================================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.518969\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:      option_selected_A   No. Observations:                 2814\n",
      "Model:                          Logit   Df Residuals:                     2803\n",
      "Method:                           MLE   Df Model:                           10\n",
      "Date:                Mon, 14 Aug 2023   Pseudo R-squ.:                  0.2286\n",
      "Time:                        18:31:57   Log-Likelihood:                -1460.4\n",
      "converged:                       True   LL-Null:                       -1893.2\n",
      "Covariance Type:            nonrobust   LLR p-value:                1.568e-179\n",
      "====================================================================================================================================================================\n",
      "                                                                                                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                                                                            0.3694      0.141      2.620      0.009       0.093       0.646\n",
      "C(scenario)[T.forest]                                                                               -1.0936      0.119     -9.203      0.000      -1.326      -0.861\n",
      "C(scenario)[T.human]                                                                                 1.2229      0.106     11.586      0.000       1.016       1.430\n",
      "C(temperature)[T.0.7]                                                                                0.4976      0.091      5.458      0.000       0.319       0.676\n",
      "C(test)[T.['combo 2', 'system_message_hum', 'user_message_baseline1', 'human']]                     -0.1447      0.162     -0.892      0.372      -0.463       0.173\n",
      "C(test)[T.['combo 3', 'system_message_risk', 'user_message_baseline1', 'risk system']]              -0.0526      0.162     -0.324      0.746      -0.371       0.265\n",
      "C(test)[T.['combo 5', 'system_message_hum_json', 'user_message_taskord', 'hum + task order']]       -1.9301      0.185    -10.452      0.000      -2.292      -1.568\n",
      "C(test)[T.['combo 5B', 'system_message_risk_json', 'user_message_taskord', 'risk + task order']]    -1.1106      0.169     -6.573      0.000      -1.442      -0.779\n",
      "C(test)[T.['combo 6', 'system_message_hum', 'user_message_chain', 'hum + chain']]                   -1.2004      0.170     -7.051      0.000      -1.534      -0.867\n",
      "C(test)[T.['combo 6B', 'system_message_risk', 'user_message_chain', 'risk + chain']]                 0.0790      0.162      0.487      0.626      -0.239       0.397\n",
      "frame_gain                                                                                          -1.3079      0.093    -14.016      0.000      -1.491      -1.125\n",
      "====================================================================================================================================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.519981\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:      option_selected_A   No. Observations:                 2412\n",
      "Model:                          Logit   Df Residuals:                     2403\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Mon, 14 Aug 2023   Pseudo R-squ.:                  0.2347\n",
      "Time:                        18:31:57   Log-Likelihood:                -1254.2\n",
      "converged:                       True   LL-Null:                       -1638.9\n",
      "Covariance Type:            nonrobust   LLR p-value:                8.164e-161\n",
      "=================================================================================================\n",
      "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Intercept                         0.2159      0.134      1.608      0.108      -0.047       0.479\n",
      "C(scenario)[T.forest]            -1.2797      0.128     -9.981      0.000      -1.531      -1.028\n",
      "C(scenario)[T.human]              1.1659      0.114     10.253      0.000       0.943       1.389\n",
      "C(temperature)[T.0.7]             0.3472      0.098      3.540      0.000       0.155       0.539\n",
      "C(instructions)[T.chain]         -0.0264      0.154     -0.171      0.864      -0.329       0.276\n",
      "C(instructions)[T.task_order]    -1.4106      0.126    -11.176      0.000      -1.658      -1.163\n",
      "C(risk)[T.risk]                   0.4134      0.122      3.377      0.001       0.173       0.653\n",
      "C(sys_role)[T.neutral_system]     0.3069      0.154      1.988      0.047       0.004       0.609\n",
      "frame_gain                       -1.3260      0.101    -13.182      0.000      -1.523      -1.129\n",
      "=================================================================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.527616\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:      option_selected_A   No. Observations:                 2814\n",
      "Model:                          Logit   Df Residuals:                     2808\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Mon, 14 Aug 2023   Pseudo R-squ.:                  0.2158\n",
      "Time:                        18:31:57   Log-Likelihood:                -1484.7\n",
      "converged:                       True   LL-Null:                       -1893.2\n",
      "Covariance Type:            nonrobust   LLR p-value:                2.447e-174\n",
      "====================================================================================================\n",
      "                                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Intercept                            0.6555      0.093      7.056      0.000       0.473       0.838\n",
      "C(scenario)[T.forest]               -2.1612      0.161    -13.444      0.000      -2.476      -1.846\n",
      "C(scenario)[T.human]                 0.0290      0.131      0.221      0.825      -0.228       0.286\n",
      "frame_gain                          -3.2412      0.203    -15.965      0.000      -3.639      -2.843\n",
      "frame_gain:C(scenario)[T.forest]     3.1998      0.269     11.881      0.000       2.672       3.728\n",
      "frame_gain:C(scenario)[T.human]      2.8940      0.244     11.865      0.000       2.416       3.372\n",
      "====================================================================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.518756\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:      option_selected_A   No. Observations:                 2814\n",
      "Model:                          Logit   Df Residuals:                     2806\n",
      "Method:                           MLE   Df Model:                            7\n",
      "Date:                Mon, 14 Aug 2023   Pseudo R-squ.:                  0.2289\n",
      "Time:                        18:31:57   Log-Likelihood:                -1459.8\n",
      "converged:                       True   LL-Null:                       -1893.2\n",
      "Covariance Type:            nonrobust   LLR p-value:                6.909e-183\n",
      "====================================================================================================\n",
      "                                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Intercept                            0.5794      0.109      5.313      0.000       0.366       0.793\n",
      "C(scenario)[T.forest]               -2.1643      0.161    -13.451      0.000      -2.480      -1.849\n",
      "C(scenario)[T.human]                 0.0280      0.131      0.213      0.831      -0.229       0.285\n",
      "C(temperature)[T.0.7]                0.1551      0.118      1.320      0.187      -0.075       0.385\n",
      "frame_gain                          -3.7617      0.236    -15.956      0.000      -4.224      -3.300\n",
      "frame_gain:C(scenario)[T.forest]     3.2219      0.271     11.879      0.000       2.690       3.753\n",
      "frame_gain:C(scenario)[T.human]      3.0089      0.249     12.104      0.000       2.522       3.496\n",
      "frame_gain:C(temperature)[T.0.7]     0.8405      0.189      4.457      0.000       0.471       1.210\n",
      "====================================================================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.518756\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:      option_selected_A   No. Observations:                 2814\n",
      "Model:                          Logit   Df Residuals:                     2806\n",
      "Method:                           MLE   Df Model:                            7\n",
      "Date:                Mon, 14 Aug 2023   Pseudo R-squ.:                  0.2289\n",
      "Time:                        18:31:57   Log-Likelihood:                -1459.8\n",
      "converged:                       True   LL-Null:                       -1893.2\n",
      "Covariance Type:            nonrobust   LLR p-value:                6.909e-183\n",
      "====================================================================================================\n",
      "                                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Intercept                            0.5794      0.109      5.313      0.000       0.366       0.793\n",
      "C(scenario)[T.forest]               -2.1643      0.161    -13.451      0.000      -2.480      -1.849\n",
      "C(scenario)[T.human]                 0.0280      0.131      0.213      0.831      -0.229       0.285\n",
      "C(temperature)[T.0.7]                0.1551      0.118      1.320      0.187      -0.075       0.385\n",
      "frame_gain                          -3.7617      0.236    -15.956      0.000      -4.224      -3.300\n",
      "frame_gain:C(scenario)[T.forest]     3.2219      0.271     11.879      0.000       2.690       3.753\n",
      "frame_gain:C(scenario)[T.human]      3.0089      0.249     12.104      0.000       2.522       3.496\n",
      "frame_gain:C(temperature)[T.0.7]     0.8405      0.189      4.457      0.000       0.471       1.210\n",
      "====================================================================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.602097\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:      option_selected_A   No. Observations:                 2412\n",
      "Model:                          Logit   Df Residuals:                     2402\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Mon, 14 Aug 2023   Pseudo R-squ.:                  0.1139\n",
      "Time:                        18:31:57   Log-Likelihood:                -1452.3\n",
      "converged:                       True   LL-Null:                       -1638.9\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.917e-75\n",
      "============================================================================================================\n",
      "                                               coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                    0.3389      0.125      2.708      0.007       0.094       0.584\n",
      "C(instructions)[T.chain]                     0.0500      0.203      0.247      0.805      -0.348       0.448\n",
      "C(instructions)[T.task_order]               -1.3890      0.150     -9.254      0.000      -1.683      -1.095\n",
      "C(sys_role)[T.neutral_system]                0.4439      0.196      2.264      0.024       0.060       0.828\n",
      "C(risk)[T.risk]                              0.5103      0.150      3.401      0.001       0.216       0.804\n",
      "frame_gain                                  -1.1195      0.185     -6.047      0.000      -1.482      -0.757\n",
      "frame_gain:C(instructions)[T.chain]         -0.1356      0.286     -0.474      0.636      -0.697       0.426\n",
      "frame_gain:C(instructions)[T.task_order]     0.5886      0.226      2.608      0.009       0.146       1.031\n",
      "frame_gain:C(sys_role)[T.neutral_system]    -0.4022      0.283     -1.421      0.155      -0.957       0.153\n",
      "frame_gain:C(risk)[T.risk]                  -0.3600      0.223     -1.612      0.107      -0.798       0.078\n",
      "============================================================================================================\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.589170\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annaking/Library/Python/3.9/lib/python/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>option_selected_A</td> <th>  No. Observations:  </th>  <td>  2814</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>       <th>  Df Residuals:      </th>  <td>  2797</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>        <th>  Df Model:          </th>  <td>    16</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 14 Aug 2023</td>  <th>  Pseudo R-squ.:     </th>  <td>0.1243</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>18:31:58</td>      <th>  Log-Likelihood:    </th> <td> -1657.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>False</td>       <th>  LL-Null:           </th> <td> -1893.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>     <th>  LLR p-value:       </th> <td>5.387e-90</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                                                      <td></td>                                                        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                                                                                <td>   -0.1499</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>test[T.['combo 2', 'system_message_hum', 'user_message_baseline1', 'human']]</th>                             <td>   -0.2827</td> <td>    0.209</td> <td>   -1.353</td> <td> 0.176</td> <td>   -0.692</td> <td>    0.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>test[T.['combo 3', 'system_message_risk', 'user_message_baseline1', 'risk system']]</th>                      <td>   -0.1117</td> <td>    0.211</td> <td>   -0.528</td> <td> 0.597</td> <td>   -0.526</td> <td>    0.303</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>test[T.['combo 5', 'system_message_hum_json', 'user_message_taskord', 'hum + task order']]</th>               <td>   -2.0475</td> <td>    0.227</td> <td>   -9.036</td> <td> 0.000</td> <td>   -2.492</td> <td>   -1.603</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>test[T.['combo 5B', 'system_message_risk_json', 'user_message_taskord', 'risk + task order']]</th>            <td>   -1.1612</td> <td>    0.208</td> <td>   -5.591</td> <td> 0.000</td> <td>   -1.568</td> <td>   -0.754</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>test[T.['combo 6', 'system_message_hum', 'user_message_chain', 'hum + chain']]</th>                           <td>   -1.1816</td> <td>    0.208</td> <td>   -5.684</td> <td> 0.000</td> <td>   -1.589</td> <td>   -0.774</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>test[T.['combo 6B', 'system_message_risk', 'user_message_chain', 'risk + chain']]</th>                        <td>    0.1166</td> <td>    0.216</td> <td>    0.540</td> <td> 0.589</td> <td>   -0.307</td> <td>    0.540</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>frame[T.loss]</th>                                                                                            <td>    0.8601</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>frame_gain</th>                                                                                               <td>   -1.0104</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>frame_gain:test[T.['combo 2', 'system_message_hum', 'user_message_baseline1', 'human']]</th>                  <td>    0.3301</td> <td>    0.302</td> <td>    1.094</td> <td> 0.274</td> <td>   -0.261</td> <td>    0.922</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>frame_gain:test[T.['combo 3', 'system_message_risk', 'user_message_baseline1', 'risk system']]</th>           <td>    0.1355</td> <td>    0.304</td> <td>    0.446</td> <td> 0.656</td> <td>   -0.460</td> <td>    0.731</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>frame_gain:test[T.['combo 5', 'system_message_hum_json', 'user_message_taskord', 'hum + task order']]</th>    <td>    1.0376</td> <td>    0.340</td> <td>    3.056</td> <td> 0.002</td> <td>    0.372</td> <td>    1.703</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>frame_gain:test[T.['combo 5B', 'system_message_risk_json', 'user_message_taskord', 'risk + task order']]</th> <td>    0.5710</td> <td>    0.313</td> <td>    1.824</td> <td> 0.068</td> <td>   -0.043</td> <td>    1.185</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>frame_gain:test[T.['combo 6', 'system_message_hum', 'user_message_chain', 'hum + chain']]</th>                <td>    0.3598</td> <td>    0.320</td> <td>    1.123</td> <td> 0.261</td> <td>   -0.268</td> <td>    0.988</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>frame_gain:test[T.['combo 6B', 'system_message_risk', 'user_message_chain', 'risk + chain']]</th>             <td>   -0.0928</td> <td>    0.307</td> <td>   -0.302</td> <td> 0.762</td> <td>   -0.694</td> <td>    0.509</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>temperature</th>                                                                                              <td>    1.1248</td> <td>    0.182</td> <td>    6.173</td> <td> 0.000</td> <td>    0.768</td> <td>    1.482</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>frame[T.loss]:temperature</th>                                                                                <td>   -0.9146</td> <td>    0.244</td> <td>   -3.754</td> <td> 0.000</td> <td>   -1.392</td> <td>   -0.437</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                                                                                                 & option\\_selected\\_A & \\textbf{  No. Observations:  } &     2814    \\\\\n",
       "\\textbf{Model:}                                                                                                         &        Logit        & \\textbf{  Df Residuals:      } &     2797    \\\\\n",
       "\\textbf{Method:}                                                                                                        &         MLE         & \\textbf{  Df Model:          } &       16    \\\\\n",
       "\\textbf{Date:}                                                                                                          &   Mon, 14 Aug 2023  & \\textbf{  Pseudo R-squ.:     } &   0.1243    \\\\\n",
       "\\textbf{Time:}                                                                                                          &       18:31:58      & \\textbf{  Log-Likelihood:    } &   -1657.9   \\\\\n",
       "\\textbf{converged:}                                                                                                     &        False        & \\textbf{  LL-Null:           } &   -1893.2   \\\\\n",
       "\\textbf{Covariance Type:}                                                                                               &      nonrobust      & \\textbf{  LLR p-value:       } & 5.387e-90   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                                                                                        & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                                                                                                      &      -0.1499  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{test[T.['combo 2', 'system\\_message\\_hum', 'user\\_message\\_baseline1', 'human']]}                               &      -0.2827  &        0.209     &    -1.353  &         0.176        &       -0.692    &        0.127     \\\\\n",
       "\\textbf{test[T.['combo 3', 'system\\_message\\_risk', 'user\\_message\\_baseline1', 'risk system']]}                        &      -0.1117  &        0.211     &    -0.528  &         0.597        &       -0.526    &        0.303     \\\\\n",
       "\\textbf{test[T.['combo 5', 'system\\_message\\_hum\\_json', 'user\\_message\\_taskord', 'hum + task order']]}                &      -2.0475  &        0.227     &    -9.036  &         0.000        &       -2.492    &       -1.603     \\\\\n",
       "\\textbf{test[T.['combo 5B', 'system\\_message\\_risk\\_json', 'user\\_message\\_taskord', 'risk + task order']]}             &      -1.1612  &        0.208     &    -5.591  &         0.000        &       -1.568    &       -0.754     \\\\\n",
       "\\textbf{test[T.['combo 6', 'system\\_message\\_hum', 'user\\_message\\_chain', 'hum + chain']]}                             &      -1.1816  &        0.208     &    -5.684  &         0.000        &       -1.589    &       -0.774     \\\\\n",
       "\\textbf{test[T.['combo 6B', 'system\\_message\\_risk', 'user\\_message\\_chain', 'risk + chain']]}                          &       0.1166  &        0.216     &     0.540  &         0.589        &       -0.307    &        0.540     \\\\\n",
       "\\textbf{frame[T.loss]}                                                                                                  &       0.8601  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{frame\\_gain}                                                                                                    &      -1.0104  &          nan     &       nan  &           nan        &          nan    &          nan     \\\\\n",
       "\\textbf{frame\\_gain:test[T.['combo 2', 'system\\_message\\_hum', 'user\\_message\\_baseline1', 'human']]}                   &       0.3301  &        0.302     &     1.094  &         0.274        &       -0.261    &        0.922     \\\\\n",
       "\\textbf{frame\\_gain:test[T.['combo 3', 'system\\_message\\_risk', 'user\\_message\\_baseline1', 'risk system']]}            &       0.1355  &        0.304     &     0.446  &         0.656        &       -0.460    &        0.731     \\\\\n",
       "\\textbf{frame\\_gain:test[T.['combo 5', 'system\\_message\\_hum\\_json', 'user\\_message\\_taskord', 'hum + task order']]}    &       1.0376  &        0.340     &     3.056  &         0.002        &        0.372    &        1.703     \\\\\n",
       "\\textbf{frame\\_gain:test[T.['combo 5B', 'system\\_message\\_risk\\_json', 'user\\_message\\_taskord', 'risk + task order']]} &       0.5710  &        0.313     &     1.824  &         0.068        &       -0.043    &        1.185     \\\\\n",
       "\\textbf{frame\\_gain:test[T.['combo 6', 'system\\_message\\_hum', 'user\\_message\\_chain', 'hum + chain']]}                 &       0.3598  &        0.320     &     1.123  &         0.261        &       -0.268    &        0.988     \\\\\n",
       "\\textbf{frame\\_gain:test[T.['combo 6B', 'system\\_message\\_risk', 'user\\_message\\_chain', 'risk + chain']]}              &      -0.0928  &        0.307     &    -0.302  &         0.762        &       -0.694    &        0.509     \\\\\n",
       "\\textbf{temperature}                                                                                                    &       1.1248  &        0.182     &     6.173  &         0.000        &        0.768    &        1.482     \\\\\n",
       "\\textbf{frame[T.loss]:temperature}                                                                                      &      -0.9146  &        0.244     &    -3.754  &         0.000        &       -1.392    &       -0.437     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:      option_selected_A   No. Observations:                 2814\n",
       "Model:                          Logit   Df Residuals:                     2797\n",
       "Method:                           MLE   Df Model:                           16\n",
       "Date:                Mon, 14 Aug 2023   Pseudo R-squ.:                  0.1243\n",
       "Time:                        18:31:58   Log-Likelihood:                -1657.9\n",
       "converged:                      False   LL-Null:                       -1893.2\n",
       "Covariance Type:            nonrobust   LLR p-value:                 5.387e-90\n",
       "============================================================================================================================================================================\n",
       "                                                                                                               coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                                                                                   -0.1499        nan        nan        nan         nan         nan\n",
       "test[T.['combo 2', 'system_message_hum', 'user_message_baseline1', 'human']]                                -0.2827      0.209     -1.353      0.176      -0.692       0.127\n",
       "test[T.['combo 3', 'system_message_risk', 'user_message_baseline1', 'risk system']]                         -0.1117      0.211     -0.528      0.597      -0.526       0.303\n",
       "test[T.['combo 5', 'system_message_hum_json', 'user_message_taskord', 'hum + task order']]                  -2.0475      0.227     -9.036      0.000      -2.492      -1.603\n",
       "test[T.['combo 5B', 'system_message_risk_json', 'user_message_taskord', 'risk + task order']]               -1.1612      0.208     -5.591      0.000      -1.568      -0.754\n",
       "test[T.['combo 6', 'system_message_hum', 'user_message_chain', 'hum + chain']]                              -1.1816      0.208     -5.684      0.000      -1.589      -0.774\n",
       "test[T.['combo 6B', 'system_message_risk', 'user_message_chain', 'risk + chain']]                            0.1166      0.216      0.540      0.589      -0.307       0.540\n",
       "frame[T.loss]                                                                                                0.8601        nan        nan        nan         nan         nan\n",
       "frame_gain                                                                                                  -1.0104        nan        nan        nan         nan         nan\n",
       "frame_gain:test[T.['combo 2', 'system_message_hum', 'user_message_baseline1', 'human']]                      0.3301      0.302      1.094      0.274      -0.261       0.922\n",
       "frame_gain:test[T.['combo 3', 'system_message_risk', 'user_message_baseline1', 'risk system']]               0.1355      0.304      0.446      0.656      -0.460       0.731\n",
       "frame_gain:test[T.['combo 5', 'system_message_hum_json', 'user_message_taskord', 'hum + task order']]        1.0376      0.340      3.056      0.002       0.372       1.703\n",
       "frame_gain:test[T.['combo 5B', 'system_message_risk_json', 'user_message_taskord', 'risk + task order']]     0.5710      0.313      1.824      0.068      -0.043       1.185\n",
       "frame_gain:test[T.['combo 6', 'system_message_hum', 'user_message_chain', 'hum + chain']]                    0.3598      0.320      1.123      0.261      -0.268       0.988\n",
       "frame_gain:test[T.['combo 6B', 'system_message_risk', 'user_message_chain', 'risk + chain']]                -0.0928      0.307     -0.302      0.762      -0.694       0.509\n",
       "temperature                                                                                                  1.1248      0.182      6.173      0.000       0.768       1.482\n",
       "frame[T.loss]:temperature                                                                                   -0.9146      0.244     -3.754      0.000      -1.392      -0.437\n",
       "============================================================================================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####Simple Regression Model \n",
    "##frame_gain: 0 = loss, 1 = gain\n",
    "##frame_cat: 0 = gain, 1 = loss\n",
    "#option_selected_rev: 0 = B; 1 = A\n",
    "#option_selected_cat: 0 = A; 1 = B\n",
    "\n",
    "\n",
    "#Simple\n",
    "logit_reg = smf.logit('option_selected_A ~ frame_gain', df_gpt3).fit()\n",
    "print(logit_reg.summary())\n",
    "# the likelihood (in log-odds) of choosing option A decreases compared to the loss frame.\n",
    "\n",
    "##Scenario  \n",
    "logit_reg_scn = smf.logit('option_selected_A ~ frame_gain + C(scenario)', df_gpt3).fit()\n",
    "print(logit_reg_scn.summary())\n",
    "\n",
    "## Temp \n",
    "logit_reg_temp = smf.logit('option_selected_A ~ frame_gain + C(temperature)', df_gpt3).fit()\n",
    "print(logit_reg_temp.summary())\n",
    "\n",
    "## Model Variables \n",
    "logit_reg_var= smf.logit('option_selected_A ~ frame_gain + C(instructions) + C(risk) + C(sys_role)', df_gpt3).fit()\n",
    "print(logit_reg_var.summary())\n",
    "\n",
    "##Scenario + Temp\n",
    "logit_reg_scn_temp = smf.logit('option_selected_A ~ frame_gain + C(scenario) + C(temperature)', df_gpt3).fit()\n",
    "print(logit_reg_scn_temp.summary())\n",
    "\n",
    "##Scenario + Temp + Test\n",
    "logit_reg_scn_temp_test = smf.logit('option_selected_A ~ frame_gain + C(scenario) + C(temperature) + C(test)', df_gpt3).fit()\n",
    "print(logit_reg_scn_temp_test.summary())\n",
    "\n",
    "##Scenario + Temp + Model Variables \n",
    "logit_reg_scn_temp_test_var = smf.logit('option_selected_A ~ frame_gain + C(scenario) + C(temperature) + C(instructions) + C(risk) + C(sys_role)', df_gpt3).fit()\n",
    "print(logit_reg_scn_temp_test_var.summary())\n",
    "\n",
    "#### Interaction \n",
    "#Scenario  \n",
    "logit_int_scn = smf.logit('option_selected_A ~ frame_gain * C(scenario) + frame_gain', df_gpt3).fit()\n",
    "print(logit_int_scn.summary())\n",
    "\n",
    "##Scenario + Temp\n",
    "logit_int_scn_temp = smf.logit('option_selected_A ~ frame_gain * C(scenario) + frame_gain *  C(temperature) + frame_gain', df_gpt3).fit()\n",
    "print(logit_int_scn_temp.summary())\n",
    "\n",
    "##Scenario + Temp + Test\n",
    "logit_int_scn_temp_test = smf.logit('option_selected_A ~ frame_gain  * C(scenario) + frame_gain *  C(temperature) + frame_gain ', df_gpt3).fit()\n",
    "print(logit_int_scn_temp_test.summary())\n",
    "\n",
    "##Model Variables \n",
    "logit_int_scn_temp_test = smf.logit('option_selected_A ~ frame_gain  * C(instructions) + frame_gain *  C(sys_role) + frame_gain *  C(risk) + frame_gain ', df_gpt3).fit()\n",
    "print(logit_int_scn_temp_test.summary())\n",
    "\n",
    "##add in interaction term for temp & model \n",
    "\n",
    "logit_reg_temptest = smf.logit('option_selected_A ~ frame_gain * test + frame * temperature ', df_gpt3).fit()\n",
    "logit_reg_temptest.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+-------------------+-------------------+------------------------+\n",
      "|    variable     |      Basic      |    + Scenario     | + Scenario, Temp  | + Scenario, Temp, Test |\n",
      "+-----------------+-----------------+-------------------+-------------------+------------------------+\n",
      "| frame gain coef |     -1.142      |      -1.176       |      -1.188       |         -1.308         |\n",
      "|     std_err     |      0.081      |       0.087       |       0.088       |         0.093          |\n",
      "|     p value     |     0.0***      |      0.0***       |      0.0***       |         0.0***         |\n",
      "|  conf_interval  | [-1.3 - -0.984] | [-1.347 - -1.004] | [-1.361 - -1.016] |   [-1.491 - -1.125]    |\n",
      "|   Odds Ratio    |      0.319      |       0.309       |       0.305       |          0.27          |\n",
      "|       DF        |       1.0       |        3.0        |        4.0        |          10.0          |\n",
      "|        n        |      2814       |       2814        |       2814        |          2814          |\n",
      "+-----------------+-----------------+-------------------+-------------------+------------------------+\n"
     ]
    }
   ],
   "source": [
    "#Table for Results \n",
    "\n",
    "#Create tables for Simple \n",
    "from tabulate import tabulate\n",
    "\n",
    "## function for 'frame_gain' regressions \n",
    "def get_summary_stats(model):\n",
    "    p_val = model.pvalues['frame_gain']\n",
    "    conf_interval = f\"[{round(model.conf_int().loc['frame_gain', 0], 3)} - {round(model.conf_int().loc['frame_gain', 1], 3)}]\"\n",
    "    if p_val < 0.01:\n",
    "        asterisks = '***'\n",
    "    elif p_val < 0.05:\n",
    "        asterisks = '**'\n",
    "    elif p_val < 0.10:\n",
    "        asterisks = '*'\n",
    "    else:\n",
    "        asterisks = ''\n",
    "    return {\n",
    "        'frame gain coef': round(model.params['frame_gain'],3),\n",
    "        'std_err' : round(model.bse['frame_gain'],3),\n",
    "        'p value': f\"{round(p_val,4)}{asterisks}\",\n",
    "        'conf_interval': conf_interval, \n",
    "        'Odds Ratio': round(np.exp(model.params['frame_gain']),3),\n",
    "        'DF': model.df_model,\n",
    "        'n':model.nobs\n",
    "    }\n",
    "\n",
    "## function for 'intercept' regressions \n",
    "def intercept_summary(model):\n",
    "    p_val = model.pvalues['Intercept']\n",
    "    conf_interval = f\"[{round(model.conf_int().loc['Intercept', 0], 3)} - {round(model.conf_int().loc['Intercept', 1], 3)}]\"\n",
    "    if p_val < 0.01:\n",
    "        asterisks = '***'\n",
    "    elif p_val < 0.05:\n",
    "        asterisks = '**'\n",
    "    elif p_val < 0.10:\n",
    "        asterisks = '*'\n",
    "    else:\n",
    "        asterisks = ''\n",
    "    return {\n",
    "        'frame gain coef': round(model.params['Intercept'],3),\n",
    "        'std_err' : round(model.bse['Intercept'],3),\n",
    "        'p value': f\"{round(p_val,4)}{asterisks}\",\n",
    "        'conf_interval': conf_interval, \n",
    "        'Odds Ratio': round(np.exp(model.params['Intercept']),3),\n",
    "        'n':model.nobs\n",
    "    }\n",
    "\n",
    "###table for Simple Comparison \n",
    "summary_stats_basic = [get_summary_stats(logit_reg),\n",
    "                          get_summary_stats(logit_reg_scn), \n",
    "                          get_summary_stats(logit_reg_scn_temp), \n",
    "                          get_summary_stats(logit_reg_scn_temp_test), \n",
    "\n",
    "\n",
    "                          ]\n",
    "summary_logit_df1 = pd.DataFrame(summary_stats_basic)\n",
    "summary_logit_df1.T\n",
    "\n",
    "table1 = summary_logit_df1.T\n",
    "print(tabulate(table1, tablefmt = 'pretty', headers=[\"variable\", \"Basic\", \"+ Scenario\", \"+ Scenario, Temp\" , \"+ Scenario, Temp, Test\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis 1.2: All AI models will exhibit the risky choice framing effect, demonstrating preference for certain option in the gain condition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Simple Models for Gain or Loss \n",
    "\n",
    "##Log Odds of Option A (certain) Only in Gain Condition \n",
    "logit_reg_gain = smf.logit('option_selected_A ~ 1', gain_cond).fit()\n",
    "print(\"frame coeff:\", logit_reg_gain.params['Intercept'])\n",
    "print(\"frame p-vale:\", logit_reg_gain.pvalues['Intercept'])\n",
    "print(logit_reg_gain.summary())\n",
    "##opposite framing effect \n",
    "\n",
    "##Log Odds of Option B (risky) Only in Loss Condition \n",
    "logit_reg_loss = smf.logit('option_selected_B ~ 1', loss_cond).fit()\n",
    "print(\"frame coeff:\", logit_reg_loss.params['Intercept'])\n",
    "print(\"frame p-vale:\", logit_reg_loss.pvalues['Intercept'])\n",
    "print(logit_reg_loss.summary())\n",
    "\n",
    "##With Controls  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##table for gain / loss Comparison \n",
    "summary_options = [intercept_summary(logit_ratingappr_gain), \n",
    "                 intercept_summary(logit_ratingappr_rat_gain),\n",
    "                 intercept_summary(logit_ratingappr_loss),\n",
    "                 intercept_summary(logit_ratingappr_rat_loss)                 \n",
    "                 ]\n",
    "summary_options_df = pd.DataFrame(summary_options)\n",
    "\n",
    "options_table = summary_options_df.T\n",
    "print('\\n')\n",
    "print(tabulate(options_table, tablefmt = 'pretty', headers=[\"variable\", \"Gain Condition - All\", \"Gain Condition - Rationale Only\",\"Loss Condition - All\", \"Loss Condition - Rationale Only\" ]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypotheses: The model type and test will impact the extent the AI exibits the framing effect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.563945\n",
      "         Iterations 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annaking/Library/Python/3.9/lib/python/site-packages/statsmodels/discrete/discrete_model.py:2383: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[209], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m##add in interaction term for test\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m logit_reg_test \u001b[39m=\u001b[39m smf\u001b[39m.\u001b[39;49mlogit(\u001b[39m'\u001b[39;49m\u001b[39moption_selected_A ~ frame_gain * test\u001b[39;49m\u001b[39m'\u001b[39;49m, df_gpt3)\u001b[39m.\u001b[39;49mfit()\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mframe coeff:\u001b[39m\u001b[39m\"\u001b[39m, logit_reg_test\u001b[39m.\u001b[39mparams[\u001b[39m1\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mframe p-vale:\u001b[39m\u001b[39m\"\u001b[39m, logit_reg_test\u001b[39m.\u001b[39mpvalues[\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/discrete/discrete_model.py:2599\u001b[0m, in \u001b[0;36mLogit.fit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m   2596\u001b[0m \u001b[39m@Appender\u001b[39m(DiscreteModel\u001b[39m.\u001b[39mfit\u001b[39m.\u001b[39m\u001b[39m__doc__\u001b[39m)\n\u001b[1;32m   2597\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, start_params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, method\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnewton\u001b[39m\u001b[39m'\u001b[39m, maxiter\u001b[39m=\u001b[39m\u001b[39m35\u001b[39m,\n\u001b[1;32m   2598\u001b[0m         full_output\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, disp\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 2599\u001b[0m     bnryfit \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(start_params\u001b[39m=\u001b[39;49mstart_params,\n\u001b[1;32m   2600\u001b[0m                           method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m   2601\u001b[0m                           maxiter\u001b[39m=\u001b[39;49mmaxiter,\n\u001b[1;32m   2602\u001b[0m                           full_output\u001b[39m=\u001b[39;49mfull_output,\n\u001b[1;32m   2603\u001b[0m                           disp\u001b[39m=\u001b[39;49mdisp,\n\u001b[1;32m   2604\u001b[0m                           callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m   2605\u001b[0m                           \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2607\u001b[0m     discretefit \u001b[39m=\u001b[39m LogitResults(\u001b[39mself\u001b[39m, bnryfit)\n\u001b[1;32m   2608\u001b[0m     \u001b[39mreturn\u001b[39;00m BinaryResultsWrapper(discretefit)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/discrete/discrete_model.py:243\u001b[0m, in \u001b[0;36mDiscreteModel.fit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# TODO: make a function factory to have multiple call-backs\u001b[39;00m\n\u001b[0;32m--> 243\u001b[0m mlefit \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(start_params\u001b[39m=\u001b[39;49mstart_params,\n\u001b[1;32m    244\u001b[0m                      method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    245\u001b[0m                      maxiter\u001b[39m=\u001b[39;49mmaxiter,\n\u001b[1;32m    246\u001b[0m                      full_output\u001b[39m=\u001b[39;49mfull_output,\n\u001b[1;32m    247\u001b[0m                      disp\u001b[39m=\u001b[39;49mdisp,\n\u001b[1;32m    248\u001b[0m                      callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    249\u001b[0m                      \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    251\u001b[0m \u001b[39mreturn\u001b[39;00m mlefit\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/base/model.py:582\u001b[0m, in \u001b[0;36mLikelihoodModel.fit\u001b[0;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m     Hinv \u001b[39m=\u001b[39m cov_params_func(\u001b[39mself\u001b[39m, xopt, retvals)\n\u001b[1;32m    581\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnewton\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m full_output:\n\u001b[0;32m--> 582\u001b[0m     Hinv \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49minv(\u001b[39m-\u001b[39;49mretvals[\u001b[39m'\u001b[39;49m\u001b[39mHessian\u001b[39;49m\u001b[39m'\u001b[39;49m]) \u001b[39m/\u001b[39m nobs\n\u001b[1;32m    583\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m skip_hessian:\n\u001b[1;32m    584\u001b[0m     H \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhessian(xopt)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/numpy/linalg/linalg.py:561\u001b[0m, in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    559\u001b[0m signature \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mD->D\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m isComplexType(t) \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39md->d\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    560\u001b[0m extobj \u001b[39m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[0;32m--> 561\u001b[0m ainv \u001b[39m=\u001b[39m _umath_linalg\u001b[39m.\u001b[39;49minv(a, signature\u001b[39m=\u001b[39;49msignature, extobj\u001b[39m=\u001b[39;49mextobj)\n\u001b[1;32m    562\u001b[0m \u001b[39mreturn\u001b[39;00m wrap(ainv\u001b[39m.\u001b[39mastype(result_t, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/numpy/linalg/linalg.py:112\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[0;32m--> 112\u001b[0m     \u001b[39mraise\u001b[39;00m LinAlgError(\u001b[39m\"\u001b[39m\u001b[39mSingular matrix\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "##add in interaction term for test\n",
    "logit_reg_test = smf.logit('option_selected_A ~ frame_gain * test', df_gpt3).fit()\n",
    "print(\"frame coeff:\", logit_reg_test.params[1])\n",
    "print(\"frame p-vale:\", logit_reg_test.pvalues[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H5: A higher temperature will increase the framing effect observed in GPT-3.5 Turbo's choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##add in interaction term for temp & model \n",
    "\n",
    "logit_reg_temptest = smf.logit('option_selected_cat ~ frame * test + frame * temperature ', df_gpt3).fit()\n",
    "print(\"frame coeff:\", logit_reg_temptest.params[1])\n",
    "print(\"frame p-vale:\", logit_reg_temptest.pvalues[1])\n",
    "logit_reg_temptest.summary()\n",
    "#framing effect is positive, but not significant \n",
    "##temperature has a positive and significant effect, suggesting that increasing temperature increases the odds of 'option_selected_cat'.\n",
    "##interaction term frame[T.loss]:temperature is negative and significant, indicating that for loss-framed scenarios, increasing temperature decreases the odds of  selecting Option B compared to gain-framed scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H6: The model prompt conditions (risk, system role, and instructions) will impact the framing effect observed in GPT-3.5 Turbo's choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.607704\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:      option_selected_A   No. Observations:                 2412\n",
      "Model:                          Logit   Df Residuals:                     2408\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Mon, 14 Aug 2023   Pseudo R-squ.:                  0.1056\n",
      "Time:                        21:18:58   Log-Likelihood:                -1465.8\n",
      "converged:                       True   LL-Null:                       -1638.9\n",
      "Covariance Type:            nonrobust   LLR p-value:                 9.893e-75\n",
      "=================================================================================================\n",
      "                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Intercept                         0.5861      0.075      7.845      0.000       0.440       0.733\n",
      "C(instructions)[T.chain]          0.1203      0.121      0.996      0.319      -0.117       0.357\n",
      "C(instructions)[T.task_order]    -1.1794      0.105    -11.277      0.000      -1.384      -0.974\n",
      "frame_gain                       -1.2356      0.090    -13.691      0.000      -1.413      -1.059\n",
      "=================================================================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.637286\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:      option_selected_A   No. Observations:                 2412\n",
      "Model:                          Logit   Df Residuals:                     2409\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Mon, 14 Aug 2023   Pseudo R-squ.:                 0.06208\n",
      "Time:                        21:18:58   Log-Likelihood:                -1537.1\n",
      "converged:                       True   LL-Null:                       -1638.9\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.465e-45\n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept                0.6046      0.113      5.370      0.000       0.384       0.825\n",
      "C(sys_role)[T.human]    -0.4747      0.114     -4.149      0.000      -0.699      -0.250\n",
      "frame_gain              -1.1626      0.087    -13.375      0.000      -1.333      -0.992\n",
      "========================================================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.639334\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:      option_selected_A   No. Observations:                 2412\n",
      "Model:                          Logit   Df Residuals:                     2409\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Mon, 14 Aug 2023   Pseudo R-squ.:                 0.05907\n",
      "Time:                        21:18:58   Log-Likelihood:                -1542.1\n",
      "converged:                       True   LL-Null:                       -1638.9\n",
      "Covariance Type:            nonrobust   LLR p-value:                 9.041e-43\n",
      "===================================================================================\n",
      "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Intercept           0.0909      0.072      1.270      0.204      -0.049       0.231\n",
      "C(risk)[T.risk]     0.2328      0.086      2.704      0.007       0.064       0.402\n",
      "frame_gain         -1.1574      0.087    -13.353      0.000      -1.327      -0.988\n",
      "===================================================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.602097\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:      option_selected_A   No. Observations:                 2412\n",
      "Model:                          Logit   Df Residuals:                     2402\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Mon, 14 Aug 2023   Pseudo R-squ.:                  0.1139\n",
      "Time:                        21:18:58   Log-Likelihood:                -1452.3\n",
      "converged:                       True   LL-Null:                       -1638.9\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.917e-75\n",
      "============================================================================================================\n",
      "                                               coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                    0.7828      0.151      5.188      0.000       0.487       1.078\n",
      "C(instructions)[T.chain]                     0.0500      0.203      0.247      0.805      -0.348       0.448\n",
      "C(instructions)[T.task_order]               -1.3890      0.150     -9.254      0.000      -1.683      -1.095\n",
      "C(risk)[T.risk]                              0.5103      0.150      3.401      0.001       0.216       0.804\n",
      "C(sys_role)[T.human]                        -0.4439      0.196     -2.264      0.024      -0.828      -0.060\n",
      "frame_gain                                  -1.5217      0.214     -7.106      0.000      -1.941      -1.102\n",
      "frame_gain:C(instructions)[T.chain]         -0.1356      0.286     -0.474      0.636      -0.697       0.426\n",
      "frame_gain:C(instructions)[T.task_order]     0.5886      0.226      2.608      0.009       0.146       1.031\n",
      "frame_gain:C(risk)[T.risk]                  -0.3600      0.223     -1.612      0.107      -0.798       0.078\n",
      "frame_gain:C(sys_role)[T.human]              0.4022      0.283      1.421      0.155      -0.153       0.957\n",
      "============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "##Models for Instructions, Risk, and Sys Role \n",
    "    ###check 'moderate' \n",
    "    #standalone model \n",
    "\n",
    "logit_reg_ins = smf.logit('option_selected_A ~ frame_gain + C(instructions)', df_gpt3).fit()\n",
    "print(logit_reg_ins.summary())\n",
    "\n",
    "logit_reg_sys = smf.logit('option_selected_A ~ frame_gain + C(sys_role)', df_gpt3).fit()\n",
    "print(logit_reg_sys.summary())\n",
    "\n",
    "logit_reg_risk = smf.logit('option_selected_A ~ frame_gain + C(risk)', df_gpt3).fit()\n",
    "print(logit_reg_risk.summary())\n",
    "\n",
    "##add in interaction term for all prompt variables\n",
    "logit_var_combined = smf.logit('option_selected_A ~ frame_gain * C(instructions) + frame_gain * C(risk) + frame_gain * C(sys_role)', df_gpt3).fit()\n",
    "print(logit_var_combined.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.604944\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:      option_selected_A   No. Observations:                 2412\n",
      "Model:                          Logit   Df Residuals:                     2406\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Tue, 15 Aug 2023   Pseudo R-squ.:                  0.1097\n",
      "Time:                        15:50:55   Log-Likelihood:                -1459.1\n",
      "converged:                       True   LL-Null:                       -1638.9\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.563e-75\n",
      "============================================================================================================\n",
      "                                               coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                    0.6493      0.085      7.626      0.000       0.482       0.816\n",
      "C(instructions)[T.chain]                     0.2499      0.176      1.417      0.157      -0.096       0.595\n",
      "C(instructions)[T.task_order]               -1.4321      0.137    -10.491      0.000      -1.700      -1.165\n",
      "frame_gain                                  -1.3653      0.122    -11.191      0.000      -1.604      -1.126\n",
      "frame_gain:C(instructions)[T.chain]         -0.2499      0.248     -1.006      0.314      -0.736       0.237\n",
      "frame_gain:C(instructions)[T.task_order]     0.6440      0.208      3.097      0.002       0.236       1.052\n",
      "============================================================================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.636568\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:      option_selected_A   No. Observations:                 2412\n",
      "Model:                          Logit   Df Residuals:                     2408\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Tue, 15 Aug 2023   Pseudo R-squ.:                 0.06314\n",
      "Time:                        15:50:55   Log-Likelihood:                -1535.4\n",
      "converged:                       True   LL-Null:                       -1638.9\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.319e-44\n",
      "===================================================================================================\n",
      "                                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Intercept                           0.7828      0.151      5.188      0.000       0.487       1.078\n",
      "C(sys_role)[T.human]               -0.6846      0.163     -4.190      0.000      -1.005      -0.364\n",
      "frame_gain                         -1.5217      0.214     -7.106      0.000      -1.941      -1.102\n",
      "frame_gain:C(sys_role)[T.human]     0.4326      0.234      1.846      0.065      -0.027       0.892\n",
      "===================================================================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.638946\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:      option_selected_A   No. Observations:                 2412\n",
      "Model:                          Logit   Df Residuals:                     2408\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Tue, 15 Aug 2023   Pseudo R-squ.:                 0.05964\n",
      "Time:                        15:50:55   Log-Likelihood:                -1541.1\n",
      "converged:                       True   LL-Null:                       -1638.9\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.970e-42\n",
      "==============================================================================================\n",
      "                                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------\n",
      "Intercept                      0.0392      0.081      0.485      0.628      -0.119       0.198\n",
      "C(risk)[T.risk]                0.3377      0.115      2.927      0.003       0.112       0.564\n",
      "frame_gain                    -1.0371      0.123     -8.442      0.000      -1.278      -0.796\n",
      "frame_gain:C(risk)[T.risk]    -0.2374      0.173     -1.369      0.171      -0.577       0.102\n",
      "==============================================================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.602097\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:      option_selected_A   No. Observations:                 2412\n",
      "Model:                          Logit   Df Residuals:                     2402\n",
      "Method:                           MLE   Df Model:                            9\n",
      "Date:                Tue, 15 Aug 2023   Pseudo R-squ.:                  0.1139\n",
      "Time:                        15:50:55   Log-Likelihood:                -1452.3\n",
      "converged:                       True   LL-Null:                       -1638.9\n",
      "Covariance Type:            nonrobust   LLR p-value:                 6.917e-75\n",
      "============================================================================================================\n",
      "                                               coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                    0.7828      0.151      5.188      0.000       0.487       1.078\n",
      "C(instructions)[T.chain]                     0.0500      0.203      0.247      0.805      -0.348       0.448\n",
      "C(instructions)[T.task_order]               -1.3890      0.150     -9.254      0.000      -1.683      -1.095\n",
      "C(risk)[T.risk]                              0.5103      0.150      3.401      0.001       0.216       0.804\n",
      "C(sys_role)[T.human]                        -0.4439      0.196     -2.264      0.024      -0.828      -0.060\n",
      "frame_gain                                  -1.5217      0.214     -7.106      0.000      -1.941      -1.102\n",
      "frame_gain:C(instructions)[T.chain]         -0.1356      0.286     -0.474      0.636      -0.697       0.426\n",
      "frame_gain:C(instructions)[T.task_order]     0.5886      0.226      2.608      0.009       0.146       1.031\n",
      "frame_gain:C(risk)[T.risk]                  -0.3600      0.223     -1.612      0.107      -0.798       0.078\n",
      "frame_gain:C(sys_role)[T.human]              0.4022      0.283      1.421      0.155      -0.153       0.957\n",
      "============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "logit_reg_ins = smf.logit('option_selected_A ~ frame_gain * C(instructions)', df_gpt3).fit()\n",
    "print(logit_reg_ins.summary())\n",
    "\n",
    "logit_reg_sys = smf.logit('option_selected_A ~ frame_gain * C(sys_role)', df_gpt3).fit()\n",
    "print(logit_reg_sys.summary())\n",
    "\n",
    "logit_reg_risk = smf.logit('option_selected_A ~ frame_gain * C(risk)', df_gpt3).fit()\n",
    "print(logit_reg_risk.summary())\n",
    "\n",
    "##add in interaction term for all prompt variables\n",
    "logit_var_combined = smf.logit('option_selected_A ~ frame_gain * C(instructions) + frame_gain * C(risk) + frame_gain * C(sys_role)', df_gpt3).fit()\n",
    "print(logit_var_combined.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Basic               + Instructions    + System Role      + Risk             All\n",
      "----------------------------------------  -----------------  -----------------  -----------------  -----------------  -----------------\n",
      "frame_gain                                -1.142 (0.000***)  -1.365 (0.000***)  -1.522 (0.000***)  -1.037 (0.000***)  -1.241 (0.000***)\n",
      "C(instructions)[T.chain]                  --                 0.250 (0.157)      --                 --                 -0.029 (0.837)\n",
      "C(instructions)[T.task_order]             --                 -1.432 (0.000***)  --                 --                 -1.159 (0.000***)\n",
      "C(sys_role)[T.neutral_system]             --                 --                 --                 --                 0.259 (0.064*)\n",
      "C(sys_role)[T.human]                      --                 --                 -0.685 (0.000***)  --                 --\n",
      "C(risk)[T.risk]                           --                 --                 --                 0.338 (0.003***)   0.353 (0.002***)\n",
      "Intercept                                 0.121 (0.023**)    0.649 (0.000***)   0.783 (0.000***)   0.039 (0.628)      0.384 (0.000***)\n",
      "frame_gain:C(sys_role)[T.human]           --                 --                 0.433 (0.065*)     --                 --\n",
      "frame_gain:C(risk)[T.risk]                --                 --                 --                 -0.237 (0.171)     --\n",
      "frame_gain:C(instructions)[T.task_order]  --                 0.644 (0.002***)   --                 --                 --\n",
      "frame_gain:C(instructions)[T.chain]       --                 -0.250 (0.314)     --                 --                 --\n"
     ]
    }
   ],
   "source": [
    "# Assuming logit_reg, logit_reg_ins, logit_reg_var are your model outputs\n",
    "table1 = create_compare_table(logit_reg, logit_reg_ins,logit_reg_sys,logit_reg_risk, logit_reg_var)\n",
    "table1.fillna(\"--\")\n",
    "#print(table1)\n",
    "print(tabulate(table1, headers = (\"Basic\", \" + Instructions\", \"+ System Role\", \"+ Risk\", \"All\" )))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Basic               + Instructions    + System Role      + Risk             All\n",
      "-----------------------------  -----------------  -----------------  -----------------  -----------------  -----------------\n",
      "frame_gain                     -1.142 (0.000***)  -1.236 (0.000***)  -1.163 (0.000***)  -1.157 (0.000***)  -1.241 (0.000***)\n",
      "C(instructions)[T.chain]       --                 0.120 (0.319)      --                 --                 -0.029 (0.837)\n",
      "C(instructions)[T.task_order]  --                 -1.179 (0.000***)  --                 --                 -1.159 (0.000***)\n",
      "C(sys_role)[T.neutral_system]  --                 --                 --                 --                 0.259 (0.064*)\n",
      "C(sys_role)[T.human]           --                 --                 -0.475 (0.000***)  --                 --\n",
      "C(risk)[T.risk]                --                 --                 --                 0.233 (0.007***)   0.353 (0.002***)\n",
      "Intercept                      0.121 (0.023**)    0.586 (0.000***)   0.605 (0.000***)   0.091 (0.204)      0.384 (0.000***)\n"
     ]
    }
   ],
   "source": [
    "##Tables to compare Results\n",
    "def extract_from_model(model):\n",
    "    \"\"\"Extract coefficients, p-values from model object.\"\"\"\n",
    "    params = model.params\n",
    "    pvals = model.pvalues\n",
    "    std_err = model.bse\n",
    "    return params, pvals, std_err \n",
    "\n",
    "def asterick(pval):\n",
    "    if pval < 0.01:\n",
    "        return '***'\n",
    "    elif pval < 0.05:\n",
    "        return '**'\n",
    "    elif pval < 0.10:\n",
    "        return '*'\n",
    "    return ''\n",
    "\n",
    "\n",
    "def create_compare_table(*models):\n",
    "    \"\"\"Create a table using coefficients, standard errors, and p-values.\"\"\"\n",
    "    # Define the desired ordering of the terms\n",
    "    ordered_vars = ['frame_gain', 'C(instructions)[T.chain]', 'C(instructions)[T.task_order]', \n",
    "                    'C(sys_role)[T.neutral_system]', 'C(sys_role)[T.human]', 'C(risk)[T.risk]', 'Intercept']\n",
    "    all_vars = set().union(*[set(model.params.index) for model in models])\n",
    "    for var in all_vars:\n",
    "        if var not in ordered_vars:\n",
    "            ordered_vars.append(var)\n",
    "    data = {'Variable': ordered_vars}\n",
    "    for i, model in enumerate(models, start=1):\n",
    "        params, pvals, std_err = extract_from_model(model)\n",
    "        model_data = []\n",
    "        for term in ordered_vars:\n",
    "            if term in params:\n",
    "                model_data.append(f\"{params[term]:.3f} ({pvals[term]:.3f}{asterick(pvals[term])})\")\n",
    "            else:\n",
    "                model_data.append(\"--\")\n",
    "        data[f'Model {i}'] = model_data\n",
    "\n",
    "    df = pd.DataFrame(data).set_index('Variable')\n",
    "    return df\n",
    "\n",
    "\n",
    "# Assuming logit_reg, logit_reg_ins, logit_reg_var are your model outputs\n",
    "table1 = create_compare_table(logit_reg, logit_reg_ins,logit_reg_sys,logit_reg_risk, logit_reg_var)\n",
    "table1.fillna(\"--\")\n",
    "#print(table1)\n",
    "print(tabulate(table1, headers = (\"Basic\", \" + Instructions\", \"+ System Role\", \"+ Risk\", \"All\" )))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming logit_reg, logit_reg_ins, logit_reg_var are your model outputs\n",
    "table1 = create_compare_table(logit_reg, logit_reg_ins,logit_reg_sys,logit_reg_risk, logit_reg_var)\n",
    "table1.fillna(\"--\")\n",
    "#print(table1)\n",
    "print(tabulate(table1, headers = (\"Basic\", \" + Instructions\", \"+ System Role\", \"+ Risk\", \"All\" )))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.628467\n",
      "         Iterations 5\n",
      "frame coeff: -1.49362472361517\n",
      "frame p-vale: 2.1055363172920415e-34\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:      option_selected_A   No. Observations:                 2814\n",
      "Model:                          Logit   Df Residuals:                     2810\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Mon, 14 Aug 2023   Pseudo R-squ.:                 0.06587\n",
      "Time:                        20:59:19   Log-Likelihood:                -1768.5\n",
      "converged:                       True   LL-Null:                       -1893.2\n",
      "Covariance Type:            nonrobust   LLR p-value:                 8.844e-54\n",
      "====================================================================================================\n",
      "                                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Intercept                            0.0560      0.075      0.748      0.454      -0.091       0.203\n",
      "C(temperature)[T.0.7]                0.1294      0.106      1.219      0.223      -0.079       0.337\n",
      "frame_gain                          -1.4936      0.122    -12.232      0.000      -1.733      -1.254\n",
      "frame_gain:C(temperature)[T.0.7]     0.6345      0.164      3.860      0.000       0.312       0.957\n",
      "====================================================================================================\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.605534\n",
      "         Iterations 5\n",
      "frame coeff: -0.028702471971571802\n",
      "frame p-vale: 0.8373960902906017\n"
     ]
    }
   ],
   "source": [
    "##Interaction with Test and Temp\n",
    "\n",
    "##add in interaction term for temp\n",
    "logit_reg_temp = smf.logit('option_selected_A ~ frame_gain *C(temperature) + frame_gain', df_gpt3).fit()\n",
    "print(\"frame coeff:\", logit_reg_temp.params['frame_gain'])\n",
    "print(\"frame p-vale:\", logit_reg_temp.pvalues['frame_gain'])\n",
    "print(logit_reg_temp.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.440755\n",
      "         Iterations 7\n",
      "frame coeff: 1.0695059164404142\n",
      "frame p-vale: 0.09188382689796289\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>option_selected_cat</td> <th>  No. Observations:  </th>  <td>   940</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>Logit</td>        <th>  Df Residuals:      </th>  <td>   924</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                  <td>MLE</td>         <th>  Df Model:          </th>  <td>    15</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 05 Aug 2023</td>   <th>  Pseudo R-squ.:     </th>  <td>0.2962</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:43:28</td>       <th>  Log-Likelihood:    </th> <td> -414.31</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>              <td>True</td>         <th>  LL-Null:           </th> <td> -588.65</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>      <th>  LLR p-value:       </th> <td>3.956e-65</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                                                       <td></td>                                                          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                                                                                   <td>   -3.2113</td> <td>    0.515</td> <td>   -6.237</td> <td> 0.000</td> <td>   -4.220</td> <td>   -2.202</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>frame[T.loss]</th>                                                                                               <td>    1.0695</td> <td>    0.635</td> <td>    1.686</td> <td> 0.092</td> <td>   -0.174</td> <td>    2.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>test[T.['combo 2', 'system_message_hum', 'user_message_baseline1', 'human']]</th>                                <td>   -0.2635</td> <td>    0.705</td> <td>   -0.374</td> <td> 0.709</td> <td>   -1.645</td> <td>    1.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>test[T.['combo 3', 'system_message_risk', 'user_message_baseline1', 'risk system']]</th>                         <td>    1.5458</td> <td>    0.560</td> <td>    2.760</td> <td> 0.006</td> <td>    0.448</td> <td>    2.643</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>test[T.['combo 5', 'system_message_hum_json', 'user_message_taskord', 'hum + task order']]</th>                  <td>    3.7690</td> <td>    0.576</td> <td>    6.541</td> <td> 0.000</td> <td>    2.640</td> <td>    4.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>test[T.['combo 5B', 'system_message_risk_json', 'user_message_taskord', 'risk + task order']]</th>               <td>    3.0909</td> <td>    0.556</td> <td>    5.556</td> <td> 0.000</td> <td>    2.000</td> <td>    4.181</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>test[T.['combo 6', 'system_message_1', 'user_message_chain', 'flag for re-run']]</th>                            <td>    0.8187</td> <td>    0.592</td> <td>    1.383</td> <td> 0.167</td> <td>   -0.341</td> <td>    1.979</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>test[T.['combo 6B', 'system_message_risk', 'user_message_chain', 'risk + chain']]</th>                           <td>    1.4554</td> <td>    0.563</td> <td>    2.587</td> <td> 0.010</td> <td>    0.353</td> <td>    2.558</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>frame[T.loss]:test[T.['combo 2', 'system_message_hum', 'user_message_baseline1', 'human']]</th>                  <td>   -0.5093</td> <td>    0.910</td> <td>   -0.559</td> <td> 0.576</td> <td>   -2.294</td> <td>    1.275</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>frame[T.loss]:test[T.['combo 3', 'system_message_risk', 'user_message_baseline1', 'risk system']]</th>           <td>   -0.9719</td> <td>    0.715</td> <td>   -1.360</td> <td> 0.174</td> <td>   -2.373</td> <td>    0.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>frame[T.loss]:test[T.['combo 5', 'system_message_hum_json', 'user_message_taskord', 'hum + task order']]</th>    <td>   -0.4983</td> <td>    0.731</td> <td>   -0.681</td> <td> 0.496</td> <td>   -1.932</td> <td>    0.935</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>frame[T.loss]:test[T.['combo 5B', 'system_message_risk_json', 'user_message_taskord', 'risk + task order']]</th> <td>   -0.1304</td> <td>    0.707</td> <td>   -0.185</td> <td> 0.854</td> <td>   -1.515</td> <td>    1.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>frame[T.loss]:test[T.['combo 6', 'system_message_1', 'user_message_chain', 'flag for re-run']]</th>              <td>   -0.6028</td> <td>    0.753</td> <td>   -0.800</td> <td> 0.424</td> <td>   -2.079</td> <td>    0.873</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>frame[T.loss]:test[T.['combo 6B', 'system_message_risk', 'user_message_chain', 'risk + chain']]</th>             <td>   -1.5772</td> <td>    0.749</td> <td>   -2.107</td> <td> 0.035</td> <td>   -3.045</td> <td>   -0.110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>temperature</th>                                                                                                 <td>    1.8456</td> <td>    0.386</td> <td>    4.780</td> <td> 0.000</td> <td>    1.089</td> <td>    2.602</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>frame[T.loss]:temperature</th>                                                                                   <td>   -1.1004</td> <td>    0.520</td> <td>   -2.116</td> <td> 0.034</td> <td>   -2.120</td> <td>   -0.081</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                                                                                                   & option\\_selected\\_cat & \\textbf{  No. Observations:  } &      940    \\\\\n",
       "\\textbf{Model:}                                                                                                           &         Logit         & \\textbf{  Df Residuals:      } &      924    \\\\\n",
       "\\textbf{Method:}                                                                                                          &          MLE          & \\textbf{  Df Model:          } &       15    \\\\\n",
       "\\textbf{Date:}                                                                                                            &    Sat, 05 Aug 2023   & \\textbf{  Pseudo R-squ.:     } &   0.2962    \\\\\n",
       "\\textbf{Time:}                                                                                                            &        01:43:28       & \\textbf{  Log-Likelihood:    } &   -414.31   \\\\\n",
       "\\textbf{converged:}                                                                                                       &          True         & \\textbf{  LL-Null:           } &   -588.65   \\\\\n",
       "\\textbf{Covariance Type:}                                                                                                 &       nonrobust       & \\textbf{  LLR p-value:       } & 3.956e-65   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                                                                                          & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                                                                                                        &      -3.2113  &        0.515     &    -6.237  &         0.000        &       -4.220    &       -2.202     \\\\\n",
       "\\textbf{frame[T.loss]}                                                                                                    &       1.0695  &        0.635     &     1.686  &         0.092        &       -0.174    &        2.313     \\\\\n",
       "\\textbf{test[T.['combo 2', 'system\\_message\\_hum', 'user\\_message\\_baseline1', 'human']]}                                 &      -0.2635  &        0.705     &    -0.374  &         0.709        &       -1.645    &        1.118     \\\\\n",
       "\\textbf{test[T.['combo 3', 'system\\_message\\_risk', 'user\\_message\\_baseline1', 'risk system']]}                          &       1.5458  &        0.560     &     2.760  &         0.006        &        0.448    &        2.643     \\\\\n",
       "\\textbf{test[T.['combo 5', 'system\\_message\\_hum\\_json', 'user\\_message\\_taskord', 'hum + task order']]}                  &       3.7690  &        0.576     &     6.541  &         0.000        &        2.640    &        4.898     \\\\\n",
       "\\textbf{test[T.['combo 5B', 'system\\_message\\_risk\\_json', 'user\\_message\\_taskord', 'risk + task order']]}               &       3.0909  &        0.556     &     5.556  &         0.000        &        2.000    &        4.181     \\\\\n",
       "\\textbf{test[T.['combo 6', 'system\\_message\\_1', 'user\\_message\\_chain', 'flag for re-run']]}                             &       0.8187  &        0.592     &     1.383  &         0.167        &       -0.341    &        1.979     \\\\\n",
       "\\textbf{test[T.['combo 6B', 'system\\_message\\_risk', 'user\\_message\\_chain', 'risk + chain']]}                            &       1.4554  &        0.563     &     2.587  &         0.010        &        0.353    &        2.558     \\\\\n",
       "\\textbf{frame[T.loss]:test[T.['combo 2', 'system\\_message\\_hum', 'user\\_message\\_baseline1', 'human']]}                   &      -0.5093  &        0.910     &    -0.559  &         0.576        &       -2.294    &        1.275     \\\\\n",
       "\\textbf{frame[T.loss]:test[T.['combo 3', 'system\\_message\\_risk', 'user\\_message\\_baseline1', 'risk system']]}            &      -0.9719  &        0.715     &    -1.360  &         0.174        &       -2.373    &        0.429     \\\\\n",
       "\\textbf{frame[T.loss]:test[T.['combo 5', 'system\\_message\\_hum\\_json', 'user\\_message\\_taskord', 'hum + task order']]}    &      -0.4983  &        0.731     &    -0.681  &         0.496        &       -1.932    &        0.935     \\\\\n",
       "\\textbf{frame[T.loss]:test[T.['combo 5B', 'system\\_message\\_risk\\_json', 'user\\_message\\_taskord', 'risk + task order']]} &      -0.1304  &        0.707     &    -0.185  &         0.854        &       -1.515    &        1.254     \\\\\n",
       "\\textbf{frame[T.loss]:test[T.['combo 6', 'system\\_message\\_1', 'user\\_message\\_chain', 'flag for re-run']]}               &      -0.6028  &        0.753     &    -0.800  &         0.424        &       -2.079    &        0.873     \\\\\n",
       "\\textbf{frame[T.loss]:test[T.['combo 6B', 'system\\_message\\_risk', 'user\\_message\\_chain', 'risk + chain']]}              &      -1.5772  &        0.749     &    -2.107  &         0.035        &       -3.045    &       -0.110     \\\\\n",
       "\\textbf{temperature}                                                                                                      &       1.8456  &        0.386     &     4.780  &         0.000        &        1.089    &        2.602     \\\\\n",
       "\\textbf{frame[T.loss]:temperature}                                                                                        &      -1.1004  &        0.520     &    -2.116  &         0.034        &       -2.120    &       -0.081     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            Logit Regression Results                           \n",
       "===============================================================================\n",
       "Dep. Variable:     option_selected_cat   No. Observations:                  940\n",
       "Model:                           Logit   Df Residuals:                      924\n",
       "Method:                            MLE   Df Model:                           15\n",
       "Date:                 Sat, 05 Aug 2023   Pseudo R-squ.:                  0.2962\n",
       "Time:                         01:43:28   Log-Likelihood:                -414.31\n",
       "converged:                        True   LL-Null:                       -588.65\n",
       "Covariance Type:             nonrobust   LLR p-value:                 3.956e-65\n",
       "===============================================================================================================================================================================\n",
       "                                                                                                                  coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                                                                                      -3.2113      0.515     -6.237      0.000      -4.220      -2.202\n",
       "frame[T.loss]                                                                                                   1.0695      0.635      1.686      0.092      -0.174       2.313\n",
       "test[T.['combo 2', 'system_message_hum', 'user_message_baseline1', 'human']]                                   -0.2635      0.705     -0.374      0.709      -1.645       1.118\n",
       "test[T.['combo 3', 'system_message_risk', 'user_message_baseline1', 'risk system']]                             1.5458      0.560      2.760      0.006       0.448       2.643\n",
       "test[T.['combo 5', 'system_message_hum_json', 'user_message_taskord', 'hum + task order']]                      3.7690      0.576      6.541      0.000       2.640       4.898\n",
       "test[T.['combo 5B', 'system_message_risk_json', 'user_message_taskord', 'risk + task order']]                   3.0909      0.556      5.556      0.000       2.000       4.181\n",
       "test[T.['combo 6', 'system_message_1', 'user_message_chain', 'flag for re-run']]                                0.8187      0.592      1.383      0.167      -0.341       1.979\n",
       "test[T.['combo 6B', 'system_message_risk', 'user_message_chain', 'risk + chain']]                               1.4554      0.563      2.587      0.010       0.353       2.558\n",
       "frame[T.loss]:test[T.['combo 2', 'system_message_hum', 'user_message_baseline1', 'human']]                     -0.5093      0.910     -0.559      0.576      -2.294       1.275\n",
       "frame[T.loss]:test[T.['combo 3', 'system_message_risk', 'user_message_baseline1', 'risk system']]              -0.9719      0.715     -1.360      0.174      -2.373       0.429\n",
       "frame[T.loss]:test[T.['combo 5', 'system_message_hum_json', 'user_message_taskord', 'hum + task order']]       -0.4983      0.731     -0.681      0.496      -1.932       0.935\n",
       "frame[T.loss]:test[T.['combo 5B', 'system_message_risk_json', 'user_message_taskord', 'risk + task order']]    -0.1304      0.707     -0.185      0.854      -1.515       1.254\n",
       "frame[T.loss]:test[T.['combo 6', 'system_message_1', 'user_message_chain', 'flag for re-run']]                 -0.6028      0.753     -0.800      0.424      -2.079       0.873\n",
       "frame[T.loss]:test[T.['combo 6B', 'system_message_risk', 'user_message_chain', 'risk + chain']]                -1.5772      0.749     -2.107      0.035      -3.045      -0.110\n",
       "temperature                                                                                                     1.8456      0.386      4.780      0.000       1.089       2.602\n",
       "frame[T.loss]:temperature                                                                                      -1.1004      0.520     -2.116      0.034      -2.120      -0.081\n",
       "===============================================================================================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome: The framing effect is stronger or weaker at different temperature settings.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.628467\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>option_selected_A</td> <th>  No. Observations:  </th>  <td>  2814</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>       <th>  Df Residuals:      </th>  <td>  2810</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>        <th>  Df Model:          </th>  <td>     3</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 14 Aug 2023</td>  <th>  Pseudo R-squ.:     </th>  <td>0.06587</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>18:37:21</td>      <th>  Log-Likelihood:    </th> <td> -1768.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>        <th>  LL-Null:           </th> <td> -1893.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>     <th>  LLR p-value:       </th> <td>8.844e-54</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                  <td></td>                    <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                        <td>    0.0560</td> <td>    0.075</td> <td>    0.748</td> <td> 0.454</td> <td>   -0.091</td> <td>    0.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(temperature)[T.0.7]</th>            <td>    0.1294</td> <td>    0.106</td> <td>    1.219</td> <td> 0.223</td> <td>   -0.079</td> <td>    0.337</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>frame_gain</th>                       <td>   -1.4936</td> <td>    0.122</td> <td>  -12.232</td> <td> 0.000</td> <td>   -1.733</td> <td>   -1.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>frame_gain:C(temperature)[T.0.7]</th> <td>    0.6345</td> <td>    0.164</td> <td>    3.860</td> <td> 0.000</td> <td>    0.312</td> <td>    0.957</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                    & option\\_selected\\_A & \\textbf{  No. Observations:  } &     2814    \\\\\n",
       "\\textbf{Model:}                            &        Logit        & \\textbf{  Df Residuals:      } &     2810    \\\\\n",
       "\\textbf{Method:}                           &         MLE         & \\textbf{  Df Model:          } &        3    \\\\\n",
       "\\textbf{Date:}                             &   Mon, 14 Aug 2023  & \\textbf{  Pseudo R-squ.:     } &  0.06587    \\\\\n",
       "\\textbf{Time:}                             &       18:37:21      & \\textbf{  Log-Likelihood:    } &   -1768.5   \\\\\n",
       "\\textbf{converged:}                        &         True        & \\textbf{  LL-Null:           } &   -1893.2   \\\\\n",
       "\\textbf{Covariance Type:}                  &      nonrobust      & \\textbf{  LLR p-value:       } & 8.844e-54   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                           & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                         &       0.0560  &        0.075     &     0.748  &         0.454        &       -0.091    &        0.203     \\\\\n",
       "\\textbf{C(temperature)[T.0.7]}             &       0.1294  &        0.106     &     1.219  &         0.223        &       -0.079    &        0.337     \\\\\n",
       "\\textbf{frame\\_gain}                       &      -1.4936  &        0.122     &   -12.232  &         0.000        &       -1.733    &       -1.254     \\\\\n",
       "\\textbf{frame\\_gain:C(temperature)[T.0.7]} &       0.6345  &        0.164     &     3.860  &         0.000        &        0.312    &        0.957     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:      option_selected_A   No. Observations:                 2814\n",
       "Model:                          Logit   Df Residuals:                     2810\n",
       "Method:                           MLE   Df Model:                            3\n",
       "Date:                Mon, 14 Aug 2023   Pseudo R-squ.:                 0.06587\n",
       "Time:                        18:37:21   Log-Likelihood:                -1768.5\n",
       "converged:                       True   LL-Null:                       -1893.2\n",
       "Covariance Type:            nonrobust   LLR p-value:                 8.844e-54\n",
       "====================================================================================================\n",
       "                                       coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------------\n",
       "Intercept                            0.0560      0.075      0.748      0.454      -0.091       0.203\n",
       "C(temperature)[T.0.7]                0.1294      0.106      1.219      0.223      -0.079       0.337\n",
       "frame_gain                          -1.4936      0.122    -12.232      0.000      -1.733      -1.254\n",
       "frame_gain:C(temperature)[T.0.7]     0.6345      0.164      3.860      0.000       0.312       0.957\n",
       "====================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##This model aims to examine how the combination of the frame condition and the temperature setting influences the likelihood of selecting Proposal B (risky option).\n",
    "print(\"Outcome: The framing effect is stronger or weaker at different temperature settings.\")\n",
    "\n",
    "#logit_reg_T = smf.logit('option_selected_cat ~ frame + temp_var', df_gpt3).fit()\n",
    "logit_reg_T = smf.logit('option_selected_A ~ frame_gain * C(temperature) + frame_gain', df_gpt3).fit()\n",
    "logit_reg_T.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Robustness Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[253], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m vif_data[\u001b[39m'\u001b[39m\u001b[39mfeature\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m     19\u001b[0m \u001b[39m# Calculate and add the VIF to the data frame\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m vif_data[\u001b[39m'\u001b[39m\u001b[39mVIF\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [variance_inflation_factor(X\u001b[39m.\u001b[39mvalues, i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X\u001b[39m.\u001b[39mcolumns))]\n\u001b[1;32m     22\u001b[0m \u001b[39mprint\u001b[39m(vif_data)\n",
      "Cell \u001b[0;32mIn[253], line 20\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     17\u001b[0m vif_data[\u001b[39m'\u001b[39m\u001b[39mfeature\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m     19\u001b[0m \u001b[39m# Calculate and add the VIF to the data frame\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m vif_data[\u001b[39m'\u001b[39m\u001b[39mVIF\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [variance_inflation_factor(X\u001b[39m.\u001b[39;49mvalues, i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X\u001b[39m.\u001b[39mcolumns))]\n\u001b[1;32m     22\u001b[0m \u001b[39mprint\u001b[39m(vif_data)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/stats/outliers_influence.py:197\u001b[0m, in \u001b[0;36mvariance_inflation_factor\u001b[0;34m(exog, exog_idx)\u001b[0m\n\u001b[1;32m    195\u001b[0m mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(k_vars) \u001b[39m!=\u001b[39m exog_idx\n\u001b[1;32m    196\u001b[0m x_noti \u001b[39m=\u001b[39m exog[:, mask]\n\u001b[0;32m--> 197\u001b[0m r_squared_i \u001b[39m=\u001b[39m OLS(x_i, x_noti)\u001b[39m.\u001b[39mfit()\u001b[39m.\u001b[39mrsquared\n\u001b[1;32m    198\u001b[0m vif \u001b[39m=\u001b[39m \u001b[39m1.\u001b[39m \u001b[39m/\u001b[39m (\u001b[39m1.\u001b[39m \u001b[39m-\u001b[39m r_squared_i)\n\u001b[1;32m    199\u001b[0m \u001b[39mreturn\u001b[39;00m vif\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/regression/linear_model.py:922\u001b[0m, in \u001b[0;36mOLS.__init__\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    919\u001b[0m     msg \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mWeights are not supported in OLS and will be ignored\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    920\u001b[0m            \u001b[39m\"\u001b[39m\u001b[39mAn exception will be raised in the next version.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    921\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(msg, ValueWarning)\n\u001b[0;32m--> 922\u001b[0m \u001b[39msuper\u001b[39;49m(OLS, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(endog, exog, missing\u001b[39m=\u001b[39;49mmissing,\n\u001b[1;32m    923\u001b[0m                           hasconst\u001b[39m=\u001b[39;49mhasconst, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    924\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mweights\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_keys:\n\u001b[1;32m    925\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_keys\u001b[39m.\u001b[39mremove(\u001b[39m\"\u001b[39m\u001b[39mweights\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/regression/linear_model.py:748\u001b[0m, in \u001b[0;36mWLS.__init__\u001b[0;34m(self, endog, exog, weights, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    747\u001b[0m     weights \u001b[39m=\u001b[39m weights\u001b[39m.\u001b[39msqueeze()\n\u001b[0;32m--> 748\u001b[0m \u001b[39msuper\u001b[39;49m(WLS, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(endog, exog, missing\u001b[39m=\u001b[39;49mmissing,\n\u001b[1;32m    749\u001b[0m                           weights\u001b[39m=\u001b[39;49mweights, hasconst\u001b[39m=\u001b[39;49mhasconst, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    750\u001b[0m nobs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexog\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    751\u001b[0m weights \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/regression/linear_model.py:202\u001b[0m, in \u001b[0;36mRegressionModel.__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, endog, exog, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 202\u001b[0m     \u001b[39msuper\u001b[39;49m(RegressionModel, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(endog, exog, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    203\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpinv_wexog: Float64Array \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_attr\u001b[39m.\u001b[39mextend([\u001b[39m'\u001b[39m\u001b[39mpinv_wexog\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwendog\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwexog\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mweights\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/base/model.py:270\u001b[0m, in \u001b[0;36mLikelihoodModel.__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, endog, exog\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 270\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(endog, exog, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    271\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialize()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/base/model.py:95\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m missing \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mmissing\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     94\u001b[0m hasconst \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mhasconst\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m---> 95\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_data(endog, exog, missing, hasconst,\n\u001b[1;32m     96\u001b[0m                               \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     97\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_constant \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mk_constant\n\u001b[1;32m     98\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexog \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mexog\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/base/model.py:135\u001b[0m, in \u001b[0;36mModel._handle_data\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_handle_data\u001b[39m(\u001b[39mself\u001b[39m, endog, exog, missing, hasconst, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 135\u001b[0m     data \u001b[39m=\u001b[39m handle_data(endog, exog, missing, hasconst, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    136\u001b[0m     \u001b[39m# kwargs arrays could have changed, easier to just attach here\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m kwargs:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/base/data.py:675\u001b[0m, in \u001b[0;36mhandle_data\u001b[0;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    672\u001b[0m     exog \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(exog)\n\u001b[1;32m    674\u001b[0m klass \u001b[39m=\u001b[39m handle_data_class_factory(endog, exog)\n\u001b[0;32m--> 675\u001b[0m \u001b[39mreturn\u001b[39;00m klass(endog, exog\u001b[39m=\u001b[39;49mexog, missing\u001b[39m=\u001b[39;49mmissing, hasconst\u001b[39m=\u001b[39;49mhasconst,\n\u001b[1;32m    676\u001b[0m              \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/base/data.py:88\u001b[0m, in \u001b[0;36mModelData.__init__\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconst_idx \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_constant \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> 88\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_constant(hasconst)\n\u001b[1;32m     89\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_integrity()\n\u001b[1;32m     90\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/statsmodels/base/data.py:133\u001b[0m, in \u001b[0;36mModelData._handle_constant\u001b[0;34m(self, hasconst)\u001b[0m\n\u001b[1;32m    131\u001b[0m check_implicit \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    132\u001b[0m exog_max \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmax(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexog, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m--> 133\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39;49misfinite(exog_max)\u001b[39m.\u001b[39mall():\n\u001b[1;32m    134\u001b[0m     \u001b[39mraise\u001b[39;00m MissingDataError(\u001b[39m'\u001b[39m\u001b[39mexog contains inf or nans\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    135\u001b[0m exog_min \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexog, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "### Check for collinarity in prompt variables \n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "# Define the predictor variables based on your model\n",
    "X = df_gpt3_w_dummy[[\n",
    "    'frame_gain', 'temperature', 'sys_role', 'instructions', \n",
    "    'risk']\n",
    "]\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Drop rows with missing or infinite values before calculating VIF\n",
    "X = X.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "# Create a new data frame for the VIF data\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['feature'] = X.columns\n",
    "\n",
    "# Calculate and add the VIF to the data frame\n",
    "vif_data['VIF'] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))]\n",
    "\n",
    "print(vif_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame coeff: 0.0652113652113649\n",
      "frame p-vale: 0.6447190740223837\n",
      "\n",
      "\n",
      "\n",
      "                             OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             rating_num   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.001\n",
      "Method:                 Least Squares   F-statistic:                    0.2128\n",
      "Date:                Fri, 04 Aug 2023   Prob (F-statistic):              0.645\n",
      "Time:                        19:47:53   Log-Likelihood:                -1870.6\n",
      "No. Observations:                 871   AIC:                             3745.\n",
      "Df Residuals:                     869   BIC:                             3755.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept         3.4795      0.105     33.120      0.000       3.273       3.686\n",
      "frame[T.loss]     0.0652      0.141      0.461      0.645      -0.212       0.343\n",
      "==============================================================================\n",
      "Omnibus:                      394.750   Durbin-Watson:                   0.992\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              147.636\n",
      "Skew:                           0.846   Prob(JB):                     8.74e-33\n",
      "Kurtosis:                       1.903   Cond. No.                         2.76\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "lin_reg = sm.OLS.from_formula('rating_num ~ frame + ', data = df_gpt3 ).fit()\n",
    "print(\"frame coeff:\", lin_reg.params[1])\n",
    "print(\"frame p-vale:\", lin_reg.pvalues[1])\n",
    "##print(\"\\nsignficicant effect? --> \", sig_effect(lin_reg.pvalues[1]))\n",
    "\n",
    "print(\"\\n\\n\\n\",lin_reg.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- H1.2: The strength of preference, as indicated by 'rating_num', will vary depending on whether the scenario is framed as a gain or loss."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
